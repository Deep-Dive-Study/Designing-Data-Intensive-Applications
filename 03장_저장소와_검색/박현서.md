# 1. 데이터베이스를 강력하게 만드는 데이터 구조

## 1) 해시 색인

키-값 저장소는 보통 해시 맵으로 구현한다.

- 비트캐스크
    - 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지하는 전략.
    - 해시 맵을 전부 메모리에 유지하기 때문에 사용 가능한 램에 모든 키가 저장되어 고성능 읽기, 쓰기가 가능하다.

하지만 파일에 항상 추가만하면 결국 디스크 공간이 부족해진다. 이러한 상황은 특정 크기의 세그먼트로 로그를 나누는 방식을 통해 해결할 수 있다.

- 세그먼트
    - 특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일에 이후 쓰기를 수행
    - 컴팩션 수행하여 중복된 키를 버리고 각 키의 최신 갱신 값만 유지

하지만 이러한 구조를 구현하기 위해서는 많은 사항을 고려해야 한다.

- 파일 형식
    - 바이트 단위의 문자열 길이를 부호화하여 원시 문자열을 부호화하는 바이너리 형식 사용
- 레코드 삭제
    - 키와 관련된 값을 삭제하려면 데이터 파일에 특수한 삭제 레코드를 추가한다.
    - 로그 세그먼트 병합 과정에서 삭제된 키의 이전 값을 무시하게 한다.
- 고장 복구
    - 서버 재시작 시에 인메모리 해시 맵은 손실되지만 세그먼트 파일을 통해 복원할 수 있다.
    - 서버 재시작 시에 비트캐스크는 각 세그먼트 해시 맵을 메모리로 빠르게 로딩하기 위해 스냅샷을 디스크에 저장해둔다.
- 부분적으로 레코드 쓰기
    - 로그에 레코드를 추가하는 도중에 서버가 죽어도 비트캐스크 파일은 체크섬을 포함하고 있어 로그의 손상된 부분을 탐지할 수 있다.
- 동시성 제어
    - 쓰기를 엄격하게 순차적으로 로그에 추가할 때 하나의 쓰기 쓰레드만 쓰는 방식으로 구현할 수 있다.

## 2) SS테이블과 LSM 트리

세그먼트 파일 형식에 간단한 요구사항은 일련의 키-값 쌍을 키로 정렬하는 것이다.

- 정렬된 문자열 테이블 (SS테이블; Sorted String Table)
    - 디스크 상에 정렬된 세그먼트 파일(SS테이블)로 인해서 메모리에 모든 키의 색인을 유지할 필요가 없다.
    - 키값이 정렬되어 있으므로 두 키 사이에 어떤 키가 있을지 유추할 수 있다.

### 2-1) SS테이블 생성과 유지

데이터를 키로 정렬하는 방법

- 쓰기 데이터를 인메모리 균형 트리 데이터 구조에 추가한다.
- 멤테이블이 임곗값보다 커지면 SS테이블 파일로 디스크에 기록한다. 트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있어 효율적으로 수행이 가능하다.
- 읽기 요청을 제공하려면 멤테이블에서 키를 찾는다. 그 다음 디스크 상의 가장 최신 세그먼트에서 오래된 세그먼트 순으로 순차적으로 찾는다.

### 2-2) SS테이블에서 LSM 트리 만들기

- 로그 구조화 병합 트리(LSM; Log-Structured Merged-Tree)
    - 메모리 버퍼와 여러 개의 불변 SS 테이블로 구성된다.
    - 새로운 데이터는 메모리에 먼저 기록되고, 일정 시간이 지나거나 버퍼가 꽉 차면 SS테이블로 병합된다.
    - 여러 레벨로 데이터를 정리하며, 최신 데이터와 오래된 데이터를 효율적으로 관리합니다.

정렬된 파일 병합과 컴팩션 원리 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부른다.

### 2-3) 성능 최적화

LSM 트리의 기본 개념은 백그라운드에서 연쇄적으로 SS테이블을 지속적으로 병합하는 거다. 데이터가 정렬된 순서로 저장돼 있단면 범위 질의를 효율적으로 실행할 수 있다. (Sorted String Table) → 디스크 쓰기 순차적을 ㅗ가능하여 LSM 트리가 매우 높은 쓰기 처리량을 보장할 수 있다.

- 블룸 필터 (Bloom filter)
    - 집합 내용을 근사한 메모리 효율적 데이터 구조
    - 키가 데이터베이스에 존재하지 않음을 알려주므로 존재하지 않는 키를 위한 불필요한 디스크 읽기 절약 가능
- SS테이블 압축, 병합 전략
    - 크기 계층 컴팩션 (size-tiered compaction)
        - 더 새롭고 작은 SS 테이블을 상대적으로 오래된 SS테이블에 연이어 병합
    - 레벨 컴팩션 (leveled compaction)
        - 키 범위를 더 작은 SS테이블로 나누고 오래된 데이터는 개별 레벨로 이동하기 떄문에 컴팩션을 점진적으로 진행하여 디스크 공간을 덜 사용함

## 3) B 트리

가장 널리 사용되는 색인 구조는 B 트리로 구조는 로그 구조화 색인과 다르다. 비슷한 점이 있다면 B 트리는 SS테이블과 같이 키로 정렬된 키-값 쌍을 유지하고 있어 범위 질의에 효율적이다. 하지만 두 색인 구조의 설계 철학이 매우 다르다.

- LSM 트리
    - (일반적으로) 수 메가바이트 이상의 가변 크기를 가진 세그먼트로 나누고 항상 순차적으로 세그먼트를 기록한다.
- B트리
    - (전통적으로) 4KB 크기의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다. 디스크가 고정 크기 블록으로 배열되기 때문에 근본적으로 하드웨어와 조금 더 밀접한 관련이 있다.

### 3-1) 신뢰할 수 있는 B 트리 만들기

B 트리의 쓰기 동작은 새로운 데이터를 디스크 상의 페이지에 덮어쓴다. 페이지를 덮어쓰더라도 페이지를 가리키는 모든 참조는 온전하게 남아 LSM 트리와 같은 로그 구조화 색인과는 대조적이다.

- 쓰기 전 로그  (WAL; Writed-Ahead Log, 리두 로그)
    - B트리 구현에 사용하는 데이터베이스가 고장 상황에서 스스로 복구할 수 있게 만드는 데이터 구조.
    - WAL은 트리 페이지에 변경된 내용을 적용하기 전에 모든 B트리의 변경 사항을 기록하는 추가 전용 파일이다.
    - 데이터베이스 고장 이후 복구될 때 일관성 있는 상태로 B 트리를 복원하는데 사용한다.
- 래치 (latch)
    - 가벼운 락으로 같은 자리의 페이지를 갱신하는 작업에서 동시성을 제어한다.

### 3-2) B 트리 최적화

- WAL 유지 대신 쓰기 시 복사 방식(copy-on-write scheme)
    - 페이지 덮어 쓰기와 고장 복구를 위해 일부 데이터베이스는 쓰기 시 복사 방식을 사용한다.
- 페이지에 전체 키를 저장하는게 아닌 키를 축약해서 쓴다.
    - 공간 절약이 가능하다.
    - 트리 내부 페이지에서 키가 키 범위 사이의 경계 역할을 하는데 충분한 정보만 제공하면 된다.
- 트리에 포인터를 추가한다.
    - 각 리프 페이지가 양쪽 형제 페이지에 대한 참조를 가지면 상위 페이지로 다시 이동하지 않아도 순서대로 키를 스캔할 수 있다.
- 프랙탈 트리(fractal tree)
    - B 트리 변형으로 디스크 찾기를 줄이기 위해 로그 구조화 개념을 일부 빌렸다.

### 3-3) B 트리와 LSM 트리 비교

- B 트리
    - 읽기 성능에 유리하다.
    - 범위 질의에 적합하다.
- LSM 트리
    - 쓰기 작업에 최적화되어 순차적 디스크 쓰기가 가능하다.
    - 읽기  시 여러 레벨의 데이터 파일을 검색해야 한다. (각 컴팩션 단계에 있는 여러 가지 데이터 구조와 SS 테이블을 확인해야 한다.)

### 3-4) LSM 트리의 장점

- B 트리
    - 모든 데이터 조각을 최소한 두 번 기록해야 한다. (쓰기 전 로그, 트리 페이지)
    - 페이지 내 몇 바이트만 바뀌어도 한 번에 전체 페이지를 기록해야 한다.
- LSM 트리
    - 순차적으로 컴팩션된 SS테이블 파일을 쓴다. → 순차 쓰기
    - 압축률이 좋아 B 트리보다 디스크에 더 적은 파일을 생성한다.
        - B 트리 저장소 엔진은 파편화로 인해 사용하지 않는 디스크 공간 일부가 남는다.
        - LSM 트리는 주기적으로 파편화를 없애기 위해 SS테이블을 다시 기록하여 저장소 오버헤드가 낮다.

### 3-5) LSM 트리의 단점

- B 트리
    - 각 키가 색인의 한 곳에만 정확하게 존재한다. → 트랜잭션이 강력하다.
- LSM 트리
    - 높은 쓰기 처리량
        - 컴팩션 과정이 때로 진행 중인 읽기와 쓰기의 성능에 영향을 준다.
        - 디스크의 쓰기 대역폭은 유한한데 백그라운드에서 수행되는 컴팩션 스레드가 이 대역폭을 공유해야 한다.
    - 컴팩션 설정
        - 컴팩션이 유입 쓰기 속도를 따라가지 못할 수 있다. 보통 SS테이블 기반 저장소 엔진은 유입 쓰기의 속도를 조절하지 않으므로 이런 상황을 감지하기 위한 모니터링이 필요하다.

## 4) 기타 색인 구조

### 4-1) 색인 안에 값 저장하기

색인에서 키는 질의가 검색하는 대상이다. 값은 실제 로우 또는 다른 곳에 저장된 로우를 가리키는 참조다.

- 힙 파일
    - 다른 곳에 저장된 로우.
    - 특정한 순서 없이 레코드를 단순히 나열하는 파일 구조.
- 힙 파일과 인덱스
    - 여러 보조 색인이 존재할 때 데이터 중복을 피할 수 있다.
    - 각 색인은 **힙 파일에서 위치만 참조**하고 실제 데이터는 일정한 곳에 유지한다.
    - 키를 변경하지 않고 값을 갱신할 때 효율적이다.
        - 새로운 값이 이전 값보다 많은 공간을 필요하지 않으면 레코드를 제자리에 덮어쓸 수 있다.
- 클러스터드 색인
    - ex. MySQL InnoDB
    - 테이블의 기본키가 클러스터드 색인이고 보조 색인은 기본키를 참조

### 4-2) 다중 칼럼 색인

- 결합 색인 (concatenated index)
    - 결합 색인은 하나의 칼럼에 다른 칼럼을 추가하는 방식으로 하나의 키에 여러 필드를 단순히 결합한다.
- 다차원 색인
    - 이차원 위치를 공간 채움 곡선(space-filling curve)을 이용해 단일 숫자로 변환한 다음 일반 B 트리 색인을 사용한다.
    - R 트리처럼 전문 공간 색인(specialized spatial index)을 사용하는 것이다.

### 4-3) 전문 검색과 퍼지 색인

철자가 틀린 단어와 같이 유사한 키에 대해서의 질의 기술이 필요하다.

- 루씬
    - 용어 사전을 위해 SS테이블 같은 구조를 사용한다.
    - 작은 인메모리 색인이 필요하다. 인메모리 색인은 키를 찾는데 필요한 정렬 파일의 오프셋을 질의에 알려주는데 사용한다. 루씬에서 인메모리 색인은 여러 키 내 문자에 대한 유한 상태 오토마톤으로 트라이와 유사하다. 이 오토마톤은 레벤슈타인 오토마톤으로 변환할 수 있다.

### 4-4) 모든 것을 메모리에 보관

램이 점점 저렴해지는 등의 이유로 인메모리 데이터베이스가 개발됐다.

일부 인메모리 키-값 저장소는 장비가 재시작되면 데이터 손실을 허용하는 용도로만 사용된다. 하지만 다른 인메모리 데이터베이스는 지속성을 목표로 한다.

- 지속성 유지
    - 특수 하드웨어를 사용
    - 디스크에 변경 사항의 로그를 기록
    - 디스크에 주기적인 스냅숏 기록
    - 다른 장비에 인메모리 상태 복제

인메모리 데이터베이스의 성능 장점은 디스크에서 읽지 않아도 된다는 것 뿐만은 아니다. 디스크 기반 저장소 엔진도 운영체제가 최근에 사용한 디스크 블록을 메모리에 캐시하기 때문이다. 인메모리 데이터베이스는 디스크에 기록하기 위한 형태로 부호화하는 오버헤드를 피할 수 있어서 빠를 수도 있다.

안티 캐싱 접근 방식은 가장 최근에 사용하지 않은 데이터를 디스크로 보내고 나중에 다시 접근할 때 메모리에 적재한다. 이러한 방식은 운영체제가 가상 메모리와 스왑 파일에서 수행하는 방식과 유사하다. 하지만 데이터베이스는 전체 메모리 페이지보다 개별 레코드 단위로 작업할 수 있기 때문에 OS보다 더 효율적으로 메모리를 관리할 수 있다.


# 2. 트랜잭션 처리나 분석

트랜잭션은 반드시 ACID 속성을 가질 필요는 없다. 트랜잭션 처리는 일괄 처리 작업이 아닌 클라이언트가 지연 시간이 낮은 읽기/쓰기가 가능하게 한다는 의미이기도 하다.

- 온라인 트랜잭션 처리 (OLTP, online transaction processing)
    - 사용자 입력 기반으로 삽입/갱신되는 레코드와 같은 접근 패턴을 갖는 트랜잭션을 의미한다.
- 온라인 분석 처리 (OLAP, online analytic processing)
    - 데이터 분석에 사용되는 경우, 예시로 많은 수의 레코드를 스캔해 일부 컬럼만 집계 통계를 계산

OLTP와 OLAP의 차이점은 명확하지 않지만 아래처럼 특징을 정리할 수 있다.

| 특성 | OLTP | OLAP |
| --- | --- | --- |
| 주요 읽기 패턴 | 질의당 적은 수의 레코드, 키 기준으로 가져옴 | 많은 레코드에 대한 집계 |
| 주요 쓰기 패턴 | 임의 접근, 사용자 입력을 낮은 지연 시간으로 기록 | 대규모 불러오기 또는 이벤트 스트림 |
| 주요 사용처 | 웹 애플리케이션을 통한 최종 사용자/소비자 | 의사결정 지원을 위한 내부 분석가 |
| 데이터 표현 | 데이터의 최신 상태 (현재 시점) | 시간이 지나며 일어난 이벤트 이력 |
| 데이터셋 크기 | 기가바이트에서 테라바이트 | 테라바이트에서 페타바이트 |

OLTP, OLAP 에서도 잘 동작했지만 OLTP 시스템을 분석 목적으로 사용하지 않고 개별 데이터베이스에서 분석을 수행하게 되는데, 이 데이터베이스를 **데이터 웨어하우스(data warehouse)**라고 부른다.

## 1) 데이터 웨어하우징

OLTP 시스템은 사업 운영에 중요하기에 높은 가용성, 낮은 지연성으로 트랜잭션 처리를 기대한다. 하지만 **즉석 분석 질의 시에 읽기 스캔, 동시에 실행되는 트랜잭션의 성능을 저하시킬 가능성**이 있다. 때문에 OLTP 시스템에 즉석 분석 질의를 실행하기에는 부담스럽다.

하지만 데이터 웨어하우스는 OLTP 작업에 영향없이 질의할 수 있다. 데이터는 OLTP 데이터베이스에서 추출, 변환하여 데이터 웨어하우스에 적재한다. 그러나 대기업에는 대부분 데이터 웨어하우스가 있지만 소규모 기업에서는 적은 양의 데이터를 갖고 있기에 SQL 데이터베이스에 질의하거나 스프레드시트에서 분석하기도 한다.

### 1-1) OLTP 데이터베이스와 데이터 웨어하우스의 차이점

- 데이터 웨어하우스
    - 데이터 모델은 관계형 모델을 사용한다. → SQL이 분석 질의에 적합하기 때문에 관계형 모델을 일반적으로 사용한다.
    - SQL을 사용한다. → 분석 질의에 적합하기 때문이다.

데이터 웨어하우스와 관계형 OLTP 데이터베이스 둘 다 SQL을 지원하기에 비슷해보이지만 **각각 다른 질의 패턴에 최적화되어 있어 시스템 내부는 완전히 다르다.**

## 2) 분석용 스키마: 별 모양 스키마와 눈꽃송이 모양 스키마

- 사실 테이블 (fact table)
    - 측정값, 비즈니스 이벤트를 저장하는 테이블 (매출, 수량, 조회수, 클릭 수, …)
- 차원 모델링 (dimensional modeling)
    - 측정값, 비즈니스 이벤트를 설명하고 분석을 위한 기준이 되는 속성을 저장하는 테이블 (고객 정보, 제품 정보, 시간 정보, …)
- 별 모양 스키마 (star schema)
    - 중앙에 사실 테이블이 있다.
    - 사실 테이블 주변에 차원 테이블이 직접 연결되어 있는 구조다.
    - 장점: 단순하고, 쿼리 성능이 좋다.
    - 단점: 차원 테이블에 중복 데이터가 많아질 수 있다.
- 눈꽃송이 모양 스키마 (snowflake schema)
    - 차원 테이블이 정규화되어 있고, 서브 테이블로 분리된 구조다.
    - 장점: 중복이 적고 저장공간이 효율적이다.
    - 단점: 조인 복잡도가 높다. 구조가 복잡해지고 직관성이 낮아진다.

# 3. 칼럼 지향 저장소

테이블에 많은 로우 개수와 페타바이트 데이터가 있다면 효율적인 저장, 질의는 어려운 문제가 된다. 사실 테이블은 보통 칼럼이 100개 이상이지만 일반적인 데이터 웨어하우스 질의는 한 번에 4, 5개 컬럼만 접근한다.

![image](https://github.com/user-attachments/assets/0412bcf4-acad-405d-b9c5-727b115cfb36)

- 로우 지향 방식
    - 대부분의 OLTP 데이터베이스에서 저장소는 로우 지향 방식으로 데이터를 배치한다.
    - 로우 지향 방식 문제: 칼럼에 색인을 걸었을 때 저장소 엔진에 레코드를 찾을 수 있는 위치를 알려준다. 하지만 특정 쿼리는 디스크로부터 모든 로우를 메모리로 적재하고 구문을 해석하여 필요한 조건을 충족하지 않은 로우를 필터링해야 한다.
- 칼럼 지향 방식
    - 모든 값을 하나의 로우에 함께 저장하지 않고 대신 각 칼럼별로 모든 값을 저장한다.
    - 로우 지향 방식 문제 해결: 각 칼럼을 개별 파일에 저장하면 질의에 사용되는 칼럼만 읽고 구분 분석을 하면 되어 작업량이 많이 줄어든다.

## 1) 칼럼 압축

질의에 필요한 컬데이터를 압축하면 디스크 처리량을 더 줄일 수 있다. 칼럼 지향 저장소는 대게 압축에 적합하다.

보통 칼럼의 고유 값은 로우 수에 비해 적다. 그래서 n개의 고유 값을 가진 칼럼을 n개의 개별 비트맵으로 변환할 수 있다. 그리고 추가적으로 런 렝스 부호화를 할 수도 있다.

- 비트맵 부호화 (bitmap encoding)
    - 고유 값에 대해 비트 배열을 만든다. 데이터 위치를 0과 1로 표시하는 인코딩 방식이다.
    - 카디널리티가 낮아야 효율적이다. → 높을 경우 비트맵 하나당 비트 수가 많아져 공간 및 연산 비용이 커진다.

### 1-1) 메모리 대역폭과 벡터화 처리

데이터 웨어하우스 질의는 디스크로부터 메모리로 데이터를 가져오는 대역폭이 병목이다.

- 메모리 대역폭 (memory bandwidth)
    - 데이터 이동 속도
- 백터화 처리 (vectorized processing)
    - 데이터 처리 속도

**백터화 처리란?**

- 메인 메모리에서 CPU 캐시로 가는 대역폭을 효율적으로 사용한다.
- CPU 명령 처리 파이프라인에서 **분기 예측 실패(branch misprediction)**와 **버블(bubble)**을 피해야 한다.
- 최신 CPU에서 **단일 명령 다중 데이터(single-instruction-multi-data)** 명령을 사용하게끔 해야 한다.
- 질의 엔진은 압축된 칼럼 데이터를 CPU의 L1 캐시에 딱 맞게 나누어 가져오고 이 작업을 타이트 루프(tight loop)에서 반복한다.
- 칼럼 압축을 사용하면 같은 양의 L1 캐시에 칼럼의 더 많은 로우를 저장할 수 있다. 비트 AND, OR 연산자는 압축된 칼럼 데이터 덩어리를 바로 연산할 수 있도록 한다.

## 2) 칼럼 저장소의 순서 정렬

데이터베이스 관리자는 공통 질의에 대한 지식을 사용해 테이블에서 정렬해야하는 컬럼을 선택할 수 있다.

시간 범위를 목표로 한다면 1차 정렬 키를 `date`로 둔다. 질의 최적화기는 `date`에 해당하는 로우만 스캔할 수 있어 모든 로우를 스캔하기보다 훨씬 빠르다. 보조 정렬키는 같은 날짜에 판매한 같은 제품을 그룹화할 수 있도록 product_sk를 보조 정렬 키로하는게 합리적이다. 날짜 범위에 판매 제품을 그룹화하거나 필터링하는 질의에 도움이 된다.

정렬된 순서일 경우 칼럼 압축에도 도움이 된다.

### 2-1) 다양한 순서 정렬

장비 문제로 데이터를 잃지 않으려면 데이터를 여러 장비에 복제해 두는 작업이 필요하다. 이때 복제 데이터를 다른 방식으로 정렬해서 저장하면 질의할 때 가장 적합한 버전을 찾아 질의할 수 있다.

## 3) 칼럼 지향 저장소에 쓰기

칼럼 지향 저장소, 압축, 정렬은 모두 읽기 질의를 더 빠르게 하지만 쓰기는 어렵다.

B 트리와 같은 제자리 갱신 접근 방식은 압축된 컬럼에서는 불가능하다. 정렬된 테이블의 중간에 있는 로우에 삽입을 원하는 경우 모든 칼럼 파일을 재작성해야 한다.

그래서 모든 쓰기는 먼저 인메모리 저장소에 이동해 정렬된 구조에 추가하고 디스크에 쓸 준비를 한다. 그리고 충분한 조건에 맞으면 디스크의 칼럼 파일에 병합하고 대량으로 새로운 파일에 기록한다.

## 4) 집계: 데이터 큐브와 구체화 뷰

데이터 웨어하우스 질의는 보통 SQL에 COUNT, SUM, AVG, MIN, MAX와 같은 집계 함수를 포함한다. 동일한 집계를 다양한 질의에서 사용하기 위해 매번 원시 데이터를 처리하는 일은 비효율적이다. 그래서 질의가 자주 사용하는 일부 값을 캐시하고 그 방법 중 하나가 **구체화 뷰**이다.

- 구체화 뷰(materialized view)
    - 질의가 가주 사용하는 카운트나 합을 캐싱하는 방법
    - 원본 데이터 변경 시 구체화 뷰 갱신
        - OLTP 데이터베이스의 경우 갱신으로 인한 쓰기 비용이 비싸 자주 사용하지 않는다.
        - 데이터 웨어하우스는 읽는 비중이 크기 때문에 구체화 뷰를 사용하는 방법이 합리적이다.
