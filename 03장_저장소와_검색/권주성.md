# 03. 저장소와 검색
- DB는 크게 두가지 기능을 제공함(데이터를 저장하고 / 요청시 제공)
  - **`Write(쓰기)`**
  - **`Read(읽기)`**

- **`개발자가 DB를 자세히 알아야하는 이유`**
  - 사용 가능한 여러 저장소 엔진 중에 어플리케이션에 적합한 엔진을 찾고, 선택하는 작업을 해야하기 때문
  - 또한, 특정 상황에 맞게 최적화하기 위해서는 내부에서 수행되는 작업에 대한 원리를 이해해야하기 때문
  - 즉, 원리를 알아야 장단점을 알고 상황에 적합한 것을 선택하거나 원하는 방식대로 수정할 수 있기 때문에 자세히 알아야함  

- 저장소 엔진
  - 로그 구조 → LSM Tree
  - 페이지 지향 → B+Tree

## 데이터베이스를 강력하게 만드는 데이터 구조
- 가장 간단한 구조의 데이터베이스를 두 개의 bash 함수로 구현해보자

```bash
#!/bin/bash

db_set () {
  echo "$1,$2" >> database
}

db_get () {
  grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```

- db_set() : 일반적으로 append-only 데이터 파일인 로그 기반의 파일 추가 작업은 매우 효율적임
- db_get() : 반면 이런 구조에선 검색 비용이 O(n) 으로 매우 비효율적임

- 따라서, 특정 키의 값을 효율적으로 찾기 위해 **`색인(index)`** 이 필요함
  - index의 일반적인 개념은 탐색을 위해 부가적인 메타데이터를 유지하는 것
    - 기본 데이터에서 파생된 추가적인 구조
    - 추가적인 구조의 유지보수는 특히 쓰기 과정에서 오버헤드가 발생함
    - 데이터를 쓸때마다 매번 색인 또한 같이 업데이트해주어야 하기 때문 

  - 즉, **읽기 질의 속도가 향상되지만, 쓰기 속도가 떨어지는 트레이드오프** 를 가짐

  - 이러한 트레이드오프 때문에 모든 것을 index 적용하진 않으며, 개발자는 애플리케이션의 전형적인 질의 패턴을 활용하여 수동으로 적절한 index를 선택해야 함
    - 애플리케이션에 가장 큰 이익을 가져다 주는 색인을 선택

- 실제 데이터 베이스는 다뤄야 할 내용이 더 많으나, 크게 보면 기본 원리는 동일함
  - 동시성 처리, 디스크 공간 회수, 오류 처리, 트랜잭션 처리, 등 

### 해시 색인
- 키-값 저장소는 dictionary type과 매우 유사하며 보통 hash map(hash table)로 구현함
- 키 → 바이트 오프셋(데이터의 위치) 매핑 정보를 in-memory hash map에 유지하는 전략이 있음

  ![CleanShot 2025-03-30 at 04 12 02](https://github.com/user-attachments/assets/389792de-0a34-41e3-be71-3522f26152ee)

- 이는, 각 키의 값이 자주 갱신되는 상황에서 적합함
  - 예를 들어, 키가 동영상 URL이고 값은 동영상의 재생횟수인 경우
    - 쓰기 부하가 많지만 고유 키는 적어서 메모리에 모든 키 보관 가능함
    - 새로운 키가 계속 추가되기 보단 기존 키의 값이 계속 갱신되기 때문에 효율적임
    - 단, 값(재생횟수 정보 로그)을 디스크에 계속 append하므로 언젠간 디스크 공간이 부족해짐

- 위 예시에서 디스크 공간 부족은 로그를 **세그먼트(segment)** 로 나눠 저장하는 방식으로 해결할 수 있음
  - 세그먼트 파일들에 대해 **컴팩션(compaction)** 을 수행해 중복된 키를 버리고 각 키의 최신 상태값만 유지할 수 있음
  - 컴팩션을 수행할 때 여러 세그먼트를 병합하여 디스크 공간을 확보할 수 있음

    ![CleanShot 2025-03-30 at 04 15 39](https://github.com/user-attachments/assets/d42b9edb-9f15-4648-93fa-f77e038418c3)

    - 병합과 컴팩션 수행은 새로운 세그먼트 파일을 만드는 방식으로 동작함
    - 병합과 컴팩션 동안 이전 세그먼트 파일을 이용해 **읽기와 쓰기 요청을 정상적으로 계속 수행**할 수 있음
    - 전환 후 이전 세그먼트 파일은 간단히 삭제하면 끝
    - 이러한 작업은 백그라운드 스레드에서 수행됨

- 이러한 해시 index 세그먼트 방식을 구현하기 위해 고려해야 할 사항들
  - **`파일 형식`**
    - CSV 같은 형식보단 이스케이핑 작업이 필요없는 원시 문자열을 부호화하는 바이너리 형식이 더 빠르고 간편함
  - **`레코드 삭제`**
    - 키에 대한 값을 삭제하려면 **툼스톤(tombstone)** 과 같은 특수한 삭제 레코드를 추가해야함
    - 세그먼트 병합 과정에서 툼스톤은 삭제된 키의 이전 값을 무시함
  - **`Crash 복구`**
    - DB 재시작 시 메모리 상의 hash map이 손실되므로 디스크 전체를 읽고 hash map을 복구해야 함
    - 이 작업은 시간이 오래걸리므로 **스냅샷**을 디스크에 저장해 복구 속도를 높일 수 있음
  - **`부분적으로 레코드 쓰기`**
    - DB는 레코드 추가 도중에도 죽을 수 있으므로 파일에 체크섬을 포함하여 로그의 손상된 부분을 탐지해 무시하도록 조치할 수 있음
  - **`동시성 제어`**
    - 쓰기 작업은 로그 추가를 엄격하게 순차적으로 수행하려면 하나의 쓰기 스레드만 사용하는 방법이 있음
    - 읽기 작업은 데이터 파일 세그먼트는 append-only이거나 immutable하므로 다중 스레드로 동시에 읽기를 할 수 있음

- 추가 전용 로그(append-only 방식)은 언뜻 보면 낭비 같아 보이지만 많은 장점이 있음 
  - append-only 방식이 정해진 자리에 파일을 갱신하는 방식 보다 좋은 점
    - 순차적인 쓰기 작업이 보통 무작위 쓰기보다 **훨씬 빠름**.
    - append-only이나 immutable이면 **동시성과 Crash 복구가 훨씬 간단함**
      - 장애 시 이전 값 부분과 새로운 값 부분이 구분되기 때문
    - 오래된 세그먼트 병합은 시간에 따라 **조각화되는 데이터 파일 문제**를 피할 수 있음
    
- hash table의 제한 사항(단점)
  - **키가 많아지면** hash table을 메모리에 비해 성능이 떨어지는 **디스크로 확장하여 저장**해야 함
    - 낮은 무작위 I/O 속도, 디스크가 가득 찼을 때의 비싼 확장 비용, 해시 충돌을 위한 성가신 로직 등
  - hash table은 **범위 질의(range query)** 에는 효율적이지 않다.

- 위와 같은 단점을 극복한 index 구조
  - LSM Tree
  - B Tree 

### SS테이블과 LSM 트리
- **SS테이블(Sorted String Table)**
  - 앞의 append-only 방식의 세그먼트는 키-값 로그가 쓰여진 순서대로 저장되며 나중의 키 값이 이전의 키 값보다 우선이었음
  - 반면, SS테이블은 일련의 **키-값 쌍을 키로 정렬** 한 형태로 데이터를 저장 
  - 각 키는 각 병합된 세그먼트 파일 내에 한 번만 나타남 (**컴팩션 과정**이 이를 보장)
  
- SS테이블이 hash index의 로그 세그먼트보다 나은 장점
  - **파일이 메모리보다 커도 효율적으로 병합할 수 있음**
    - SS테이블의 세그먼트 병합은 **병합정렬(Merge Sort)** 방식과 유사함
    - 이미 정렬된 각 세그먼트 파일의 첫 번째 키부터 가져오며 새로운 병합된 세그먼트 파일을 생성함

  - **메모리에 모든 키의 index를 유지할 필요가 없음**
    - 디스크 상의 세그먼트 파일에서 키들이 정렬되어 있으므로, index에 없는 키는 index의 다른 두 키 사이 범위만 스캔하여 빠르게 찾을 수 있음
   
  - **레코드 블록을 압축하여 디스크에 저장함**
    - 읽기 요청은 여러 키-값 쌍 범위를 스캔하므로 해당 레코드들을 그룹화하여 압축 저장함
    - 그러면 index의 각 항목은 블록의 시작을 가리키게 됨
    - 이는 **디스크 공간 절약** 뿐만 아니라 **I/O 대역폭 감소**라는 장점을 갖음 

![CleanShot 2025-03-30 at 04 25 13](https://github.com/user-attachments/assets/6082fd92-4277-4cf9-9136-8499c8f9b690)

![CleanShot 2025-03-30 at 04 28 08](https://github.com/user-attachments/assets/372f46ed-94b7-4236-a879-7a036840052b)

### SS테이블 생성과 유지
- 데이터 키로 정렬하기 위해 일단 쓰기 요청이 들어오면 **멤테이블(memtable)** 에 추가하여 관리함
  - 정렬된 데이터 구조는 디스크보다 메모리에서 유지하는 편이 훨씬 쉬움
    - 레드블랙 트리나 AVL 트리 등의 인 메모리의 balanced tree 형태
  - 이후 멤테이블이 임곗값보다 커지면 SS테이블 파일로 디스크에 기록 수행

- 읽기 요청이 들어오면 먼저 멤테이블에서 키를 찾고, 없으면 그 다음엔 디스크의 최신 세그먼트 파일에서, 그 다음 최신 세그먼트에서 찾는 식으로 탐색을 수행함

- 세그먼트 파일의 병합과 컴팩션은 백그라운드에서 실행함
- DB 장애 시, 아직 디스크에 기록되지 않은 멤테이블의 데이터 소실 문제가 발생할 수 있음
- 따라서, 매번 쓰기를 즉시 추가할 수 있게 분리된 로그를 디스크 상에 유지해야 함
  - WAL(write ahead log)으로 두어 해결
  - 멤테이블을 SS테이블로 기록하고 나면 해당 로그를 버릴 수 있음

### SS테이블에서 LSM 트리 만들기
- **로그 구조화 병합 트리(Log-Structured Merge-Tree, LSM 트리)**
  - 앞서 다룬 SS테이블처럼 정렬된 **파일 병합**과 **컴팩션** 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라고 함
  - LevelDB, RocksDB 등에서 활용
  - 구글 Bigtable(SS테이블, 멤테이블 용어 소개)에서 영감을 받은 카산드라와 HBase 또한 유사한 저장소 엔진을 사용함

- Elastic Search, Solr에서 사용하는 Lucene은 전문 검색 엔진
  - term dictionary를 저장하는데 유사한 방법을 사용
  - 검색 질의가 들어오면 단어가 언급된 모든 문서를 찾음
  - 키가 term, 값은 단어를 포함한 모든 문서의 ID 목록인 키-값 구조

### 성능 최적화
- 키가 DB에 없는 경우를 미리 확인하여 DB 전체 탐색을 사전에 방지
  - DB에 존재하지 않는 키를 찾는 경우, 멤테이블 → 최근 세그먼트 파일 → 오래된 세그먼트 파일 순으로 DB 전체를 탐색하므로 성능이 느려짐
  - **블룸 필터(Bloom filter)** 를 적용하면 집합 내용을 approximating(확률에 기반한 추정)한 데이터 구조로 DB 내 키 존재 여부를 빠르게 판단할 수 있으므로 불필요한 디스크 읽기를 절약할 수 있음

- 병합 순서와 시기를 결정하는 전략으로 성능 개선을 고려
  - **크기 계층 컴팩션(size-tiered compaction)**
    - 더 작고 새로운 SS테이블을 더 크고 오래된 것에 연이어 병합하는 방식
    - HBase, 카산드라
  - **레벨 컴팩션(leveled compaction)**
    - 키 범위를 작게 나누고 오래된 데이터를 개별 레벨로 이동하는 방식
    - 컴팩션을 점진적으로 진행해 디스크 공간을 덜 사용함
    - LevelDB, RocksDB, 카산드라

- 그 밖에 LSM 트리의 성능상 이점
  - LSM 트리의 기본 개념은 백그라운드에서 연쇄적으로 SS테이블을 지속적으로 병합하는 것으로, **`데이터셋이 메모리보다 훨씬 크더라도 효과적`** 
  - 데이터가 정렬된 상태로 저장되어 있으므로 **`range query에도 효과적`**
  - 쓰기 또한 순차적이므로 **`높은 쓰기 처리량도 보장함`**

### B 트리
- 관계형에서 표준 색인 구현으로 사용되는 것은 B-tree이며 많은 비관계형에서도 사용됨
- 키로 **정렬된 키-값 쌍을 유지**하여 range query에 효율적이란 점만 SS테이블과 유사하고 설계 철학이 매우 다름
  - 로그 구조화 색인 : DB를 수 MB 이상의 **가변 크기를 가진 세그먼트**로 나누고 항상 순차적으로 세그먼트를 기록함
  - B 트리 : 4KB 정도의 **고정 크기의 페이지**(혹은 블록)로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 수행함
  
  ![CleanShot 2025-03-30 at 04 42 24](https://github.com/user-attachments/assets/51c461ae-e2b1-4bdf-b84e-9fcaace07c76)

- 한 페이지가 B 트리의 루트(root)로 지정되어 루트에서부터 탐색이 시작됨
- 각 페이지는 여러 키와 하위 페이지에 대한 참조를 가짐 (참조는 포인터와 유사하나 메모리가 아닌 디스크상에 저장됨)
- 최종적으로 leaf page까지 도달하여 키에 대한 값을 탐색
- **분기 계수(branching factor)** : 한 페이지에서 하위 페이지를 참조하는 수.
  - 클 수록 트리의 깊이 수준을 낮출 수 있음

- B 트리의 키 값 갱신과 추가 방법
  - 키 값 갱신 : 키를 포함하는 leaf page 검색하여 페이지의 값을 바꾼 다음 디스크에 다시 기록함
  - 키 값 추가 : 추가할 키를 포함하는 범위의 페이지를 찾아 해당 페이지에 추가함. 페이지에 여유공간이 없다면 페이지를 둘로 나눠 상위 페이지가 나눠진 두 페이지를 참조하도록 갱신함

    ![CleanShot 2025-03-30 at 04 43 35](https://github.com/user-attachments/assets/56363056-b895-4772-983d-82baddc43a0c)

  - 위 알고리즘은 트리가 계속 균형을 유지하는 것을 보장함.n 개의 키를 가진 트리는 깊이가 항상 O(log n)임

### 신뢰할 수 있는 B 트리 만들기
- **WAL(write-ahead log)**
  - B 트리는 로그 구조화 색인과 달리, 새로운 데이터를 디스크 상의 페이지에 **덮어씀** (append-only가 아님)
  - 덮어쓰기는 하드웨어 동작이 복잡하며 DB가 고장나면 index가 훼손될 수 있음 (다른 페이지와의 참조를 잃어버린 **고아 페이지(orphan page)**)
  - 트리 페이지에 내용을 적용하기 전에 B 트리의 모든 변경사항을 WAL로 기록해두면 **DB 고장 시 복구**가 가능함 (WAL은 append-only로 기록)
- **래치(latch) 동시성 제어**
  - 같은 자리의 페이지를 갱신할 때 다중 스레드가 트리에 접근하는 것을 제어하기 위해 latch로 lock을 걸어 데이터 구조를 보호함
  - 반면, 로그 구조화 접근 방식은 유입 질의 간섭 없이 백그라운드로 모든 병합을 수행. 동시성 제어 측면에서 매우 간단함

### B 트리 최적화
- WAL 대신 **쓰기 시 복사 방식(copy-on-write scheme)**을 사용하여 동시성 제어까지 확보할 수 있음
  - 변경된 페이지는 다른 위치에 기록하고 상위 페이지의 새로운 버전을 만들어 새로운 위치를 가리키게 하는 방식
- 페이지에 전체 키가 아니라 **축약된 키**를 사용하여 공간을 절약할 수 있음
  - 페이지의 분기 계수가 늘어나면 트리 깊이 수준을 낮출 수 있음
- leaf page를 최대한 디스크 상에 연속된 순서로 배치하여 range query 성능을 높임
  - 하지만 트리가 커지면 순서를 유지하기 어려움
  - 반면, LSM 트리는 병합 과정에서 새로운 세그먼트 파일을 저장하므로 순서 유지가 더 쉬움
- 트리에 **포인터를 추가하여 형제 leaf page들끼리 참조**를 가지면 상위 페이지로 이동하지 않고도 순서대로 키를 스캔할 수 있음

### B 트리와 LSM 트리 비교
- 일반적으로 LSM 트리는 쓰기에서 빠르고 B 트리는 읽기에서 더 빠름
- LSM 트리는 컴팩션 단계의 데이터 구조와 SS 테이블을 확인해야 하므로 읽기에서 상대적으로 느릴 수 있음

- **`LSM 트리의 장점`**
  - B 트리보다 **쓰기 증폭(write amplification)**이 낮다.
    - DB 쓰기 한 번이 디스크에 여러번 쓰기를 야기하는 효과
    - B 트리는 WAL과 페이지 저장으로 최소 2번 기록(+덮어쓰기)
    - 반면 로그 구조화 색인은 컴팩션, 병합으로 여러번 쓰지만 append-only
  - B 트리보다 **쓰기 처리량을 높게 유지**할 수 있다.
    - LSM 트리는 순차적으로 컴팩션된 SS테이블 파일을 쓰기 때문 (덮어쓰기X)
  - B 트리보다 압축률이 더 좋다.
    - 주기적으로 파편화를 없애기 위해 SS테이블을 다시 기록하므로(컴팩션)

- **`LSM 트리의 단점`**
  - 컴팩션 과정이 읽기와 쓰기 성능에 영향을 미침
    - 디스크가 가진 자원은 한계가 있으며 **비싼 컴팩션 연산이 끝날 때까지 요청을 대기**해야하는 상황이 발생하기 쉬움
  - 높은 쓰기 처리량으로 인한 디스크 대역폭 제한
    - **디스크 대역폭**을 초기 쓰기와 백그라운드 컴팩션 작업이 **공유**하므로 DB가 커질 수록 컴팩션에 더 많은 대역폭을 사용해야 함
  - 컴팩션 속도가 유입 쓰기 속도를 따라가지 못 하는 경우
    - 아직 병합되지 않은 세그먼트 수가 디스크 공간이 부족해질 때까지 증가
    - 많은 세그먼트 파일을 확인해야 하므로 읽기 속도 또한 느려짐
  - 강력한 트랜잭션 시맨틱을 제공하는 DB에선 B 트리가 더 매력적
    - B 트리는 각 키가 index의 한 곳에만 정확하게 존재함
    - 반면, 로그 구조화 저장소 엔진은 같은 키의 다중 복사본이 존재할 수 있음 (여러 세그먼트를 병합하며 같은 키의 최신 값을 찾던 예시)

### 기타 색인 구조
- **`기본키 색인(primary key index)`**
    - 키-값 색인의 대표적인 예는 관계형 모델의 primary key
    - 관계형 : 기본키 ⇒ 로우
    - 문서형 : 기본키 ⇒ 문서
    - 그래프형 : 기본키 ⇒ 정점

- **`보조 색인 (seconday index)`**
    - 보통 효율적으로 조인을 수행하는데 사용
    - CREATE INDEX 명령으로 보조 색인 생성

### 색인 안에 값 저장하기
- **`힙 파일(heap file)`**
    - 실제 데이터가 저장되는 곳이며 각 index는 힙 파일에서 위치만 참조하고 실제 데이터는 일정한 곳에 유지함
    - 여러 보조 색인이 존재할 때 데이터 중복을 피할 수 있어 일반적인 방식
    - 키를 변경하지 않고 값을 갱신할 때 효율적임

- **`클러스터드 색인(clusterd index)`**
    - index에서 heap file로 다시 이동하는게 성능상 불이익이 많아서 index 안에 바로 색인된 로우(실제 데이터)를 저장하는 것이 바람직할 수 있음

- 커버링 색인(covering index), 포괄열이 있는 색인(index with included column)
    - 클러스터드 색인과 비클러스터드 색인 사이의 절충안

### 다중 칼럼 색인
- **`결합 색인(concatenated index)`**
  - 하나의 키에 여러 필드를 결합한 인덱스 (성, 이름)
  - 순서가 정렬되어 있어 특정 성인 모든 사람을 찾거나 특정 성 이름 조합을 가진 모든 사람을 찾을 때 유용함

### 모든 것을 메모리에 보관
- **`인메모리 데이터베이스`**
  - 램이 점점 저렴해지고 데이터셋 대부분은 그다지 크지 않기 때문에 메모리에 전체를 보관하는 방식이 현실성 있게 되었음(혹은 여러 장비 간 분산해서 보관)
  - 재시작 시 디스크나 네트워크를 통해 복제본에서 상태를 다시 적재해야 함
  - VoltDB, MemSQL, Oracle TimesTen, RAMCloud, Redis, Couchbase 등

## 트랜잭션 처리나 분석?
- 데이터 베이스를 사용하는 패턴(사례)는 크게 나누면 두가지로 분류가 가능함
  - **`온라인 트랜잭션 처리(OLTP)`** : 실시간(낮은 지연시간)으로 사용자의 입력을 기반으로 하는 트랜잭션 처리
  - **`온라인 분석 처리(OLAP)`** : 비즈니스 인텔리전스를 위한 데이터 분석

  ![CleanShot 2025-04-05 at 02 57 49](https://github.com/user-attachments/assets/ab8a99c8-3026-4a78-8e0d-2dfb6d1d9552)

- 이전에는 하나의 DB를 두고 두가지 용도로 사용하였으나, 최근에는 각각의 용도에 맞게 DB를 별도로 사용함
  - OLAP 을 위한 DB를 **`데이터 웨어하우스(data warehouse)`** 라고 함
  - 데이터가 증가함에 따라 처리에 대한 부하가 증가하게 되었으며, 부하에 따른 영향을 사용자에게 제공하는 트랜잭션 처리에 영향을 최소화하기 위함
 
### 데이터 웨어하우징
- 데이터 웨어하우스는 분석가들이 **`OTLP 작업에 영향을 주지 않고 마음껏 질의할 수 있는 개별 데이터베이스`** 임
  - 회사 내의 모든 다양한 OTLP 시스템에 있는 데이터의 `읽기 전용 복사본`
  - 데이터는 `추출하고(extract)`, 분석 친화적인 스키마로 `변환되고(transform)`, 적절한 데이터베이스에 `적재됨(load)`
  - 이과정을 **`ETL`** 이라고 함 (ETL 파이프라인을 구축하는 직군을 데이터 엔지니어라고 함) 
  
  ![CleanShot 2025-04-05 at 03 13 42](https://github.com/user-attachments/assets/0237a4d1-c7a0-4bca-b0b1-41000af62275)

### 분석용 스키마 : Star & Snowflake
- SQL은 일반적으로 분석 질의에 적합하기 때문에 데이터 웨어하우스의 데이터 모델은 가장 일반적인 관계형 모델을 사용함
  - SQL 질의를 생성하고 결과를 시각화하고 분석가가 드릴 다운, 슬라이싱 , 다이싱 같은 작업을 통해 데이터를 탐색하게 도와주는 도구가 많음

- 다만, 표면적으로는 SQL 인터페이스를 지원하지만, 각 시스템을 지원하는 데이터베이스 엔진의 내부 동작은 완전히 다름 
  - OLAP 용 DB : AWS RedShift, 아파치 하이브, 스파크 SQL, 등  

- 데이터 모델용 스키마는 대표적으로 `Star(별 모양) Schema` 라고 불리우는 차원 모델링 방식의 상당히 정형화된 방식을 사용함 
  - 정규화된 관계형 모델

  ![CleanShot 2025-04-05 at 03 20 00](https://github.com/user-attachments/assets/21771201-ceef-4807-bac4-98e84f577622)

 - 사실(이벤트, 행동, 등) 테이블을 중심으로 누가, 언제, 어디서, 무엇을, 어떻게, 왜를 나타내는 속성을 가지고 각각의 속성에 해당하는 차원 테이블(관계 테이블)과 연결되어 있는 형태

- 해당 스키마에 변형된 형태인 Snowflake 스키마는 차원이 하위 차원으로 좀 더 세분화된 형태
  - 더 정규화된 형태이지만, 분석가들에겐 Star가 작업하기 쉽다는 이유로 좀 더 선호됨 

- 보통 칼럼이 수백개인 경우도 있음

## 컬럼 지향 저장소
- OLAP는 보통 일괄적으로 많은 데이터를 집계하는 쿼리를 사용하기 때문에, OLAP를 위한 DB는 효율적으로 저장하고 쿼리하는 것이 중요함
- 보통, 분석가들이 분석을 위한 쿼리 패턴은 테이블의 컬럼 중 일부만 사용하는 경우가 많음 (전체 로우 혹은 광범위한 로우를 대상으로)

  ![CleanShot 2025-04-05 at 03 36 09](https://github.com/user-attachments/assets/c4208b19-dbd7-4d92-b0aa-b3ebddf2a553)

- 일반적인 트랜잭션 시스템은 로우 중심적임
  - 왜냐하면, 특정 사용자에 맞는 데이터를 제공하는 경우가 많기 때문에 인접한 데이터가 있는 로우 중심으로 처리가 중요함 (마치 document 처럼)
- 반면에, 분석은 개별 사용자보다도 전체 사용자의 패턴이나 통계적인 부분이 중요하기 때문에 컬럼 지향적임

- 컬럼 지향 저장소는 테이블의 데이터를 로우가 단위가 아닌 각 컬럼별로 모든 값을 함께 저장하는 형태

  ![CleanShot 2025-04-05 at 03 39 25](https://github.com/user-attachments/assets/228032a4-648b-405c-9661-bbed21b7a7eb)

  - 각 로우는 각 컬럼 파일에서 동일한 순서에 있음 

- 컬럼 지향 저장소에 장단점
  - 압축, 정렬,등의 작업을 통해 읽기 쿼리가 최적화되어 있음
  - 반대로 이러한 장점들로 인해 쓰기가 어려움(느려짐)
  - 앞서 설명한 LSM 방식을 통해 이런 단점을 극복하고 있음

- 대표적으로 아파치 카산드라, HBase, AWS Redshift, 등이 있음
