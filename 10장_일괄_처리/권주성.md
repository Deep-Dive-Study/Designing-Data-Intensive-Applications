# 10. 일괄 처리
- 시스템의 세 가지 유형
  - **`서비스(온라인 시스템)`**
    - 서비스는 클라이언트로부터 요청, 지시를 기다림
    - 가능한 빨리 요청을 처리해야함
    - 중요한 성능 지표는 **응답 시간**
      
  - **`일괄 처리 시스템(오프라인 시스템)`**
    - 매우 큰 입력 데이터를 받아 처리하고 결과 데이터를 생산함
    - 매우 오래 걸리므로 사용자가 작업이 끝나길 대기하지 않음
    - 일일 배치 등 반복적으로 수행
    - 주요한 성능 지표는 **처리량**
      
  - **`스트림 처리 시스템(준실시간 시스템)`**
    - 온라인과 오프라인, 일괄 처리 사이의 중간 어딘가에 위치함(준 실시간 처리)
    - 입력 데이터를 소비하고 출력 데이터를 생산함
    - 일괄 처리 시스템보다 지연 시간이 낮음

- 일괄 처리 시스템은 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션을 구축하는데 매우 중요한 구성 요소임
  - Ex) 맵리듀스(MapReduce)

## 유닉스 도구로 일괄 처리하기
- 다양한 도구를 사용해 로그를 처리하고 웹사이트 트래픽에 대한 보고서를 깔끔하게 만들 수 있음
- nginx 기본 액세스 로그 형식

  ![CleanShot 2025-06-29 at 22 29 40](https://github.com/user-attachments/assets/6f0940c0-8417-4422-954a-46c6992991fd)

#### 단순 로그 분석
- 유닉스 도구를 사용해 로그를 처리하여 웹사이트 트래픽에 관한 보고서를 작성

  ![CleanShot 2025-06-29 at 22 30 32](https://github.com/user-attachments/assets/5e505bcc-1747-4613-8415-011edf6b993d)

#### 연쇄 명령 대 맞춤형 프로그램
- 유닉스 도구 외에도 프로그래밍 문법으로도 위의 작업이 가능함
  - 문법적, 가독성 차이외에도 실행 흐름이 크게 다름(대용량 파일을 분석해보면 차이가 확연히 드러남)

- 유닉스 연쇄 명령 대신 루비 코드로 작성한 예제
  
  ![CleanShot 2025-06-29 at 22 31 18](https://github.com/user-attachments/assets/142f0a3f-d27a-4e9f-9c08-f2373fb67b5c)

#### 정렬 대 인메모리 집계
- 루비 스크립트는 URL 해시 테이블을 메모리에 유지함
- 허용 메모리보다 작업 세트가 크다면 **`정렬 접근법`** 을 사용하는 것이 좋음
  - 작업 세트 : 작업에서 임의 접근이 필요한 메모리 양
  - 반대로, 작업 세트가 충분히 작다면 인메모리 해시 테이블도 잘 작동함

- 정렬 접근법은 디스크를 효율적으로 사용함 (**SS테이블과 LSM 트리**)
  - 데이터 청크를 메모리에서 정렬하고 청크를 세그먼트 파일로 디스크에 저장
  - 정렬된 세그먼트 파일 여러 개를 한 정렬 파일로 **병합**
  - 병합 정렬은 순차적 접근 패턴을 따르고 디스크 상에서 좋은 성능을 냄

- 리눅스의 sort 유틸리티는 메모리보다 큰 데이터셋을 자동으로 디스크로 보내고 여러 CPU 코어에서 병렬로 정렬함
- 이는 유닉스 연쇄 명령이 **`메모리 부족 없이 손쉽게 큰 데이터셋으로 확장 가능`** 하다는 의미

### 유닉스 철학
- 유닉스 철학
  - 각 프로그램이 **`한 가지 일`** 만 하도록 작성하라
  - 모든 **`프로그램의 출력`** 은 **`다른 프로그램의 입력`** 으로 쓰일 수 있다고 생각하라
  - 소프트웨어를 **`빠르게 써볼 수 있게 설계하고 구축`** 하라
  - 프로그래밍 작업을 줄이려면 **`도구를 사용`** 하라. 도구 빌드에 한참 둘러가야 하고 사용 후 바로 버린다 할지라도

- sort의 경우 한 가지 일을 잘 해내는 좋은 예시임
  - 단, 단독으론 그다지 유용하지 않다. uniq 같은 **다른 유닉스 도구와 조합할 때 강력** 해짐

- 유닉스에서 이런 **`결합성`** 을 부여하는 것은 무엇일까?

#### 동일 인터페이스
- 어떤 특정 프로그램의 출력을 다른 프로그램의 입력으로 쓰려면 프로그램들이 같은 데이터 형식을 사용해야 함
  - 즉, 호환 가능한 인터페이스를 써야함
- 유닉스에서 인터페이스는 **`파일(파일 디스크립터)`** 임
  - 파일은 단지 순서대로 정렬된 바이트의 연속임

- 많은 유닉스 프로그램은 연속된 바이트를 아스키 텍스트로 취급함
  - awk, sort, uniq, head는 입력 파일을 `\n` 문자로 분리된 레코드로 다룸
- 완벽하진 않음에도 유닉스의 동일 인터페이스는 여전히 상호 운용, 구성 면에서 훌륭함

#### 로직과 연결의 분리
- 유닉스 도구의 다른 특징으론 **`표준 입력(stdin)`** 과 **`표준 출력(stdout)`** 을 사용한다는 점임
  - 혹은 파일에서 입력을 가져와 다른 파일로 출력을 재전송할 수도 있음

- 파이프는 한 프로세스의 stdout을 다른 프로세스의 stdin과 연결함
  - 중간 데이터를 디스크에 쓰지 않고 작은 인메모리 버퍼를 사용해 프로세스 간 데이터를 전송

- 프로그램은 입력이 어디서부터 들어오는지, 출력이 어디로 나가는지 신경쓸 필요가 없음
  - 쉘 사용자는 유닉스 접근법으로 원하는 대로 입력과 출력을 연결할 수 있음 
  - **`느슨한 결합(loose coupling)`** , **`지연 바인딩(late binding)`** , **`제어 반전(inversion of control)`** 이라고도 함

- 프로그램에서 **입출력을 연결하는 부분을 분리** 하면 작은 도구로 **`큰 시스템을 구성하기 수월`** 해짐

- 단, stdin, stdout을 사용할 경우 제약사항이 있음
  - 여러 개의 입력, 출력이 필요한 때 까다로워짐
  - 프로그램의 출력을 파이프를 이용해 네트워크와 연결하진 못함
  - 프로그램이 직접 파일을 열어 읽고 쓰거나, 서브프로세스로 다른 프로그램을 구동하거나, 네트워크 연결을 한다면 → 프로그램의 IO는 그 프로그램 자체와 서로 묶이게 됨
  - 즉, 입출력을 연결하는 **유연함이 감소** 함

#### 투명성과 실험
- 유닉스 도구가 성공적인 이유 중 하나는 `진행 사항을 파악하기 쉽기 때문`
  - 유닉스 명령의 **입력 파일** 은 보통 **`불변`** 으로 처리됨
    - 다양한 명령을 수행하더라도 입력 파일에는 손상을 주지 않음
  - 파이프라인의 어느 시점이든 **출력을 less로** 보내 원하는 형태의 출력이 나오는지 확인할 수 있음(디버깅할 때 매우 유용함)
  - 파이프라인의 특정 단계의 출력을 파일로 쓰고 그 파일을 다음 단계의 입력으로 사용할 수 있음
    - 이렇게 하면 전체 파이프라인을 다시 시작하지 않고 다음 단계부터 재시작할 수 있음

- 유닉스 도구를 사용하는 데 가장 큰 제약은 단일 장비에서만 실행된다는 점
  - 하둡과 같은 도구가 필요한 이유

## 맵리듀스와 분산 파일 시스템
- 맵리듀스는 수천 대의 장비로 분산해서 실행 가능함
- 입력을 수정하지 않으므로 출력 생산 외 다른 부수 효과가 없음
- 출력 파일은 순차적으로 한 번만 쓰여지고 이미 쓰여진 부분은 고치지 않음
- HDFS와 같은 분산 파일 시스템 상의 파일을 입력, 출력으로 사용함

- **`HDFS 분산 파일 시스템`**
  - NAS(Network Attached Storage), SAN(Storage Area Network) 등 공유 디스크 방식과는 반대로 **`비공유`** 원칙을 기반으로 하여 맞춤형 HW나 특별한 네트워크 인프라를 필요로 하지 않음
  - 각 장비에서 실행되는 데몬 프로세스로 구성되고 중앙 서버인 NameNode가 각 파일 블록이 어떤 장비에 저장됐는지 추적함 (개념적으로 매우 큰 하나의 파일 시스템)
  - 파일 블록은 장애 복구를 위해 단순히 여러 장비에 동일하게 복사되거나 erasure coding 방식으로 분산 저장되기도 함
  - 확장성이 뛰어남. 수만대 장비를 묶어 용량이 수백 페타바이트에 도달할 수 있음

### 맵리듀스 작업 실행하기
- **`맵리듀스의 데이터 처리 패턴`**
  - 입력 파일을 읽고 레코드로 쪼갬(한 로그 라인이 한 레코드가 됨)
  - 각 입력 레코드마다 매퍼 함수를 호출해 **`키와 값을 추출`** 함
  - 키를 기준으로 키-값 쌍을 모두 정렬함
  - 정렬된 키-값 쌍 전체에 대해 리듀스 함수를 호출함

- 맵리듀스 작업을 생성하려면 **매퍼와 리듀서라는 콜백 함수를 구현해야 함**
  - **`매퍼(Mapper)`**
    - 모든 입력 레코드마다 한 번씩만 호출됨
    - 입력 레코드로부터 키와 값을 추출함
    - 각 레코드를 독립적으로 처리

  - **`리듀서(Reducer)`**
    - 매퍼가 생산한 키-값 쌍을 받아 같은 키를 가진 레코드를 모음
    - 출력 레코드를 생산

#### 맵리듀스의 분산 실행
- 매퍼와 리듀서로 표준 유닉스 도구를 사용할 수도 있으나 보통 프로그래밍 언어로 함수를 작성함
- 매퍼 입력 파일의 복제본이 있는 장비에 리소스가 충분하다면 해당 장비에서 작업을 수행하려 함 → **`데이터 가까이에서 연산하기`**
  - 네트워크로 파일을 복사하는 부담 감소, 지역성은 증가
- 애플리케이션 코드(자바라면 jar 파일)를 작업을 수행하기 적절한 장비로 복사함
- 리듀서 측 연산도 파티셔닝됨
  - **`맵 태스크 수`** : 입력 파일의 블록 수로 결정됨
  - **`리듀서 태스크 수`** : 사용자 설정값에 의해 결정됨
  - 즉, 맵과 리듀스의 태스크 수가 다를 수 있음

- 키-값 쌍이 어느 리듀스 태스크에서 수행될지 결정하기 위해 **`키의 해시값`** 을 사용함

- 키-값 쌍은 반드시 정렬돼야 하지만 데이터셋이 매우 크면 한 장비에서 모두 정렬하기 어려우므로 **`여러 단계로 나누어`** 정렬을 수행함
  - 맵 태스크는 출력을 리듀서로 파티셔닝하여 로컬 디스크에 정렬된 파일로 기록함
  - 리듀서는 담당 파티션에 해당하는 키-값 쌍 파일을 다운로드함
  - 리듀서를 기준으로 파티셔닝, 정렬한 뒤 매퍼로부터 데이터 파티션을 복사하는 과정을 **`셔플(shuffle)`** 이라 함
  - 리듀스 태스크는 매퍼로부터 파일을 가져와 정렬된 순서를 유지하며 병합함

#### 맵리듀스 워크플로
- 단일 맵리듀스 작업으로 해결할 수 있는 문제의 범위는 제한적이므로 여러 맵리듀스 작업을 연결해 **`워크플로(workflow)`** 를 구성하는 방식이 일반적임
  - 한 MR 작업의 출력을 다른 MR의 입력으로 사용하는 방식
- 하둡 맵리듀스 작업 간 수행 의존성을 관리하기 위해 다양한 스케줄러가 개발되었음
  - Oozie, Azkaban, Luigi, Airflow, Pinball 등

### 리듀스 사이드 조인과 그룹화
- 연관된 레코드 양쪽 모두에 접근해야 하는 코드가 있다면 **`조인`** 이 필수이고, DB에서 적은 수의 레코드만 질의할 경우 **`색인`** 을 쓰는게 효율적임
- 그러나 맵리듀스에선 색인 개념이 없으며 입력 파일 전체를 읽는 **`전체 테이블 스캔(full table scan)`** 을 사용함
  - 일괄 처리 맥락에서 조인은 데이터셋 내 모든 연관 관계를 다룬다는 뜻임
  - 즉, **모든 사용자 데이터를 동시에 처리** 함

- **`사용자 활동 이벤트 분석 예제`**
  - 웹사이트의 로그인 사용자 이벤트 로그와 사용자 DB를 연관시키는 예제
  - 가장 단순한 조인 구현 방법
    - 이벤트 로그를 훑으면서 모든 사용자 ID마다 사용자 DB에 질의 보내기
    - 단점
      - DB 통신의 왕복 시간으로 **처리량이 제한**되고 **DB가 과부하**되기 쉽다. 즉 성능이 나쁘다.
      - 원격 DB에 질의하면 **일괄처리가 비결정적**이 된다. DB 데이터는 도중에 변경될 수 있기 때문

  - 더 좋은 방법 :
    - DB의 사본을 가져와 이벤트 로그와 함께 HDFS에 같이 저장하고
    - 이를 맵리듀스를 사용해 연관된 레코드끼리 모두 모아 효율적으로 일괄처리하는 것

- **`정렬 병합 조인 (sort-merge join)`**
  - 매퍼가 **키로 정렬된 출력**을 생산하고, 리듀서는 **정렬된 레코드 목록을 병합**하는 방식으로 조인이 수행됨
  - 리듀서가 읽을 키-값 쌍을 정렬해 특정 값을 먼저 보도록 하는 방식을 **보조 정렬(secondary sort)** 이라 함

- **같은 곳으로 연관된 데이터 가져오기**
  - 병합 정렬 조인은 (사용자 ID로 조인 연산할 때) 필요한 데이터를 미리 한 곳으로 모아 리듀서를 사용자 ID 별로 한 번만 호출함
    - 처리량은 높게, 메모리 부담은 줄임
  - 맵리듀스는 데이터를 모으는 네트워크 통신 측면 과 데이터 처리 로직 을 분리함
    - 장비 다운 등 부분 실패가 있더라도 **`실패한 태스크를 확실하게 재시도`**
          
- **`그룹화`**
  - 조인 외에도 SQL의 `GROUP BY` 절과 같이 집계 연산(레코드 수 카운트, 값 더하기 등)을 위해 특정 키로 레코드를 그룹화할 수 있음
  - 맵리듀스 상에서 그룹화와 조인은 구현이 상당히 유사함
  - **`세션화(sessionization)`** : 사용자의 일련의 활동을 찾기 위해 세션별 활동을 분석할 때에도 그룹화를 사용함

- **`쏠림 다루기`**
  - 키 하나에 너무 많은 레코드가 쏠리면 맵리듀스가 제대로 작동하지 않는다.
    - 한 리듀서만 매우 많은 레코드를 처리하느라 느려짐, 마지막 리듀서가 완료될 때까지 후속 작업 딜레이
  - **핫 키(hot key)** : 불균형한 활성 데이터베이스 레코드 (또는 린치핀 객체)
  - **핫스팟** : 리듀서 한 개에 쏠림 현상이 발생하는 것
  - 핫스팟을 완화할 알고리즘들
    - Pig의 **쏠린 조인(skewed join)** 메서드, Crunch의 **공유 조인(shared join)** 메서드
    - Hive는 **맵 사이드 조인(map-side join)** 을 사용해 처리
  - 핫 키로 레코드를 그룹화, 집계하는 작업은 **두 단계** 로 수행
    - 레코드를 임의의 리듀서로 보내고, 각 리듀서는 핫 키 레코드의 일부를 그룹화, 집계하여 **간소화된 집계 결과를 출력**
    - 두 번째 단계에선 첫 단계의 **모든 리듀서 출력을 결합해 하나의 값으로**

### 맵 사이드 조인
- 앞의 **`리듀스 사이드 조인(reduce-side join)`** 은 데이터를 정렬 후 리듀서로 복사한 뒤, 리듀서 입력을 병합하는 과정에서 드는 **비용이 크다** 는 단점이 있음
- 반면 **`맵사이드 조인(map-side join)`** 은 리듀서도 정렬 작업도 필요 없는 축소된 맵리듀스 작업으로, 조인을 더 빠르게 수행할 수 있음

- **`브로드캐스트 해시 조인`**
  - 작은 데이터셋과 매우 큰 데이터셋을 조인하는 경우 적용 가능
  - 모든 매퍼는 작은 데이터셋 전체를 **인메모리 해시 테이블** 에 적재함
  - 즉, 작은 입력을 큰 입력의 모든 파티션에 **브로드캐스트** 함
  - 인메모리 해시 테이블 대신 **로컬 디스크에 읽기 전용 색인** 으로 저장할 수도 있음
      - 데이터셋 전체가 메모리에 들어오지 않을 경우에도 빠르게 임의 접근이 가능한 유용한 방법

- **`파티션 해시 조인`**
  - **해시 조인 접근법** 을 각 **파티션에 독립적** 으로 적용할 수 있음
  - 조인할 두 데이터셋을 조인 키(사용자ID) 를 기준으로 파티셔닝하여 각 매퍼에 재배열할 수 있음
      - ex) 3번 매퍼가 ID가 3으로 끝나는 사용자들을 해시 테이블에 올리고, ID가 3으로 끝나는 활동 이벤트를 모두 스캔하는 식
  - 조인할 레코드 모두가 같은 번호의 파티션에 위치하게 됨
  - 각 매퍼의 **해시 테이블에 적재할 데이터 양을 줄일 수 있다** 는 장점이 있음
  - Hive에서는 **버킷 맵 조인(bucketed map join)** 이라 함

- **`맵 사이드 병합 조인`**
  - 입력 데이터셋이 이미 같은 키로 **파티셔닝** 및 **정렬**됐다면 **맵 사이드에서 병합 조인**을 수행할 수 있음
    - 매퍼도 리듀서와 동일하게 병합 연산을 수행할 수 있음
  - 보통 **선행 맵리듀스 작업**이 이미 입력 데이터셋을 **파티셔닝하고 정렬했을 때** 가능함
  - 리듀스 사이드가 아닌 맵 사이드에서 병합 정렬이 유용할 때가 있음
    - 파티셔닝, 정렬된 데이터셋이 바로 조인 외 다른 용도로 필요한 경우 등.

- **`맵 사이드 조인을 사용하는 맵리듀스 워크플로`**
  - MR 조인의 출력을 하위 작업에서 입력으로 사용할 때, 맵 사이드 조인과 리듀스 사이드 조인은 출력 구조가 다름
    - **리듀스 사이드 조인** : **조인 키** 로 파티셔닝, 정렬해서 출력
    - **맵 사이드 조인** : **큰 입력과 동일한 방법** 으로 파티셔닝, 정렬
      - 큰 조인 입력의 **파일 블록마다 맵 태스크가 실행** 되기 때문
  - 하둡 생태계에서 데이터셋 파티셔닝 관련 메타데이터 관리
    - **HCatalog** 나 **Hive 메타스토어** 를 사용하여 관리

### 일괄 처리 워크플로의 출력
- 맵리듀스와 같은 일괄처리의 결과는 어떻게 나오고 수행하는 이유는 무엇인가?
  - **`OLTP 질의`** : 색인을 사용해 소량의 레코드만 특정 키로 조회하는 것이 일반적
  - **`분석 질의`** : 대량의 레코드를 스캔해 그룹화, 집계 연산을 수행한 결과를 보고서 형태로 출력
  - **`일괄 처리`** : 트랜잭션 처리도, 분석도 아니다. 일괄 처리의 출력은 흔히 보고서가 아닌 다른 형태의 구조임

#### 검색 색인 구축
- 맵리듀스는 구글에서 검색 엔진에 사용할 색인을 구축하기 위해 처음 사용됐음
  - 루씬, 솔라용 색인을 구축하는데 맵리듀스는 훌륭한 방법임

- 일괄 처리는 색인을 구축하는데 매우 효율적임
  - 매퍼는 문서 집합을 파티셔닝하고, 리듀서는 파티션 별 색인을 구축, 색인 파일은 분산 파일 시스템에 저장

#### 일괄 처리의 출력으로 키-값을 저장
- 검색 색인 외에도 분류기와 같은 머신러닝 시스템을 구축하거나 추천 시스템을 구축하는데에도 일괄 처리는 유용함
- 데이터베이스 파일을 생성하는 작업도 굉장히 좋은 맵리듀스 활용법임
  - 매퍼로 키를 추출한 다음, 키로 정렬하는 과정은 색인을 만들 때에도 필요한 작업임
  - 키-값 저장소는 대부분 읽기 전용이므로 자료 구조가 단순함

#### 일괄 처리 출력에 관한 철학
- 앞서 살펴본 유닉스 철학은 데이터플로가 “프로그램이 입력을 읽어 출력을 내놓는다” 로 명확하며 과정에서 아무런 **부수 효과가 없음**.
- 맵리듀스 작업도 이런 철학과 마찬가지로 **입력을 불변으로 처리**하고, 외부 DB에 기록하는 등 **부수 효과를 피함**.
- 따라서 일괄 처리 작업은 좋은 성능을 내면서도 유지보수가 간단함
- 다만 입력 파싱 부분에서 유닉스와 하둡은 다름
  - 유닉스 도구는 타입이 없는 텍스트 파일을 가정, 처리하므로 입력을 파싱해야하는 부담이 있음
  - 하둡에선 구조화된 파일 형식을 사용하여 저수준 구문 변환 작업을 하지 않아도 됨(Avro, Parquet)

### 하둡과 분산 데이터베이스의 비교
- 맵리듀스 논문이 발간될 당시에 맵리듀스는 전혀 새로운 개념이 아니었음
- **`대규모 병렬 처리(massively parallel processing, MPP)`** 데이터베이스에서 이미 맵리듀스의 처리 알고리즘과 병렬 조인 알고리즘을 구현한 바 있음

- 맵리듀스와의 차이점
  - MPP 데이터베이스는 장비 클러스터에서 분석 SQL 질의를 병렬로 수행하는 것에 초점을 둠
  - 맵리듀스와 분산 파일 시스템의 조합은 아무 프로그램이나 실행할 수 있는 운영체제와 비슷한 속성을 제공함

#### 저장소의 다양성
- MPP 데이터베이스는 특화된 저장 형태로 데이터를 가져오기 때문에 가져오기 전 신중하게 모델링해야 함
  - 이는 중앙 집중식 데이터 수집을 느리게 만듬
- 반면 하둡과 같은 분산 파일시스템은 데이터가 어떤 형태라도 수집 가능하며, **데이터를 어떻게 처리할지(스키마 설계 등)는 덤프 이후에 고려** 함
  - 이런 속성 덕에 데이터 수집 속도가 올라감
  - **data lake** 또는 **enterprise data hub** 라고 알려진 개념
  - 현실에선 이상적인 데이터 모델을 만드는 것보다 **데이터를 빨리 사용 가능하게 만드는 것** 이 더 가치있음
  - **`초밥 원리(sushi principle)`** : 원시 데이터를 덤프하는 것 만으로도 여러 변환이 가능하다. “원시 데이터가 더 좋다.”
  - 데이터 생산자에게 데이터셋 표준 형식을 강제하는 대신, 소비자에게 데이터 해석의 부담을 이전시킴 → **`스키마 온 리드(schema-on-read) 접근법`**

#### 처리 모델의 다양성
- MPP 데이터베이스는 SQL과 같은 설계된 질의 유형으로 좋은 성능을 얻을 수 있으나, **SQL 질의만으로 모든 종류의 처리를 표현할 수 없음**
  - 머신러닝, 추천 시스템, 랭킹 모델을 탑재한 전문 검색 색인 구축 등

- 이러한 한계를 넘으려면 잔순한 질의 작성이 아닌 `코드 작성` 이 반드시 필요함
  - 맵리듀스와 HDFS를 사용하면 그 위에서 SQL 질의 실행 엔진도 사용할 수 있음(Apache Hive)
  - 물론 SQL 질의로 표현하기 어려운 다양한 일괄 처리 코드도 직접 작성할 수 있음
    
- 결정적으로 이런 다양한 처리 모델은 모두 **`단일 공유 클러스터 장비`**에서 실행됨
  - 여러 서비스들이 HDFS의 동일한 파일들에 접근 가능하므로 특정 처리를 위해 데이터를 다른 시스템으로 보낼 필요가 없음
  - 예를 들어, 임의 접근 가능한 OLTP DB인 HBase, MPP 스타일의 분석 데이터베이스인 Impala 모두 HDFS를 저장소로 사용함

#### 빈번하게 발생하는 결함을 줄이는 설계
- 맵리듀스와 MPP 데이터베이스는 아래 두 설계 방식에서 큰 차이점이 있음
  - 결함을 다루는 방식
  - 메모리, 디스크를 사용하는 방식

- **`맵리듀스는 실패를 잘 견딜 수 있게 설계되었음`**
  - **`개별 태스크 수준에서 작업을 재실행`** 하기 때문에 전체 작업은 영향을 받지 않음
  - 내결함성 확보와 큰 데이터셋 이슈로 데이터를 **`되도록 디스크에 기록`** 함
  - 많은 데이터를 처리하고 오랜 시간 수행하는 작업일 수록 태스크가 실패할 가능성이 높으므로, 맵리듀스는 대용량 작업에 적합함

- **`맵리듀스가 잦은 실패에도 견딜 수 있도록 설계된 이유`**
  - 하드웨어를 신뢰할 수 없기 때문이 아니라, 프로세스를 **`임의로 종료`** 할 수 있으면 연산 클러스터에서 **`자원 활용도를 높일 수 있기 때문`**
  - 구글에서 개발할 때 장시간 수행되는 맵리듀스 작업은 언제든 (효율적인 리소스 사용을 위해) **`선점`** 될 수 있도록 염두에 뒀기 때문
  - 실제로 하둡 YARN의 **`CapacityScheduler`** 는 다른 큐 간의 리소스 선점을 지원함
    - 단, YARN, Mesos, K8S를 작성할 당시엔 우선순위 선점 방식은 지원하지 않았다고 함

## 맵리듀스를 넘어
- 맵리듀스는 **`분산 파일 시스템 상에서 상당히 단순 명료하게 추상화된 모델`** 로, 무엇을 하고 있는지 이해하기 쉬움
- 맵리듀스를 직접 사용하는건 어렵기 때문에 맵리듀스 상에서 추상화된 다양한 고수준 프로그래밍 모델이 개발됐음(피그, 하이브, 캐스캐이딩, 크런치)
  - 맵리듀스 동작 원리를 이해하면 배우기 쉬고, 일괄 처리 태스크를 구현하기 편해짐
- 그러나 맵리듀스 모델 자체에도 문제가 있으며 이는 추상화 단계를 올린다고 해결되지 않음 → 일괄 처리 방법의 대안을 알아보자

### 중간 상태 구체화
- **`중간 상태(Intermediate state)`**
  - 맵리듀스에서 보통 한 작업의 출력은 다른 작업의 입력으로만 사용됨
  - 즉, 분산 파일 시스템 상의 파일들은 단순히 **`데이터를 다른 작업으로 옮기는 수단`** 에 불과하며 이를 **`중간 상태`** 라 함

- **`구체화(materialization)`**
  - 중간 상태를 파일로 기록하는 과정
  - 구체화는 요청이 왔을 때 계산을 시작하는 것이 아니라, **`미리 특정 연산 결과를 만들어 둔다는 의미`** (ad-hoc 쿼리와 반대)

- 맵리듀스의 중간 상태 구체화는 유닉스 파이프에 비해 여러 단점이 있음
  - 선행 작업이 완료되어야만 작업이 가능함
    - 즉, 모든 선행 작업이 종료될 때까지 전체 워크플로 수행시간이 지연되므로 느림
  - 각 맵리듀스 작업이 중복으로*매퍼를 갖음
    - 즉, 앞 작업의 리듀서의 일부가 될 수 있는 매퍼를 굳이 끼워넣어야 함
  - 중간 상태 파일도 분산 파일 시스템에 저장하므로 복제가 됨(임시 데이터에 대한 과잉조치)

#### 데이터플로 엔진
- 이러한 맵리듀스의 문제를 해결하기 위해 분산 일괄 처리 연산을 수행하는 새로운 엔진들이 개발되었음(Spark, Tez, Flink 등)
  - 이들의 공통점은 전체 워크플로를 독립된 하위 작업으로 나누지 않고, **`작업 하나로서 다룬다는 점`** 임

- **`데이터플로 엔진(dataflow engine)`**
  - 여러 처리 단계를 통해 데이터 흐름을 명시적으로 모델링하는 시스템
  - 단일 스레드에서 UDF를 반복 호출해 한 번에 레코드 한 개씩 처리
  - 입력을 파티셔닝해 병렬화
  - 한 함수의 출력을 다른 함수의 입력으로 사용
  - 맵과 리듀스를 번갈아 수행해야하는 맵리듀스와 달리, **`연산자(operator)`** 라는 함수들을 조합하는 **`유연한 방식`** 을 사용

- **`맵리듀스 모델과 비교했을 때 장점`**
  - 값비싼 작업(정렬 등)은 실제로 필요할 때만 수행함
  - 필요없는 맵 태스크는 없음
  - 워크플로에 모든 조인, 데이터 의존 관계가 명시되므로 지역성 최적화가 가능함
  - 연산자 간 중간 상태를 메모리나 로컬 디스크에 기록하여 HDFS에 기록할 때보다 I/O가 훨씬 적게 듬 (맵리듀스는 무조건 HDFS에 중간 상태 기록함)
  - 연산자들은 입력이 준비되는 즉시 실행을 시작할 수 있음 (앞 태스크가 완료되길 기다릴 필요 없음)
  - 워크플로가 하나의 작업으로 다뤄지므로, 새로운 연산자를 실행할 때마다 새로운 JVM을 구동할 필요 없이 이미 존재하는 JVM을 사용함

#### 내결함성
- 맵리듀스는 중간 상태를 HDFS에 구체화하는 것으로 내구성을 확보함
- 반면 Spark, Flink, Tez는 중간 상태를 HDFS에 쓰지 않음
  - 따라서 중간 상태가 유실되면 **`유효한 데이터로부터 계산을 다시 수행`** 해 복구함
  - Spark는 데이터의 조상을 추적하기 위해 **`RDD(resilient distributed dataset)`** 추상화를 사용함
  - Flink는 연산자 상태를 체크포인트로 남겨 실패한 연산자 수행을 재개할 수 있음

- 데이터를 재연산할 때는 해당 연산이 **`결정적`** 인지 여부가 중요함
  - 동일한 입력 데이터가 주어지면 항상 같은 출력을 생산하는가?
  - 전파되는 결함을 피하려면 연산자를 결정적으로 만들어야 함

#### 구체화에 대한 논의
- 대부분의 경우, 출력 또한 입력과 마찬가지로 HDFS에 기록하게 됨
- 입력은 불변히고 최종 출력은 완전히 교체하는 방식인 점에서 맵리듀스와 비슷함
- 맵리듀스보다 개선된 점은, 모든 중간 상태를 HDFS에 기록하는 수고를 덜어준다는 것

### 고수준 API와 언어
- 맵리듀스 작업을 직접 작성하는 일은 상당히 어렵기 때문에 하이브 등 고수준 언어와 API가 인기를 끌었음

- 이런 데이터플로 API는 일반적으로 **`관계형 스타일의 빌딩 블록을 사용해 연산을 표현`** 함
  - 특정 필드의 값을 기준으로 데이터셋을 조인
  - 키로 튜플을 그룹화하고 특정 조건으로 필터링하거나 튜플을 카운트 등 집계

- 고수준 인터페이스의 장점
  - 코드를 적게 사용함
  - 대화식 사용도 지원 → 셸에서 코드 동작을 바로 확인할 수 있음
  - 사용자가 시스템을 생산성 높게 사용할 수 있음

#### 선언형 질의 언어로 전환
- 코드를 작성하는 방식에 비해 관계형 연산자로 조인을 나타내면 최적화가 가능하다는 장점이 있음
  - Hive, Spark, Flink는 비용 기반의 질의 최적화기를 내장하고 있음
  - 질의 최적화기는 중간 상태를 최소화하기 위해 조인 순서를 바꾸기도 함
    
- 위와 같은 최적화가 이뤄지려면 **`선언적`** 인 방법으로 조인을 지정해야 함

- 고수준 API에서 선언적 방식과 질의 최적화기를 가진다면 MPP 데이터베이스와 견줄만한 성능을 낼 수 있게 됨
  - 임의의 코드를 실행하고
  - 임의 형식의 데이터를 읽을 수 있는 확장성을 지니고
  - 일괄 처리 프레임워크의 장점인 유연성은 그대로 유지할 수 있음

## 정리
- 분산 일괄 처리 프레임워크가 해결해야 할 두 가지 중요한 문제
  - **파티셔닝**
    - 맵리듀스의 매퍼는 입력 파일 블록에 따라 파티셔닝되고 리듀서 파티션 개수는 사용자가 설정할 수 있음
    - 이 파티셔닝의 목적은 같은 키를 갖는 모든 레코드를 같은 장소(리듀서)로 모으는 것임

  - **내결함성**
    - 맵리듀스는 개별 태스크가 실패하더라도 전체 작업을 재수행하지 않도록 중간 상태를 빈번히 디스크에 기록함 (느린 이유)
    - 반면, 데이터플로 엔진은 메모리에 중간 상태를 유지함. 내결함성은 결정적인 구조와 RDD, 체크포인트 등으로 확보함

- 맵리듀스에서 사용하는 조인 알고리즘
  - **정렬 병합 조인** (리듀스 사이드 조인)
    - 기본적인 조인으로, 같은 키를 갖는 모든 레코드는 하나의 리듀서로 모임
    - 이 과정을 위해 매퍼가 조인 키를 추출하고 레코드는 파티셔닝, 정렬, 병합 과정을 거침
  - **브로드캐스트 해시 조인** (맵 사이드 조인)
    - 두 조인 데이터셋 중 상대적으로 작은 것을 파티셔닝하지 않고 해시 테이블에 통째로 적재하여 사용하는 방식
    - 조인 연산 시작 전에 각 매퍼가 작은 데이터셋을 브로드캐스트받고 자신의 해시 테이블에 올려놓고 조인에 사용함
  - **파티션 해시 조인** (맵 사이드 조인)
    - 조인 입력 두 개를 같은 방식으로 파티셔닝(키, 해시 함수, 파티션 수가 모두 동일하게 사용)
    - 해시 테이블 방식을 각 파티션 별로 독립적으로 사용할 수 있음
