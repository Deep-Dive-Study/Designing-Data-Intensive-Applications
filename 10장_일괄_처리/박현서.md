- 서비스 (온라인 시스템)
    - 클라이언트로부터 요청, 지시가 올 때까지 기다린다.
    - 요청이 들어오면 가능한 빨리 처리해 응답을 보낸다.
- **일괄 처리 시스템 (오프라인 시스템)**
    - 매우 큰 입력 데이터를 받아 데이터를 처리하는 작업을 수행하고 결과 데이터를 생산한다.
    - 주요 성능 지표로는 처리량이 대표적이다.
- 스트림 처리 시스템 (준실시간 시스템)
    - 온라인/오프라인 일괄 처리 사이의 어딘가에 있기에 준실시간 처리(near-real-time processing 또는 nearline processing)라 불린다.
    - 일괄 처리 시스템과 마찬가지로 요청에 대해 응답하지 않으며 입력 데이터를 소비하고 출력 데이터를 생산한다.
    - 입력 이벤트가 발생한 직후 바로 작동하여 일과 처리 시스템보다 지연 시간이 낮다.
- **맵리듀스(MapReduce)**
    - 일괄 처리 알고리즘인 맵리듀스는 “구글을 대규모로 확장 가능하게 만든 알고리즘”으로 불린다.
    - 맵리듀스는 그 이후에 하둡과 카우치DB, 몽고DB 등 다양한 오픈소스 시스템에서 구현됐다.
    - **맵리듀스는 데이터 웨어하우스용으로 개발했던 병렬 처리 시스템보다 상당히 저수준 프로그래밍 모델이다.** 하지만 범용 하드웨어만을 사용해 처리한 데이터 규모 면에서 상당히 진보했다.
- 일괄 처리
    - 1940년대, 1950년대에 비즈니스 데이터 처리에 널리 사용된 전기 기계식 IBM 카드 분류기와도 신기할 정도로 비슷하다.

# 1. 유닉스 도구로 일괄처리하기

## 1) 단순 로그 분석

로그를 처리하고 웹사이트 트래픽에 관한 보고서를 기본 유닉스 도구를 이용해 만들어보자.

```
cat /var/log/nginx/access.log
	awk '{print $7}'
	sort
	uniq -c
	sort -r -n
	head -n 5
```

1. 로그를 읽는다.
2. 줄마다 공백으로 분리, 요청 URL에 해당하는 7번째 필드만 출력한다.
3. 요청 URL을 알파벳 순으로 정렬한다. 특정 URL이 n번 요청되면 정렬 후에는 이 URL이 연속해서 n번 반복된다.
4. uniq 명령은 인접한 두 줄이 같은 지 확인해서 중복을 제거한다. -c는 중복 횟수를 함께 출력하는 옵션이다. 즉, 중복 없는 URL을 기준으로 각각 몇 번씩 요청이 있었는지를 확인한다.
5. -n 옵션을 사용해 매 줄 첫 번째로 나타나는 숫자, 즉 URL의 요청 수를 기준으로 다시 정렬한다. -r 옵션을 함께 사용해 내림차순으로 정렬한다.
6. 마지막으로 head 명령을 사용해 앞에서부터 5줄만(-n 5) 출력한다.

유닉스 도구에 익숙하지 않다면 앞에서 사용한 명령줄을 이해하기 쉽지 않다.

하지만 수 기가바이트의 로그 파일을 수 초 내로 처리할 수 있고, 필요에 따라 분석 방법을 수정하기도 쉽다.

### 1-1) 연쇄 명령 대 맞춤형 프로그램

유닉스 연쇄 명령 대신 같은 작업을 하는 간단한 프로그램을 작성할 수도 있다.

```
counts = Hash.new(0)

File.open('/var/log/nginx/access.log') do |file|
	file.each do |line|
		url = line.split[6]
		counts[url] += 1
	end
end

top5 = counts.map{|url, count| [count, url] }.sort.reverse[0...5]
top5.each{|count, url| puts "#{count} #{url}" }
```

**루비로 작성하면 유닉스 연쇄 파이프보다 간결하지는 않지만 더 읽기 쉽다.**

단지 취향의 문제도 있고, 표면적인 문법의 차이를 빼고도 두 가지 방법은 실행 흐름이 다르기도 하다.

대용량 파일을 분석해보면 차이가 확연히 드러난다.

### 1-2) 정렬 대 인메모리 집계

루비 스크립트는 URL 해시 테이블을 메모리에 유지한다.

해시 테이블에는 각 URL이 출현한 수를 매핑한다.

유닉스 파이프 라인 예제에는 이런 해시 테이블이 없고, 정렬된 목록에서 같은 URL이 반복해서 나타난다.

어떤 접근법이 더 좋은지는 URL이 얼마나 되느냐에 따라 다르다.

**적은 메모리를 필요로하면 인메모리 해시 테이블도 잘 작동한다.**

**하지만 허용 메모리보다 작업 세트가 크다면 정렬 접근법을 사용하는 것이 좋다.**

정렬 접근법은 디스크를 효율적으로 사용하고, 앞서 말했던 “SS테이블과 LSM트리”에서 설명한 원리와 다르지 않다. 데이터 청크를 메모리에서 정렬하고 청크를 세그먼트 파일로 디스크에 저장한다. 그 다음 각각 정렬된 세그먼트 파일 여러 개를 한 개의 큰 정렬 파일로 병합한다. 병합 정렬은 순차적 접근 패턴을 따르고 이 패턴은 디스크 상에서 좋은 성능을 낼 수 있다.

## 2) 유닉스 철학

연쇄 명령을 사용해 쉽게 로그 파일을 분석할 수 있었던 것은 유닉스의 핵심 설계 아이디어 중 하나이다.

유닉스 철학

- 각 프로그램이 한 가지 일만 하도록 작성하라. 새 작업을 하려면 기존 프로그램을 고쳐 새로운 “기능”을 추가하지 않고 새로운 프로그램을 작성하라.
- **모든 프로그램의 출력은 아직 알려지지 않은 다른 프로그램의 입력으로 쓰일 수 있다고 생각하라. 불필요한 정보로 출력이 너저분해서는 안된다. 입력 형식으로 엄격하게 열을 맞춘다거나 이진 형태를 사용하지 마라.**
- 소프트웨어를 빠르게 써볼 수 있게 설계하고 구축하라. 거슬리는 부분은 과감히 버리고 새로 구축하라.
- 프로그래밍 작업을 줄이려면 미숙한 도움보단 도구를 사용하라.

### 2-1) 동일 인터페이스

**유닉스에서의 인터페이스는 파일이다. 파일은 단지 순서대로 정렬된 바이트의 연속이다.** 파일은 이처럼 단순해서 같은 인터페이스로 파일시스템의 실제 파일, 프로세스 간의 통신 채널, TCP 연결을 나타내는 소켓 등 다른 여러 가지를 표현할 수 있다.

### 2-2) 로직과 연결의 분리

유닉스 도구의 다른 특징으로는 표준 입력(stdin)과 표준 출력(stdout)을 사용한다는 점이 있다.

**파이프는 한 프로세스의 stdout을 다른 프로세스의 stdin과 연결한다. 이때 중간 데이터를 디스크에 쓰지 않고 작은 인메모리 버퍼를 사용해 프로세스 간 데이터를 전송한다.**

프로그램은 입력이 어디서부터 들어오는지 출력이 어디로 나가는지 신경 쓰거나 알 필요조차 없다. 프로그램에서 입출력을 연결하는 부분을 분리하면 작은 도구로부터 큰 시스템을 구성하기가 훨씬 수월하다.

### 2-3) 투명성과 실험

유닉스 도구가 성공적인 이유 중 하나는 진행 사항을 파악하기가 쉽다는 것이다.

# 2. 맵리듀스와 분산 파일 시스템

맵리듀스는 유닉스 도구와 비슷한 면이 있지만 수천 대의 장비로 분산해서 실행이 가능하다는 점에서 차이가 있다.

유닉스 도구는 stdin, stdout을 입출력으로 사용하는데 **맵리듀스 작업은 분산 파일 시스템 상의 파일을 입력과 출력으로 사용**한다. 하둡 맵리듀스 구현에서 이 파일 시스템은 HDFS(Hadoop Distributed File System)라고 한다.

HDFS는 비공유 원칙을 기반으로 한다.

NAS(Network Attached Storage)와 SAN(Storage Area Network) 아키텍처에서 사용하는 공유 디스크 방식과는 반대다. 공유 디스크 저장소는 중앙 집중 저장 장치를 사용하는데 맞춤형 하드웨어를 사용하거나 파이버 채널과 같은 특별한 네트워크 인프라를 사용하기도 한다. 반면 **비공유 방식은 특별한 하드웨어가 필요없다. 일반적인 데이터센터 네트워크에 연결된 컴퓨터면 충분하다.**

HDFS는 각 장비에서 실행되는 데몬 프로세스로 구성된다.

데몬 프로세스는 다른 노드가 해당 장비에 저장된 파일에 접근 가능하게끔 네트워크 서비스를 제공한다. 데이터센터 내 모든 범용 장비에 디스크가 장착돼 있다고 가정한다. 네임노드(NameNode)라고 부르는 중앙 서버는 특정 파일 블록이 어떤 장비에 저장됐는지 추적한다. HDFS는 개념적으로 매우 큰 하나의 파일 시스템이고 데몬이 실행 중인 모든 장비의 디스크를 사용할 수 있다.

## 1) 맵리듀스 작업 실행하기

- **맵리듀스**
    - **HDFS 같은 분산 파일 시스템 위에서 대용량 데이터셋을 처리하는 코드를 작성하는 프로그래밍 프레임워크다.**
    - 맵리듀스 작업을 생성하려면 매퍼, 리듀서라는 두 가지 콜백 함수를 구현해야 한다.
- **매퍼(Mapper) : 적합한 형태로 데이터를 준비**
    - 매퍼는 모든 입력 레코드마다 한 번씩만 호출된다.
    - 매퍼는 입력 레코드로부터 키와 값을 추출하는 작업이다.
    - 각 입력으로부터 생성하는 키-값 쌍은 빈 쌍을 포함해 원하는 만큼 생성 가능하다.
    - 매퍼는 입력 레코드로부터 다음 레코드까지 상태를 유지하지 않기 때문에 각 레코드를 독립적으로 처리한다.
- **리듀서(Reducer) : 데이터를 가공**
    - 맵리듀스 프레임워크는 매퍼가 생산한 키-값 쌍을 받아 같은 키를 가진 레코드를 모은다.
    - 해당 값의 집합을 반복해 리듀서 함수를 호출한다.
    - 리듀서는 출력 레코드를 생산한다.

### 1-1) 맵리듀스의 분산 실행

**맵리듀스는 병렬로 수행하는 코드를 직접 작성하지 않고도 여러 장비에서 동시에 처리가 가능하다.**

![image](https://github.com/user-attachments/assets/a67bbe89-6492-4170-b7f7-5ed6ec9f40ef)


맵리듀스 작업의 병렬 실행은 파티셔닝을 기반으로한다.

작업 입력으로 HDFS상의 디렉터리를 일반적으로 사용하고, 입력 디렉터리 내 각 파일 또는 파일 블록을 독립된 맵 태스크에서 처리할 독립 파티션으로 간주한다.

매퍼 입력 파일의 복제본이 있는 장비에 RAM과 CPU에 여유가 충분하다면 맵리듀스 스케줄러가 입력 파일이 있는 장비에서 작업을 수행하려 한다. → 네트워크를 통해 입력 파일을 복사하는 부담과 네트워크 부하가 감소하고 지역성이 증가한다.

맵리듀스 프레임워크는 같은 키를 가진 모든 키-값 쌍을 같은 리듀서에서 처리하는 것을 보장하는데, 이를 결정하기 위해 키의 해시값을 사용한다. 키-값 쌍은 정렬돼야 해서 일반적인 정렬 알고리즘이 아니라 단계를 나누어 정렬을 수행한다. “SS테이블과 LSM트리”에서 사용되는 기술과 유사하다.

### 1-2) 맵리듀스 워크플로

맵리듀스 작업 하나로 해결할 수 있는 문제 범위는 제한적이다.

맵리듀스 작업을 연결해 워크플로(workflow)로 구성하는 방식은 일반적이다.

**맵리듀스 작업 하나의 출력을 다른 맵리듀스 작업의 입력으로 사용하는 방식**이다.

하둡 맵리듀스 프레임워크는 워크플로를 직접 제공하지 않는다. 때문에 맵리듀스 작업은 디렉터리 이름을 통해 암묵적으로 연결되는데 첫 번째 작업은 HDFS상에 지정된 디렉터리에 출력하도록 설정하고 두 번째 작업은 해당 디렉터리를 입력으로 사용하도록 설정해야 한다.

연결된 맵리듀스 작업은 유닉스 명령 파이프라인보다는 각 **명령의 출력을 임시 파일에 쓰고 다음 명령이 그 임시 파일로부터 입력을 읽는 방식**에 더 가깝다.

**일괄 처리 작업의 출력은 작업이 성공적으로 끝났을 때만 유효**하다. 워크플로 상에서 해당 작업의 입력 디렉터리를 생성하는 선행 작업이 완전히 끝나야만 다음 작업을 시작할 수 있다. 이러한 하둡 맵리듀스 작업 간 수행 의존성을 관리하기 위해 다양한 스케줄러가 개발됐다. (우지, 아즈카반, 루이지, 에어플로, 핀볼)

이런 스케줄러에는 많은 일괄 처리 작업의 집합을 유지보수할 때 유용한 관리 기능이 있다. 이런 복잡한 데이터 플로를 관리하기 위한 도구를 지원하는 일은 매우 중요하다.

## 2) 리듀스 사이드 조인과 그룹화

관계형 모델에서는 외래키, 문서 모델에서는 문서 참조, 그래프 모델에서는 간선이 있다. 연관된 레코드 양쪽 모두에 접근해야 하는 코드가 있다면 조인은 필수다. 비정규화 작업으로 조인을 줄일 수 있지만 일반적으로 완전히 제거하기는 어렵다.

데이터베이스에서 적은 수의 레코드만 관련된 질의를 실행한다면 데이터베이스는 일반적으로 색인을 사용해 관심 있는 레코드를 찾는다. 하지만 맵리듀스에는 적어도 일반적으로 이야기하는 색인 개념이 없다.

파일 집합이 입력으로 주어진 맵리듀스 작업이 있다면 맵리듀스 작업은 입력 파일 전체 내용을 읽는다. 색인 탐색에 비해 비용이 크지만 **분석 질의는 대량의 레코드를 대상으로 집계 연산을 하는 것이 일반적**이다. **이런 경우 입력 전체를 스캔하는 건 상당히 합리적**이다. 여러 장비에 걸쳐 병렬 처리가 가능한 경우는 특히 그렇다.

### 2-1) 사용자 활동 이벤트 분석 예제

![image](https://github.com/user-attachments/assets/55dd2907-c877-4bca-a538-a8b406314f9e)


왼쪽 그림 : 로그인 사용자가 웹사이트에서 활동한 이벤트 로그

오른쪽 그림 : 사용자 데이터베이스

이 분석 태스크는 사용자 활동과 사용자 프로필 정보를 연관시켜야 한다.

간단하게는 하나씩 활동 이벤트를 훑으면서 나오는 모든 사용자 ID마다 원격 서버에 있는 사용자 데이터베이스에 질의를 보내는 것이다. **하지만 성능이 나쁘고, 일괄 처리가 비결정적이다.** (원격 데이터베이스의 데이터가 변겨오딜 수 있기 때문이다.)

더 좋은 방법으로는 사용자 데이터베이스의 사본을 가져와 사용자 활동 이벤트 로그가 저장된 분산 파일 시스템에 넣는 방법이다. 이럴 경우 **사용자 데이터베이스와 사용자 활동 레코드가 같은 HDFS 상에 존재**하고 맵리듀스를 사용해 **연관된 레코드끼리 모두 같은 장소로 모아 효율적으로 처리**가 가능하다.

### 2-2) 정렬 병합 조인

매퍼는 입력 레코드로부터 키와 값을 추출하는 것이 목적이다.

맵리듀스 프레임워크에서 키로 매퍼의 출력을 파티셔닝해 키-값 쌍으로 정렬한다면 같은 사용자의 활동 이벤트와 사용자 레코드는 리듀서의 입력으로 서로 인접해서 들어간다.

![image](https://github.com/user-attachments/assets/ccfcd7a4-5fa5-4fff-b06f-b1283a90c8fe)


- 보조 정렬
    - 리듀서가 항상 사용자 데이터베이스를 먼저 보고 활동 이벤트를 시간 순으로 보게하는 식으로 맵리듀스에서 작업 레코드를 재배열하기도 한다. 이를 “보조 정렬”이라고 한다.
- 보조 정렬 후 실제 조인 로직
    - 리듀서 함수는 모든 사용자 ID당 한 번만 호출하고 보조 정렬 덕분에 첫 번째 값은 사용자 데이터베이스의 생년월일 레코드로 예상할 수 있다.
- 연령대별 클러스터링
    - 리듀서는 지역 변수에 생년월일을 저장하고, 그다음부터 같은 사용자 ID가 동일한 활동 이벤트를 순회해서 viewed-url, viewer-age-in-years의 쌍을 출력한다.
    - 맵리듀스 작업들이 각 URL마다 본 사람의 연령 분포를 계산하고 연령대별로 클러스터링할 수 있다.
- **정렬 병합 조인(sort-merge join)**
    - 리듀서는 특정 사용자 ID의 모든 레코드를 한 번에 처리하므로 한 번에 사용자 한 명의 레코드만 메모리에 유지하면 된다. → 네트워크로 요청을 보낼 필요가 없다.
    - 매퍼 출력이 키로 정렬된 후에 리듀서가 조인의 양측의 정렬된 레코드 목록을 병합하기 때문이고, 이를 “정렬 병합 조인”이라고 한다.

### 2-3) 같은 곳으로 연관된 데이터 가져오기

맵리듀스 프로그래밍 모델은 올바른 장비로 데이터를 모으는 연산의 물리적 네트워크 통신 측면과 받은 데이터를 처리하는 애플리케이션 로직을 분리한다. 맵리듀스는 모든 네트워크 통신을 직접 관리하기 떄문에 특정 장비가 죽는 것과 같이 부분적으로 실패가 발생해도 애플리케이션 코드 단에서 고민할 필요가 없다.

맵리듀스는 애플리케이션 로직에 영향이 가지 않게 실패한 태스크는 확실하게 재시도한다.

### 2-4) 그룹화

SQL에서 GROUP BY절과 같이 특정 키로 레코드를 그룹화하는 작업이 있다.

맵리듀스로 그룹화 연산을 간단하게 구현하는 방법은 그룹화 대상을 키로 하는 것이다. → 파티션 및 정렬 프로세스가 같은 키를 가진 모든 레코드를 같은 리듀서로 모은다.

사용자가 취한 일련의 활동을 찾을 때도 그룹화를 많이 사용한다. 사용자 요청을 받는 서버가 여러 개라면 활동 이벤트는 여러 서버로 분산돼 각각 다른 로그 파일ㄷ에 저장된다. 이때 세션 쿠기, 사용자 ID나 유사한 식별자를 그룹화 키로 사용해 특정 사용자 활동 이벤트를 모두 한 곳으로 모으면 세션화를 구현화할 수 있다.

### 2-5) 쏠림 다루기

- 린치핀 객체(linchpin object), 핫 키(hot key)
    - 키 하나에 너무 많은 데이터가 연관된다면 “같은 키를 가지는 모든 레코드를 같은 장소로 모으는” 패턴을 제대로 작동하지 않는다.

쏠림 현상이 생기면 모든 매퍼와 리듀서가 완전히 끝나야지만 맵리듀스가 끝나기에 가장 느린 리듀서가 작업을 완료할 때까지 후속 작업들은 시작하지 못한 채 기다려야 한다.

핫스팟 완화하는 여러가지 알고리즘이 있다.

첫 번째 예시로 피그(pig)를 봐보자.

피그에 쏠린 조인 메서드는 어떤 키가 핫 키인지 결정하기 위해 샘플링 작업을 수행한다. 실제 조인을 수행할 때 매퍼는 핫 키를 가진 레코드는 여러 리듀서 중 임의로 선택한 하나로 레코드를 보낸다. 키의 해시값을 기반으로 리듀서를 결정하는 관습적인 맵리듀스와는 반대다. → 이 기법은 핫 키를 여러 리듀서에 퍼뜨려서 처리하게 하는 방법이다. 다른 조인 입력을 여러 리듀서로 복제하는 비용이 들지만 병렬화 효과가 훨씬 크다.

두 번째 예시로 하이브(hive)도 있다.

테이블 메타데이터에 **핫키를 명시적으로 지정**하고 **핫 키와 관련된 레코드를 나머지 키와는 별도 파일에 저장**한다. 해당 테이블에서 조인할 때 핫 키를 가지는 레코드는 **맵 사이드 조인**을 사용해 처리한다. 핫 키로 레코드를 그룹화하고 집계하는 작업은 두 단계로 수행된다. 첫 번째 맵리듀스 단계는 레코드를 임의의 리듀서로 보낸다. 각 리듀서는 핫 키 레코드의 일부를 그룹화하고 키별로 집계해 간소화한 값을 출력한다. 두 번째 맵리듀스 작업은 첫 단계 모든 리듀서에서 나온 값을 키별로 모두 결합해 하나의 값으로 만든다.

## 3) 맵 사이드 조인

- 리듀스 사이드 조인(reduce-side join)
    - 실제 조인 로직을 리듀서에서 수행한다.
    - 장점 : 입력 데이터에 대한 특정 가정이 필요 없다.
    - 단점 : 정렬 후 리듀서로 복사한 뒤 리듀서 입력을 병합하는 모든 과정에 드는 비용이 상당히 크다. 맵리듀스 단계를 거칠 때 허용된 메모리 버퍼에 따라 데이터를 여러 번 디스크에 저장해야 할 수도 있다.
    - 매퍼 역할 : 매퍼는 각 입력 레코드에서 키와 값을 추출해 추출한 키-값 쌍을 리듀서 파티션으로 할당하고 키별로 정렬하는, 즉 입력 데이터를 준비하는 역할을 한다.
- 맵사이드 조인(map-side join)
    - 입력 데이터에 대해 특정 가정이 가능할 때 효율적일 수 있다.
    - 장점 : 축소된 맵리듀스 작업으로, 리듀서는 물론 정렬 작업도 없다.
    - 단점 : 입력 데이터에 대한 특정 가정이 필요하다.
    - 매퍼 역할 : 각 매퍼가 할 작업은 분산 파일 시스템에서 단순히 입력 파일 블럭 하나를 읽어 다시 해당 분산 파일 시스템에 출력하는 것이 전부이다.

### 3-1) 브로드캐스트 해시 조인

- 맵 사이드 조인
    - 작은 데이터셋과 매우 큰 데이터셋을 조인하는 경우에 간단하게 적용할 수 있다.
    - 작은 데이터셋 : 각 매퍼 메모리에 적재 가능할 정도로 충분히 작아야 한다.

**모든 매퍼는 작은 입력 전체를 메모리에 적재한다.**

**큰 입력의 파티션 하나를 담당하는 각 매퍼는 작은 입력 전체를 읽는 방법을 사용한다.**

### 3-2) 파티션 해시 조인

맵 사이드 조인의 입력을 파티셔닝한다면 해시 조인 접근법을 각 파티션에 독립적으로 적용할 수 있다.

예시) 3번 매퍼가 ID가 3으로 끝나는 모든 사용자를 해시 테이블에 올리고 ID가 3으로 끝나는 각 사용자 활동 이벤트 모두를 스캔하는 방식이다.

파티셔닝이 정상 작동했다면 조인할 레코드 모두가 같은 번호의 파티션에 위치한다.

각 매퍼는 각 입력 데이터셋 중 파티션 한 개만 읽어도 충분하다.

이 방법은 **각 매퍼의 해시 테이블에 적재해야할 테이터의 양을 줄일 수 있다는 장점**이 있다.

### 3-3) 맵 사이드 병합 조인

- 맵 사이드 병합 조인
    - 입력 데이터셋이 같은 방식으로 파티셔닝됐을 뿐 아니라 같은 키를 기준으로 정렬됐다면 변형된 맵 사이드 조인을 적용할 수 있다.
    - 수행 과정은 오름차순으로 양쪽 입력 모두를 점진적으로 읽어 키가 동일한 레코드를 맞춘다.

### 3-4) 맵 사이드 조인을 사용하는 맵리듀스 워크플로

**맵리듀스 조인의 출력을 하위 작업에서 입력으로 사용할 때 맵사이드 조인을 사용할지 리듀스 사이드 조인을 사용할지에 따라 출력 구조가 달라진다.**

- 리듀스 사이드 조인
    - 조인 키로 파티셔닝하고 정렬해서 출력
- 맵 사이드 조인
    - 큰 입력과 동일한 방법으로 파티셔닝하고 정렬

맵 사이드 조인을 수행하기 위해서는 크기, 정렬, 입력 데이터의 파티셔닝 같은 제약 사항이 따른다.

## 4) 일괄 처리 워크플로의 출력

일괄 처리는 트랜잭션 처리도 아니고 분석도 아니다.

일괄 처리는 입력 데이터셋 대부분을 스캔하는 것이 일반적이라 분석에 더 가깝다.

그러나 맵리듀스 작업의 워크플로는 분석 목적으로 사용하는 SQL 질의와는 다르다.

**일괄 처리의 출력은 흔히 보고서가 아닌 다른 형태의 구조**다.

### 4-1) 검색 색인 구축

맵리듀스는 구글 검색 엔진에 사용할 색인을 구축하기 위해 처음 사용됐었다. (현재는 x)

### 4-2) 일괄 처리의 출력으로 키-값을 저장

일괄 처리 작업의 출력은 일종의 데이터베이스가 된다.

외부에서 데이터를 가져오는 경우 문제가 있을 수 있어, 좋은 해결책으로 일괄 처리 작업 내부에 새로운 데이터베이스를 구축해 분산 파일 시스템의 작업 출력 디렉터리에 저장하는 방법이 있다.

### 4-3) 일괄 처리 출력에 관한 철학

유닉스 철학으로 데이터 플로가 ‘프로그램이 입력을 읽어 출력을 내놓는다’로 명확하다.

맵리듀스 작업도 마찬가지로 입력을 불변으로 처리하여 부수 효과를 피하기 때문에 일괄 처리 작업은 좋은 성능을 내면서 유지보수가 간단하다.

## 5) 하둡과 분산 데이터베이스의 비교

하둡은 유닉스 분산 버전과 비슷하다.

HDFS는 파일 시스템이고 맵리듀스는 특별한 방식으로 구현된 유닉스 프로세스다.

### 5-1) 저장소의 다양성

- 데이터베이스 : 특정 모델(관계형, 문서형, …)에 따라 데이터를 구조화한다.
- 분산 파일시스템의 파일 : 어떤 데이터 모델과 인코딩을 사용해서도 기록할 수 있는 연속된 바이트

MPP 데이터베이스는 데이터와 질의 형태를 신중하게 선행 모델링 해야한다.

하지만 하둡은 어떤 데이터 형태라도 상관없이 HDFS로 덤프할 수 있다.

현실에서는 이상적인 데이터 모델을 만들기보다 데이터를 빨리 사용 가능하게 만드는 것이 더 가치있다.

제약없는 데이터 덤핑은 데이터를 해석하는 부담을 이전시킨다.

데이터셋 생산자에게 데이터셋을 표준 형식으로 바꾸게끔 강제하는 대신 데이터 해석은 소비자가 해결할 문제가 된다.

### 5-2) 처리 모델의 다양성

SQL 질의만으로 모든 종류의 처리를 표현하지 못한다.

특정 애플리케이션에 한정되는 경우가 많아서 단순한 질의 작성이 아닌 코드 작성이 필요하다.

맵리듀스를 이용하면 엔지니어가 자신이 작성한 코드를 대용량 데이터셋 상에서 쉽게 실행할 수 있다.

HDFS와 맵리듀스가 있으면 그 위에 SQL 질의 실행 엔진을 구축할 수 있고, 하이브 프로젝트가 그런 역할을 한다.

### 5-3) 빈번하게 발생하는 결함을 줄이는 설계

- MPP
    - 질의 실행 중에 한 장비만 죽어도 대부분은 전체 질의가 중단된다.
    - 디스크에서 데이터를 읽는 비용을 피하기 위해 해시 조인 같은 방식을 사용해 메모리에 많은 데이터를 유지하는 것을 선호한다.
- 맵리듀스
    - 실패를 견딜 수 있다. → 개별 태스크 수준에서 작업을 재수행하기 때문에 전체 작업으로 보면 영향을 받지 않는다.
    - 데이터를 되도록 디스크에 기록하려고한다. → 내결함성 확보를 위해서 그리고 메모리에 올리기에 데이터셋이 너무 크다는 가정 때문이다.
- 맵리듀스 설계 환경
    - 태스크
        - 컨테이너를 사용해 CPU 코어, RAM, 디스크 공간 등의 자원을 할당받는다.
        - 모든 태스크에는 우선순위가 있다.
        - 우선순위가 높은 태스크에 더 많은 자원이 필요하면 우선순위가 낮은 태스크를 종료할 수도 있다.
    - 디스크 기록
        - 태스크 종료가 예상치 못하게 자주 발생하더라도 견딜 수 있게 설계됐다.
        - 즉, 하드웨어를 신뢰할 수 없기 때문이 아니라 프로세스를 임의로 종료할 수 있으면 연산 클러스터에서 자원 활용도를 높일 수 있기 때문이다.

# 3. 맵리듀스를 넘어

맵리듀스는 분산 파일 시스템 상에서 이해하기 쉬운 추상화된 모델이다.

맵리듀스 실행 모델 자체에도 문제가 있으며, 추상화 단계를 올린다고 해결되지 않는다.

일부 유형의 처리에 대해서는 성능 저하를 유발하기도 한다.

반면 맵리듀스는 매우 견고하고, 태스크가 자주 종료돼 신뢰할 수 없는 멀티 테넌트 시스템에서도 대규모 데이터를 처리하기 위해 맵리듀스를 사용할 수 있고 그 작업은 느릴지언정 성공한다. 반면 다른 특정 유형의 처리는 다른 도구들이 훨씬 빠를 때도 있다.

## 1) 중간 상태 구체화

- 구체화 (materialization)
    - 중간 상태를 파일로 기록하는 과정
    - 구체화는 요청이 왔을 때 계산을 시작하는 것이 아니라 미리 특정 연산 결과를 만들어 둔다는 의미다.
- **중간 상태를 구체화하는 맵리듀스 접근법의 단점** (유닉스 파이프와 비교했을 때)
    - 입력을 생성하는 모든 선행 작업이 완료돼야함.
    - 매퍼가 중복될 수 있음.
    - 분산 파일 시스템에서 중간 상태를 저장하는 것은 중간 상태 파일들이 여러 장비에 걸쳐 복제됐다는 의미로 임시데이터에게는 과잉 조치임.

### 1-1) 데이터플로 엔진

이러한 맵리듀스의 문제를 해결하기 위해 분산 일괄 처리 연산을 수행하는 엔진이 개발됐다.

설계 방식은 모두 다르지만 공통점으로는 전체 워크플로를 독립된 하위 작업이 아닌 하나의 작업으로서 다룬다는 것이다.

**맵리듀스와 달리 맵과 리듀스를 번갈아 수행하는 식의 규칙을 엄격하게 지킬 필요가 없다.**

대신 유연한 방법으로 함수들을 조합할 수 있다. 이런 함수를 연산자라고 부른다.

데이터플로 엔진은 연산자의 출력과 다른 연산자의 입력을 연결하는 여러 가지 선택지를 제공한다.

**데이터플로 엔진을 사용해서 맵리듀스 워크플로와 동일한 연산을 구현할 수 있고, 일반적으로 최적화로 인해 수행 속도가 훨씬 빠르다.**

### 1-2) 내결함성

- 중간상태 확보
    - 맵리듀스는 중간 상태를 모두 구체화하기 때문에 쉽게 내결함성을 확보한다. 태스크 실패 시에도 다른 장비에서 태스크를 재실행할 수 있고 파일 시스템으로부터 동일한 입력을 다시 읽을 수 있다.
- 중간상태 비확보
    - 스파크, 플링크, 테즈는 HDFS 중간 상태를 쓰지 않기 때문에 내결함성 확보를 위해 유효한 데이터로부터 계산을 다시 복구하거나, HDFS 상에 있는 원본 데이터를 사용한다.
    - 재계산이 가능하려면 주어진 데이터가 어떻게 연산되는지 추적해야하고, 해당 연산이 결정적인지 파악해야 한다.

### 1-3) 구체화에 대한 논의

맵리듀스는 명령의 출력을 임시 파일에 기록하는 것과 유사하다.

데이터플로 엔진은 유닉스 파이프와 매우 비슷하다.

데이터플로 엔진을 사용할 때 HDFS 상에 구체화된 데이터셋은 보통 작업의 입력과 최종 출력이다.

입력은 불변이고 최종 출력을 완전히 교체하는 방식은 맵리듀스와 비슷하다.

**맵리듀스보다 개선된 점은 사용자가 직접 모든 중간 상태를 파일 시스템에 기록하는 수고를 덜어준다는 점**이다.

## 2) 그래프와 반복 처리

많은 그래프 알고리즘이 한 번에 하나의 간선을 순회하는 방식으로 표현된다.

특정 정보를 전파하기 위해 정점 하나와 인접한 정점을 조인하면서 특정 조건에 도달할 때까지 반복한다.

그래프는 **분산 파일 시스템에 정점과 간선 목록이 포함된 파일의 형태로 저장할 수 있다.**

하지만 “완료할 때까지 반복"이라는 개념은 일반적인 맵리듀스로 표현할 수 없다.

맵리듀스는 데이터를 일회성으로만 처리하기 때문이다.

### 2-1) 프리글 처리 모델

- 벌크 동기식 병렬 (bulk synchronous parallel, BSP, 프리글모델) 연산 모델
    - 일괄 처리 그래프를 최적화하는 방법
    - ex. 아파치 그래프, 스파크 그래프 X(Graph X) API, 플링크 젤리 API, …

맵리듀스와 프리글 모델의 차이점은 반복해서 사용한 정점을 **메모리에 기억**하고 있다는 점이다.

### 2-2) 내결함성

정점이 서로 직접 질의하는 방식이 아니라 메시지 전달로 통신한다는 점은 프리글 작업 성능 향상에 도움을 준다.

네트워크 상의 문제로 메시지 유실, 중복, 지연돼도 프리글 구현상 메시지는 목적지 정점에서 정확히 한 번만 처리된다.

이런 내결함성은 반복이 끝나는 시점에 모든 정점의 상태를 주기적으로 체크포인트로 저장함으로써 보장된다.

## 3) 고수준 API와 언어

**데이터플로 API는 일반적으로 관계형 스타일의 빌딩 블록을 사용해 연산을 표현**한다.

내부적으로 연산들은 다양한 조인과 그룹화 알고리즘을 사용해 구현됐다.

이런 고수준 인터페이스는 코드를 적게 작성해도 되는 명백한 이점뿐만 아니라 **대화식 사용도 지원**한다.

**즉, 셸에서 분석 코드를 점진적으로 작성하고 코드가 어떻게 동작하는지 바로 확인할 수 있다.**

### 3-1) 선언형 질의 언어로 전환

간단한 필터링과 매핑 연산을 선언적 방법으로 표현한다면 질의 최적화기가 칼럼 기반 저장 레이아웃을 이용해 디스크에서 필요한 칼럼만 읽을 수 있다. 또한 내부 루프에서 데이터를 반복해서 CPU 캐시가 잘되게 하거나 함수 호출을 피하는 방식이 가능하다.

고수준 API에 선언적 측면을 포함하면서 실행 중에 이용할 수 있는 질의 최적화기를 가진다면 **일괄 처리 프레임워크는 MPP 데이터베이스와 한층 비슷해진다.**

### 3-2) 다양한 분야를 지원하기 위한 전문화

재사용 가능한 공통 빌딩 블록을 구현하는 일은 가치가 있다. 통계학, 수치 알고리즘은 분류, 추천 시스템과 같은 머신러닝 애플리케이션을 구축하는데 필요하다. 재사용 가능한 구현의 예로는 머하웃(Mahout)이 있다.
