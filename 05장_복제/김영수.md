# 5장 복제

복제란 네트워크로 연결된 여러 장비에 동일한 데이터의 복사본을 유지한다는 의미 

- ﻿﻿지리적으로 사용자와 가깝게 데이터를 유지해 지연 시간을 줄인다.
- ﻿﻿시스템의 일부에 장애가 발생해도 지속적으로 동작할 수 있게 해 가용성을 높인다.
- ﻿﻿읽기 질의를 제공하는 장비의 수를 확장해 읽기 처리량을 늘린다.

복제 자체는 어려운 문제가 아니지만, 복제된 데이터의 변경 처리가 어렵다.

분산 DB에서는 single-leader, multi-leader, leaderlss 복제 아키텍처를 이용한다.

트레이드 오프도 고려해야 하는데,

* 동기식 복제와 비동기식 복제 중 어떤것을 사용할지
* 잘못된 복제본은 어떻게 처리할지 등

## 리더와 팔로워

DB의 복사본을 저장하는 노드를 replica 라고 함.

여러 서버 중 하나를 leader(master or primary라고도 함)로 지정하고, 쓰기는 무조건 리더로 보낸다.

다른 복제 서버는 팔로워라고 하고 리더의 쓰기 저장소에 기록될때마다 데이터 변경사항을 replication log나 change stream의 일부로 팔로워에게 전송한다. 팔로워는 받아서 로컬 복사본을 갱신한다.

![image-20250414200006742](./images//image-20250414200006742.png)

이 방식은 pg, sql server, oracal 등에 사용되는 방식이다.

카프카나 rabbit MQ등에도 사용된다

### 동기식  vs 비동기식 복제

**제 대상 노드에 변경 내용을 언제 적용하느냐**에 따라 구분되는 개념

동기식 : 쓰기 작업이 모든 복제 대상 노드에 반영될 때까지 대기한 후, 클라이언트에 성공 응답을 반환

비동기식 : **쓰기 작업이 Primary에서 완료되면 즉시 클라이언트에 응답하고**, 나중에 복제 노드에 데이터를 전송



동기식 복제의 장점은 팔로워와 리더가 일관성있게 서로 최신 복사봉늘 가지는것을 보장함 

단점은 동기 팔로워 응답 지연시 쓰기가 처리될 수가 없을수도 있음. 블로킹 되기 때문에.

이런 이유로 모든 팔로워가 동기식이면 비현실적이다. 

팔로워 하나만 동기식으로 하고 나머지는 비동기식으로 둬서 성능을 좀 높여야 한다. 이것을 반동기식이라고 한다.



보통 리더 베이스 복제는 완전히 비동기식으로 구성한다. 리더가 잘못된경우 복구가 불가능하긴 하지만 모든 팔로워가 고장나더라도 리더는 계속 쓰기가 가능하다. 

### 새로운 팔로워 설정

복제 서버 수를 늘리거나 장애 노드 대체를 위해 새로운 팔로워 선출을 한다. 

이때 새 팔로워가 리더의 복제본을 100% 정확히 복사했는지 보장해야 하는데 어떻게 보장할까

개념적으로 팔로워 설정은 중단시간 없이 수행할 수 있따.

1. 리더디비의 스냅숏을 일정 시접에 가져온다. 이 시점에서 "어디까지 복제 로그를 기록했는지"도 같이 저장됨 (→ LSN, Binlog 위치)
2. 이 스냅숏을 새 팔로워 노드로 복사. 네트워크나 외장디스크로 통째로 복사.
3. 팔로워가 리더에 연결하여 이후 변경사항만 복제 스냅숏 이후 리더에서 발생한 **변경 로그들(WAL, binlog, oplog)** 을 따라잡기 시작함. (여기에 사용되는 위치 를 log sequence number라고 함)
4. 이 시점부터는 리더가 새로 처리하는 데이터를 실시간으로 같이 반영함.



### 노드 중단 처리

리더 기반 복제에서 고가용성을 달성하는 방법. (여러 이유로 중단될 수 있음. 장애, 계획된 유지보수 등)

#### 팔로워 장애 : 따라잡기 복구

각 팔로워가 리더로 부터 수신한 변경 데이터 로그를 로컬에 보관하고, 보관된 로그에서 처리한 마지막 트랜잭션을 알아낸 다음 그 이후 데이터들을 받는다.

### 리더 장애: 장애 복구

리더 장애 처리는 까다롭다. 팔로워중 하나를 리더로 승격해야 하고, 재설정도 필요하며, 다른 팔로워는 새 리더로부터 데이터 변경을 소비하라는것

다음과 같은 단계로 구성

1. 리더가 장애인지 판단하는것이 우선. 무엇이 문제인지를 모르기때문에 서로의 ping-pong 타임아웃을 장애 판단의 근거로 삼는다
2. 새 리더 선택. 선출 과정(투표 등)을 통해 이뤄지거나 controller 노드에 의해 새 리더가 임명 가능하다. 
3. 새 리더 사용을 위해 시스템을 재설정한다. 클라이언트는 새 쓰기 요청을 새 리더에게 라우팅 해야한다.

그러나 장애 복구 과정은 또다른 장애를 낳는 버그 투성이일 수 있다.

* 비동기 복제 사용시, 기존 팔로워였던 새 리더는 이전 쓰기 리더의 일부를 수신 못했을수도 있음. 즉 동기화가 안되어 있을수도 있음 -> 데이터 손실, 고가용성 확보 실패
* 쓰기 자체 폐기 방법을 사용하는것은 위험함. 데이터 불일치 일으킬 수 있음
* 특정 결함 시나리오에서 두 노드가 서로 자기들이 리더라고 믿을 수 있는 스플릿 브레인 현상 발생 가능. 둘다 쓰기 요청을 받으면 충돌이 일어날 수 있어 데이터 유실 및 오염 가능함. 두 노드가 둘다 죽을수도 있고.
* 리더가 죽었다고 판단하는 적절한 타임아웃을 얼마로 둬야하는지에 대한 문제. 긴 타임아웃은 확실해 지지만 복구까지 오랜 시간이 걸리며, 너무 짧으면 별것도 아닌것에 대해서 장애 판명이 나서 리밸런싱이 일어날 수 있음.

## 복제 로그 구현

리더 기반 복제는 내부적으로 어떻게 동작할까 

### 구문 기반 복제

모든 쓰기 statement을 기록하고 쓰기 구문 로그를 팔로워에게 전송한다. 그리고 각 팔로워는 SQL 구문을 파싱하고 실행한다.

이 방법은 합리적인거같지만 복제가 깨질 수 있는 사례가 있음

* NOW(), RAND() 같은 비결정적 함수 호출시 각 서버마다 다른 값 생성 가능
* auto increment 컬럼이나 DB에 있는 다른 데이터에 의존시, 각 복제 서버에서 정확히 같은 순서로 실행돼야 함.
* 부수 효과를 가진 프로시저, 트리거 등 부수 효과가 결정적이지 않으면 각 복제 서버에서 다른 결과가 나올 수 있음 

이런경우 -> 비 결정적 함수가 고정값을 반환하게끔 대처하거나, 애플리케이션에서 생성하여 넘기면 됌 

### 쓰기 전 로그 배송

db의 모든 쓰기를 포함하는 로그 자체를 복제 서버에 전송하여 그대로 처리하게 한다.

가장 큰 단점은 로그가 제일 저수준 데이터를 기록하며, db 엔진 버전이 다르다면 실행할 수 없는 케이스도 있다.

### 논리적(로우 기반) 로그 복제

복제와 저장소 엔진을 위해 다른 로그 형식을 사용해서 저장하는것.

rdb용 논리적 로그는 대개 로우 단위로 테이블에 쓰기를 기술한 레코드 열임

- ﻿﻿삽입된 로우의 로그는 모든 칼럼의 새로운 값을 포함한다.
- ﻿﻿삭제된 로우의 로그는 로우를 고유하게 식별하는 데 필요한 정보를 포함한다. 보통 이것은 기본키지만 테이블에 기본키가 없다면 모든 칼럼의 예전 값을 로깅해야 한다.
- ﻿﻿갱신된 로우의 로그는 로우를 고유하게 식별하는 데 필요한 정보와 모든 칼럼의 새로운 값(적어도 변경된 모든 칼럼의 새로 운 값)을 포함한다.

여러 로우 수정하는 트랜잭션은 여러 로그 레코드를 생성한 다음 트랜잭션이 커밋됐음을 레코드에 표시한다.

* mysql은 이 방식을 사용

이렇게 엔진과 분리하면 하위 호환성을 쉽게 유지 가능하고, 다른 버전의 db나 소프트웨어, 엔진을 사용할 수 있다.

이 기술을 Change Data Capture라 부른다 

* PG는 모든 변경 사항을 WAL에 먼저 기록함
  * 논리 복제 방식으로써 행 기반 데이터를 저장함 
* MySQL은 binLog에 변경 이록을 기록함
  * MySQL도 기본은 행 기반이고, 스테이트먼트 혹은 MIXED 설정 가능 
* Mongodb는 Oplog에 기록함
  * 변경 도큐먼트가 어떻게 되었는지 등 거의 로그 기반이라고 볼 수 있음 



## 복제 지연 문제

많은 팔로워들을 만들어 읽기 요청을 분산하는 read-scaling 아키텍처는 처리가 쉽지만, 비동기식 복제에서만 동작한다. 동기식으로 하면 쓰기가 매우 불안정 해짐.

팔로워가 뒤처지면 읽기 불일치가 발생할 수 있는데, 시간이 지나거나 쓰기가 멈추면 결국 일치하게 되고 이 효과를 최종 일관성이라고 한다.

이렇게 복제 지연 이 발생할 수 있는 사례는 뭐가 있을까

### 자신이 쓴 내용 읽기

![image-20250415153047488](./images//image-20250415153047488.png)

쓰기를 수행한 직후 봐야하는 데이터가 있을 시, 복제에서 읽으면 반영되지 않았을 수도 있다.

이경우 쓰기 후 읽기 일관성이 필요하다.  어떻게 구현할까?

* 사용자가 수정한 내용 읽을시 리더에서 읽고, 나머지는 팔로워에서 읽는다. 
  * 이 경우 질의하지 않고 무엇이 수정됐는지 알 수 있는 방법이 필요한데, 예를 들어 SNS에서 사용자 프로필 정보는 본인만 편집에 접근 가능하다는 것들을 이용한다
* 대부분 내용을 사용자가 편집할 가능성이 있따면, 대부분 리더에서 읽기때문에 효율적이지 않다. 이경우 다른 기준이 필요하며, 마지막 갱신 시간을 찾아서 마지막 갱신 후 1분 동안 리더에서 모든 읽기를 수행하는 방법도 있다.
* 클라이언트는 가장 최근 쓰기 타임스탬프를 기억할 수 있는데, 복제 서버가 최신 내용이 아닌 경우 다른 복제 서버가 읽기를 처리하거나 복제 서버가 따라잡을 떄까지 질의를 대기시킨다. -> 어려울듯?
* 여러 데이터센터에 복제가 분산될 수 있으므로, 리더가 제공해야 하는 요청은 리더가 포함된 데이터 센터로만 라우팅 한다

동일한 사용자가 여러 디바이스로 접근시에도 이 일관성이 깨질 수 있다.

* 이경우 사용자 마지막 갱신 타임 스탬프도 어려움. 이 정보를 다른 디바이스에서 알 수 없기 때문

### 단조 읽기(monotonic read)

시간이 거꾸로 흐르는 현상을 목격할 수 있음.

이경우는 사용자가 각기 다른 복제 서버에서 여러 읽기를 수행할 때 발생할 수 있음.

예를들어 같은 findById를 각기 다른 복제 서버에 두번 읽는 문제임 .

단조 읽기는 이걸 해결하는 방법.

각 사용자의 읽기가 항상 동일한 복제 서버에서 수행되게끔 하는 법이다. 

* 사용자 ID 기반 해시 라우팅을 하던가. 

### 일관된 순서로 읽기

a : 안녕하세요 현재는 12시 10분 1초

b: 안녕하세요 현재는 12시 10분 10초

순서대로 저장되었지만, 반대로 출력되는 경우가 있다. 복제 지연이 발생했기 때문

이경우 Consistent Prefix Read같은 보장이 필요하다. 

이는 샤딩된 db에서 발생하는 문제다. 이경우 서로 인과성이 있는 쓰기가 동일한 파티션에 기록되게 해야 한다. 

### 정리 - 복제 지연 시 발생 가능한 문제들



| 문제 유형                                | 설명                                             | 실제 사례                                       |
| ---------------------------------------- | ------------------------------------------------ | ----------------------------------------------- |
| 🧩 **데이터 불일치**                      | 팔로워에서 읽은 데이터가 최신 상태가 아님        | 팔로워에서 읽은 주문 상태가 여전히 `결제 전`    |
| ❗ **읽기 후 쓰기 오류**                  | 팔로워에서 읽고 처리한 데이터를 리더에 쓰면 충돌 | "삭제된 유저"를 다시 참조하는 API 응답          |
| 🧨 **일관성 깨짐 (Read Your Write 불가)** | 유저가 방금 저장한 글이 보이지 않음              | 유저가 댓글을 달았지만 새로고침하면 안 보임     |
| 🔁 **Failover 시 데이터 손실**            | 팔로워가 리더로 승격되었는데, 최신 데이터가 없음 | 리더 장애 후 일부 트랜잭션 유실됨               |
| 🐌 **비동기 작업 지연**                   | CDC, 로그 기반 이벤트 발행이 지연됨              | Kafka로 전달되는 이벤트가 몇 분 늦게 전송       |
| 🧪 **테스트 및 모니터링 왜곡**            | 로그 분석, A/B 테스트 데이터가 왜곡됨            | 사용자 행동 로그가 순서가 바뀌어 분석 오류 발생 |

