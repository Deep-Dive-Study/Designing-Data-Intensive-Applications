# 12장: 데이터 시스템의 미래

# 데이터 통합

책에서 반복되는 핵심 메시지 – 해결책은 하나가 아니다

- 이 책 전반의 주제는 **문제 해결을 위한 다양한 접근법과 그 트레이드오프**에 대한 설명.
- 예시:
  - 저장소: 로그 구조화 vs B-트리 vs 칼럼 지향 저장소 (3장)
  - 복제: 단일 리더 vs 복수 리더 vs 리더 없는 구조 (5장)
- **모든 상황에 완벽히 맞는 한 가지 해결책은 없다.**
- 소프트웨어 하나에 모든 기능을 담으려 하면, **구현이 복잡하고 약해지기 쉽다.**
- → 상황에 맞게 적절한 도구 조합을 선택해야 한다.

도구의 조합은 불가피하다.

실제 애플리케이션은 **데이터를 여러 방식으로 사용**한다.

예를 들어, OLTP 시스템 하나로는 검색, 분석, 캐싱, 추천, 알림 등을 모두 커버하기 어려움.

→ **여러 도구를 결합해서 사용하는 것**이 일반적이다.

## ___파생 데이터에 특화된 도구의 결합

예를들어 OLTP 시스템에서 전문 검색 색인을 통합하는 요구는 잦다. 

예: 데이터베이스 + 검색엔진

- `PostgreSQL` 같은 DB는 간단한 검색 기능을 제공하지만, 복잡한 검색에는 `Elasticsearch` 같은 도구가 필요함.
- 반대로 검색엔진은 **지속적인 데이터 저장**에는 적합하지 않음.
- → 두 시스템을 **함께 사용하는 것이 일반적**임.

추가 예: 분석, 캐시, ML, 알림 등등은?

- 데이터 웨어하우스, 일괄처리 시스템, 스트림 처리 시스템, 캐시 시스템, 머신러닝, 추천 시스템 등도 함께 사용함.
- 이들은 **원본 데이터에서 파생된 형태**로 활용됨.



특정 사람들이 "99%는 X만 있으면 된다"는 말은 **객관적 진실이 아닌, 개인 경험에 의존한 주장**일 가능성이 높다.

**데이터 활용 방식은 사람마다 다르며**, 필요도도 다르다.

#### 데이터 플로에 대한 추론

다른 데이터 접근 양식을 만족하기 위해, 같은 데이터를 여러 저장소에 사본으로 유지한다면 입력과 출력을 분명히 해야한다.

1. **데이터 복제는 흐름이 중요하다**
   - 데이터를 여러 저장소 시스템에 나눠 저장하는 경우, 반드시 **입력과 출력의 경계**를 분명히 해야 한다.
   - 어떤 시스템에서 데이터를 처음 기록하는지, 어떤 방식으로 파생되는지, 어떤 경로로 전파되는지 등을 명확히 정의해야 한다.
2. **안정적인 구조 예시: 변경 데이터 캡처(CDC)**
   - 데이터베이스에 먼저 데이터를 기록하고, 변경 사항을 **CDC(Change Data Capture)** 방식으로 감지해 검색 색인에 반영하면 일관성을 유지하기 쉬움.
   - 이때 검색 색인은 데이터베이스에서 파생된 구조이며, **DB만이 유일한 입력 경로**가 된다.
3. **문제 상황: 다중 쓰기 진입점**
   - 애플리케이션이 **검색 색인과 DB에 동시에 직접 데이터를 기록**하면, 쓰기 순서를 시스템마다 다르게 처리할 수 있어 **불일치 발생** 가능성이 높아진다.
   - 각각이 독립적으로 순서를 결정하면, **충돌과 영구적 불일치**가 생긴다.
4. **해결 방안: 단일 쓰기 진입점 + 순서 보장**
   - 모든 쓰기를 **하나의 중앙 시스템에 집중시켜 일관된 순서**로 처리하면, 이후 파생 데이터 생성도 안전하게 이루어질 수 있다.
   - 이 구조는 상태 기계 복제(State Machine Replication) 개념과 유사하다.
   - CDC든 이벤트 소싱(Event Sourcing)이든 **핵심은 순서 보장**이다.
5. **추가 장점: 결정성 + 멱등성**
   - 파생 시스템이 **이벤트 로그 기반으로 갱신**되면, 결과가 항상 동일하게 나오는 **결정적 처리**가 가능하다.
   - 동일한 요청이 여러 번 처리돼도 결과가 바뀌지 않는 **멱등성(idempotency)** 덕분에, 장애 복구나 재처리에 유리하다.

#### 파생 데이터 대 분산 트랜잭션

파생 데이터 시스템을 사용하는 방법은 분산 트랜잭션과 비교하면 어떨까?

**파생 데이터 vs 분산 트랜잭션**

1. **두 가지 접근법의 공통 목표**

파생 데이터 시스템과 분산 트랜잭션 시스템은 서로 다른 방식으로 **동일한 목적**을 추구한다. 바로 **여러 시스템 간의 일관성 유지**이다.

- 분산 트랜잭션은 **잠금(Lock)과 원자적 커밋(Atomic Commit)**을 통해 일관성을 보장한다.
- 파생 데이터 시스템은 **이벤트 로그와 변경 데이터 캡처(CDC)**를 기반으로, 순서를 결정하고 데이터를 반영한다.

2. **주요 차이점: 구현 방식**

| 구분        | 분산 트랜잭션                          | 파생 데이터 시스템                     |
| ----------- | -------------------------------------- | -------------------------------------- |
| 순서 결정   | 2단계 잠금(2PL)을 통한 동기적 처리     | 로그 기반으로 순서를 비동기적으로 결정 |
| 일관성 보장 | 원자적 커밋으로 단일 시점에서 반영     | 결정적 재시도 + 멱등성 기반으로 반영   |
| 선형성 보장 | O (자신이 쓴 내용을 즉시 읽을 수 있음) | X (기본적으로 비동기 갱신)             |



※ **선형성(linearizability)**: 어떤 클라이언트가 쓴 값을 바로 읽을 수 있는 성질

3. **현실적인 적용성과 한계**

- 분산 트랜잭션은 기능적으로 강력하지만, **비용이 크고 장애에 취약**하다.
  - 특히 **XA 프로토콜**(대표적인 분산 트랜잭션 표준)은 현실에서 성능 문제와 복잡성 문제로 인해 널리 사용되지 않는다.
- 실제로는 이종 시스템을 연결할 때 **분산 트랜잭션을 포기하고 로그 기반의 파생 시스템**을 사용하는 경우가 훨씬 많다.

4. **파생 시스템의 장점과 한계**

- 로그 기반 시스템은 **결정적이고 멱등적인 처리**가 가능하므로, 장애가 발생해도 데이터를 다시 처리할 수 있다.
- 하지만 기본적으로 **비동기 처리**이기 때문에,
  - 사용자가 기록한 값을 바로 읽는 기능(선형성)을 제공하지 못할 수 있다.
  - 이로 인해 사용자의 기대와 실제 데이터 상태가 잠시 어긋날 수 있다.

5. **최종적 일관성에 대한 현실적인 시각**

- 어떤 상황에서는 “최종적 일관성 eventually consistent이면 충분하다”는 주장도 있지만,
  - 이것이 **모든 사람에게 무조건 옳다고 강요하는 것은 적절하지 않다**.
  - 오히려 **일관성 지연을 어떻게 다룰지에 대한 설계 지침**이 필요하다.

#### 전체 순서화의 제약

이벤트의 전체 순서를 보장하는 것은 작고 단순한 시스템에서는 가능하지만, 규모가 커지거나 분산되면 구조적으로 어려워진다.

**제약 요약:**

- **단일 리더 병목**
  모든 이벤트가 하나의 리더 노드를 거쳐야 전체 순서를 보장할 수 있는데, 처리량이 증가하면 한계가 발생하고 결국 파티셔닝이 필요해진다.
  → 파티션 간에는 순서 보장이 어렵다.
- **지리적 분산 구조**
  여러 지역 데이터센터 간에는 네트워크 지연 때문에 동기화가 비효율적이므로, 각 센터에 리더를 두게 된다.
  → 서로 다른 데이터센터 간 이벤트는 순서가 정의되지 않는다.
- **마이크로서비스 구조**
  각 서비스가 독립적으로 상태를 관리하므로, 서비스 간 이벤트에도 순서를 정의할 수 없다.
- **클라이언트 주도 이벤트 처리**
  일부 앱은 서버 응답을 기다리지 않고 상태를 갱신하거나 오프라인에서도 동작한다.
  → 클라이언트와 서버가 보는 이벤트 순서가 달라질 수 있다.
- **이론적 한계**
  전체 순서 브로드캐스트는 **합의 알고리즘**과 동일하며, 대부분은 단일 노드 처리 전제를 기반으로 한다.
  → 분산 환경에서 확장 가능한 방식은 아직 연구 과제이다.

#### 인과성 획득을 위한 이벤트 순서화

모든 이벤트에 순서를 부여할 필요는 없고, **인과성이 있는 이벤트**에 대해서만 올바른 순서를 유지하면 된다.

**인과성 예시:**

- 친구 관계를 끊은 후 불만 메시지를 보내는 소셜미디어 상황
  → "친구 끊기" 이후에 "메시지 보내기"가 발생했음을 시스템이 인지하지 못하면, 잘못된 사용자에게 메시지 알림이 전달될 수 있다.

**해결 방안 요약:**

- **논리적 타임스탬프**
  실제 시간 대신 이벤트 발생 순서를 나타내는 번호 부여 → 전체 순서를 흉내 낼 수 있음.
- **인과적 참조 기록**
  사용자가 행동을 결정하기 전, 그때 본 상태를 이벤트로 기록하고, 이후 이벤트는 이를 참조 → 인과성 관계 명시.
- **충돌 해소 알고리즘 (예: CRDT)**
  이벤트 순서가 예상과 달라도 결과를 병합해 일관성을 유지.
  → 단, 외부 효과(알림 등)에는 한계가 있음.

**향후 방향:**
 전체 순서를 강제하지 않고도 **필요한 인과성만 효율적으로 추적하고 일관성을 유지하는 개발 패턴**이 앞으로 중요해질 것이다.

## 일괄 처리와 스트림 처리

데이터 통합의 목표 : 데이터를 올바른 장소에 올바른 형태로 두는것

이를 위해서 입력을 소비해 형태를 바꾸고 필터링하고 집계해 적절한 출력으로 기록해야함.

스파크라는 도구는 엔진에서 마이크로 일괄 처리 단위로 나누어 처리하고, 아파치 플링크는 스트림 처리 엔진 상에서 일괄 처리를 수행한다.

* 마이크로 일괄 처리는 홉핑 윈도우나 슬라이딩 윈도우를 구현하기에는 좋지 않다. 



## 데이터베이스 언번들링

데이터베이스와 운영체제(특히 유닉스)는 겉보기에는 매우 다른 시스템처럼 보이지만, 사실은 **모두 “정보 관리 시스템”**이라는 공통 목표를 갖고 있다.
 이 장에서는 이 두 시스템 철학의 차이를 탐구하며, 두 세계를 **조화롭게 결합할 가능성**을 모색한다.

* 언번들링(Unbundling)이란: 기존에 하나의 시스템에 통합되어 있던 기능들을 분리하여, 더 세밀하게 제어하거나 조합하는 접근
* **언번들링 데이터베이스(Unbundling the Database)**는 전통적인 **“올인원 데이터베이스 시스템”을 여러 독립적이고 잘 정의된 구성 요소로 분해해서 사용하는 접근 방식**

**언번들링은 여러 기능들을 하나의 소프트웨어 안에 감추지 않고, 각각을 독립적인 구성 요소로 분리하여 조합**하는 방식

예를 들면:

| 기능            | 언번들링 방식의 구현 예        |
| --------------- | ------------------------------ |
| 데이터 저장     | Amazon S3, HDFS, NoSQL DB      |
| 색인            | Elasticsearch, Typesense       |
| 변경 추적       | Kafka, Debezium (CDC)          |
| 구체화 뷰       | Materialize, Precomputed Cache |
| 트랜잭션/복제   | 이벤트 로그 기반 비동기 처리   |
| 질의 인터페이스 | Apache Drill, Trino, Presto    |



→ 각각의 기능을 “전문 도구”로 나눠서, 필요에 따라 연결해서 사용하는 구조

1. **정보 관리 시스템으로서의 공통점**

- 데이터베이스, 하둡, 운영체제(유닉스)는 모두 다음 기능을 수행한다:
  - 데이터를 저장하고,
  - 데이터를 처리하며,
  - 질의(Query)에 응답한다.
- 다루는 단위는 다르다:
  - 데이터베이스: 테이블의 로우, 문서, 그래프 정점 등 **논리적 단위**
  - 운영체제: 파일 시스템을 통해 **파일 단위**로 저장
- 하둡은 유닉스의 분산 버전처럼 작동하며, 유닉스와 DB 시스템은 본질적으로 유사한 추상화를 구현한다.

2. **실질적 차이점**

- **처리 단위와 효율성의 차이**
  - 운영체제는 수많은 작은 파일을 비효율적으로 처리하지만,
  - 데이터베이스는 수천만 개의 레코드를 문제없이 처리 가능
- **제공하는 추상화 수준의 차이**
  - **유닉스**: 저수준, 하드웨어와 가까운 추상화 (ex. 바이트 스트림, 파이프)
  - **관계형 데이터베이스**: 고수준 추상화 제공 (ex. SQL, 트랜잭션, 인덱스, 동시성 제어 등)



유닉스는 “얇은 추상화 = 간단함”

관계형 DB는 “풍부한 기능을 간단히 쓰게 해줌 = 간단함”

즉, **간단함의 정의 자체가 다르다**

운영체제와 데이터베이스는 서로 다른 철학을 기반으로 정보 관리를 수행하지만, 본질은 같다. 최근에는 이 두 철학을 조화롭게 통합하여 **유연성과 고급 기능을 함께 제공하려는 움직임**이 있다. 데이터베이스의 언번들링은 이런 조화의 실현 가능성을 보여주는 중요한 흐름이다.





언번들링의 장단점

장점

* **유연성**: 특정 기능만 교체하거나 확장 가능

  **전문화**: 각 도구가 한 가지 기능에 최적화되어 있음

  **분산과 확장성**: 기능을 독립적으로 수평 확장 가능

  **느슨한 결합(loose coupling)**: 장애 전파 최소화

  **팀 분리**: 각 도구를 다른 팀이 독립적으로 관리 가능

단점

* **복잡성 증가**: 구성 요소가 많아지고 연결 지점도 많아짐

  **운영 부담**: 설정, 배포, 모니터링이 어려움

  **통합 관리 부족**: 통일된 질의 언어나 트랜잭션이 없음

  **초기 구현 비용**: 전체 시스템을 수동으로 구성해야 함



### 데이터 저장소 기술 구성하기

데이터베이스가 제공하는 다양한 기능은 다음과 같다

* 보조 색인은 필드 값 기반으로 레코드를 효율적으로 검색
* 구체화 뷰는 질의 결과를 미리 연산한 캐시의 일종
* 복제 로그는 데이터의 복사본을 다른 노드에 최신 상태로 유지하는 기능
* 전문 검색 색인은 텍스트에서 키워드 검색을 가능하게 하는 기능



#### 색인 생성하기

**색인 생성 과정은 파생 데이터 시스템과 닮았다**

`CREATE INDEX` 명령의 내부 동작을 살펴보면 다음과 같다:

- 테이블의 일관된 스냅숏을 스캔하고 색인을 생성
- 이후 스냅숏 이후의 쓰기 변경 사항(백로그)을 적용
- 완성된 후에는 쓰기 시마다 색인을 함께 갱신

이 과정은 다음과 유사하다:

- **새로운 팔로워 복제본 만들기**
- **변경 데이터 캡처 초기화**
- **스트림 처리 기반 파생 데이터 갱신**

→ 즉, **색인 생성 자체가 데이터 재처리 및 파생 상태 유지의 한 예시**다.

#### 모든것의 메타 데이터베이스

이러한 관점에서 보면, 현대 기업의 데이터플로 전체는 하나의 대형 데이터베이스처럼 동작한다.

- 일괄 처리 / 스트림 처리 / ETL → 파생 데이터 시스템 유지
- 각 시스템은 마치 RDB의 **색인**, **트리거**, **구체화 뷰 유지 루틴**처럼 동작
- 단지 여러 팀이, 여러 인프라에서 나눠 관리할 뿐이다

서로 다른 저장소와 처리도구를 사용하지만, 하나의 응집된 시스템으로 구성할 수 있는 두가지 길이 있다.

**(1) 연합 데이터베이스 (읽기 중심)**

- 여러 저장소 시스템을 읽기 인터페이스 하나로 묶음
- 예: PostgreSQL의 Foreign Data Wrapper
- 특징:
  - 고수준 질의 언어 사용
  - 내부적으로는 다른 데이터 모델에 질의 번역
  - "읽기 전용 통합"에 유용

**(2) 언번들링 데이터베이스 (쓰기 중심)**

- 여러 시스템에 걸친 **쓰기 동기화**가 핵심
- 변경 사항을 **이벤트 로그** 기반으로 복제
- 각 기능(색인, 캐시, 분석 등)을 외부 도구로 분리해서 수행
- 유닉스 철학(작은 도구들 + 조합)과 유사

**왜 언번들링이 중요한가?**

- **분산 트랜잭션은 복잡하고 깨지기 쉬움**
- 이벤트 로그 기반 방식은:
  - 느슨한 결합(loose coupling) 제공
  - 장애 복구에 유리 (비동기 처리 + 버퍼링)
  - 구성 요소 간 독립성과 팀 간 분업을 가능하게 함
  - 멱등성, 이벤트 순서 보장 등으로 통합이 쉬움

→ 단일 통합 시스템보다 유연하고 탄탄한 확장성을 제공



결국 **미래는 언번들링 + 선언적 구성**을 고민해야 한다. 

- 아직은 언번들링된 시스템을 쉽게 구성할 수 있는 **“데이터 시스템용 셸”**이 부족하다
- 이상적인 미래 시스템은 다음을 지원해야 한다:
  - `mysql | elasticsearch` 와 같이 **데이터 흐름을 선언적으로 구성**
  - **색인**, **캐시**, **데이터 전환** 등을 코드 없이 연결
  - **미분 데이터플로(Differential Dataflow)**와 같은 기술로 구체화 뷰 자동 갱신

### 데이터플로 주변 애플리케이션 설계

데이터플로 기반 애플리케이션 구조란?

- **정의**: 전통적인 데이터베이스 중심 설계에서 벗어나, **데이터 흐름(Dataflow)** 중심으로 저장소와 처리 시스템을 조립하는 아키텍처.
- **별칭**: “언번들링(Unbundling) 데이터베이스”, “데이터베이스 인사이드 아웃”
- **영감**: 함수형 반응형 프로그래밍(FRP), 스프레드시트, 데이터플로 언어(Oz, Juttle), 논리형 언어(Bloom

#### 파생 함수로서의 애플리케이션 코드

- **파생 데이터셋**: 기존 데이터에서 변환, 요약, 분석을 통해 생성된 데이터
- **예시**
  - 보조 색인: 키 값 기준으로 정렬
  - 전문 검색 색인: 자연어 처리 결과를 인덱싱
  - 머신러닝 모델: 특징 추출 → 학습 → 예측
  - 캐시: UI 최적화용 데이터셋
- **사용자 정의 코드의 필요성**
  - CREATE INDEX 같은 내장 함수로는 한계가 있음
  - 앱 로직에 특화된 처리에는 **사용자 정의 함수(UDF)** 필요
  - 관계형 DB의 트리거/프로시저는 보조적 기능이며, 복잡한 앱 배포와는 잘 맞지 않음



애플리케이션 코드와 상태의 로직의 분리

- **현대적 구조**
  - 상태: 데이터베이스
  - 로직: 애플리케이션 서버 (컨테이너, 쿠버네티스 등에서 관리)
- **이유**
  - DB는 앱 코드 실행에 적합하지 않음 (의존성 관리, 모니터링, 외부 호출 등)
  - 상태는 지속성 있게, 로직은 유연하게 → 독립 배포 가능
- **비유**
  - 상태(state)와 정치(Church)는 분리해야 한다는 말처럼, 데이터와 코드도 분리



대부분 웹 애플리케이션은 상태 비저장 서비스로 배포되며, 어떤 서비스로도 요청이 라우팅 된다. 이렇게 되면 많은 요청을 처리할 수 있게 된다. 

* 하지만 상태는 반드시 어딘가에 존재해야 하며, 그 역할을 **데이터베이스가 담당**한다.



대부분의 프로그래밍 언어에서는 값이 변해도 자동 알림이 없다.

- 관찰자 패턴(Observer Pattern)은 있지만 언어 차원에서 내장되어 있지는 않다.
- 그래서 DB의 값이 변했는지 감지하려면 **폴링(주기적 조회)** 외에는 방법이 없었다.

하지만 최근에는 **변경 스트림(Change Stream) 구독**이라는 새로운 기능이 등장하고 있다.

- DB의 변경을 이벤트 스트림으로 받아 처리 가능

#### 데이터플로란 무엇인가?

- **정의**: 데이터 상태 변경과 그에 따른 애플리케이션 반응을 **명시적인 흐름(Flow)** 으로 모델링

- **관점 전환**:
  - 기존: DB는 무언가를 쓰고 읽는 수동적 저장소. DB는 수동적 공유 변수 (폴링 필요)
  - 데이터플로: DB 변경 = 이벤트 → 파생 상태 갱신

- 기존 구조: DB는 무언가를 쓰고 읽는 수동적 저장소
- 데이터플로 관점: 상태가 변경되면 → 그 변경이 이벤트로 흐르고 → 다른 파생 상태를 만든다
- 예: 색인 갱신, 캐시 갱신, 분석, 알림 발송 등은 **변경 이벤트의 연쇄 반응**으로 발생
- 이런 방식은 스트림 처리자, 메시지 시스템(Kafka 등), 액터 모델 등으로 구현 가능
- 단, 단순한 메시징 시스템과 달리 **파생 데이터 갱신에서는 순서와 내결함성이 중요**
  - 순서가 바뀌면 뷰들이 불일치 상태가 될 수 있다
  - 메시지 하나만 잃어도 전체 동기화가 무너질 수 있다
  - 그래서 메시징 시스템과 파생 데이터 갱신 시스템 모두 **신뢰성과 순서 보장**이 필요하다

**핵심 메시지**:
 파생 데이터는 단순 메시징이 아니라 **일관성 있고 내결함적인 데이터 흐름**을 구성해야 하며, 이를 위한 핵심 도구가 스트림 처리자다.

- **적용 방식**
  - 스트림 처리자와 메시징 시스템을 사용해 캐시, 색인, 모델 등을 파생
  - 정확한 순서 보장, 내결함성 보장 필요
  - 데이터 재처리와 이벤트 재전송을 대비한 설계 필요

#### 스트림 처리자와 서비스

최근 유행 애플리케이션은 개발 스타일은 rest api같은 동기 네트워크 요청을 통해 통신하는 서비스의 집합으로 나뉘는것. 각 마이크로 서비스마다 api를 호출하는 방식으로 이용된다. 

- 마이크로서비스는 기능 단위의 동기 API 호출 기반 구조다.

  - 기능별 API 호출
  - **동기식** 요청/응답
  - 팀 간 경계, 느슨한 결합 → 배포 유연함
    - 그러나 동기식 호출 → 장애 전파, 성능 한계

- 스트림 처리자는 비동기 이벤트 기반 구조다.

  - **비동기식** 이벤트 기반 연산

    상태 변경의 **시간적 흐름**을 반영

    높은 내결함성, 빠른 성능

  - 시스템 간 결합이 느슨하고, 장애에 강함

- 예시: 환율 정보를 이용한 구매 처리

  1. 마이크로서비스: 구매 시 환율 서비스에 동기 질의
  2. 데이터플로: 환율 스트림을 구독해 환율을 로컬에 유지, 구매 시 빠르게 참조

* 스트림 조인 : 스트리밍 환경에서 두 개 이상의 실시간 데이터 흐름을 결합하여 새로운 의미있는 정보를 만드는 연산.
  * 각 데이터가 시간에 따라 도착합니다.
    서로 다른 출처에서 들어오는 이벤트를 **결합해서 분석하거나 응답을 생성**해야 하는 상황이 많다.
    * `구매 이벤트 스트림` + `환율 갱신 스트림` → 외화 결제 금액 계산
    * `사용자 로그인 스트림` + `회원 정보 테이블` → 로그인 위치 이상 탐지
    * `상품 조회 이벤트` + `실시간 재고 스트림` → 구매 가능성 판단
  * **스트림 조인에서 중요한 점**
    - 이벤트가 발생한 **시점의 컨텍스트**가 중요 (예: 구매 시 환율)
    - 이벤트 재처리를 위해서는 과거 상태 복원 필요
      - 재처리나 보정 시에도 해당 시점의 상태를 되살릴 수 있어야 함. 
    - 스트림 테이블 조인 등에서 시간 의존성 관리 필수





- 결과적으로 데이터플로는
  - 더 빠르다 (네트워크 요청 없음)
  - 더 견고하다 (의존 서비스 장애 영향 없음)
  - 시간 의존 조인(stream-table join)에 유리하다



 데이터플로 기반 설계는 성능, 견고성, 유지보수성 측면에서 **마이크로서비스보다 더 나은 대안**이 될 수 있다.

### 파생 상태 관찰하기

**파생 상태(derived state)**는 원본 데이터로부터 계산해낸 2차적인 정보.

- 예: 검색 색인, 캐시, 집계 뷰, 예측 모델, 추천 결과 등.

이 상태는 일반적으로 **쓰기 경로(write path)**에서 계산되며, **읽기 경로(read path)**에서 사용된다.

**쓰기 경로 vs 읽기 경로**

| 항목          | 설명                                                         |
| ------------- | ------------------------------------------------------------ |
| **쓰기 경로** | 데이터를 수집하고, 변환하고, 파생 상태로 반영하는 경로. 즉, **미리 계산**하는 과정 |
| **읽기 경로** | 사용자가 요청할 때 파생 상태를 조회해 응답을 생성하는 경로. 즉, **요청 시점 계산 또는 조회** |

→ 함수형 프로그래밍 개념으로 보면:

- 쓰기 경로 = eager evaluation (조급한 평가)
- 읽기 경로 = lazy evaluation (느긋한 평가)

![image-20250706134158164](./images//image-20250706134158164.png)

* 검색 색인을 갱신하는 과정의 예 

### 구체화 뷰와 캐싱

전문 검색색인에서 쓰기 경로는 색인을 갱신하고, 읽기 경로는 색인을 사용해 키워드를 찾는다.

색인이 존재하지 않으면 모든 검색 질의는 풀스캔 해야하므로 읽기 경로의 작업이 늘어나게 된다.



**색인, 캐시, 구체화 뷰의 차이와 공통점**

- **색인(index)**: 데이터를 빠르게 찾기 위한 역방향 구조. 예: 검색 엔진 색인
- **캐시(cache)**: 자주 요청되는 질의 결과를 미리 저장해두는 구조
- **구체화 뷰(materialized view)**: 자주 사용되는 집계 결과를 테이블처럼 저장한 뷰

→ 이 셋 모두 **쓰기 경로와 읽기 경로 사이의 경계**에 존재
 → 핵심은 얼마나 **미리 계산해둘 것인가**에 대한 트레이드오프 결정

### 오프라인 대응 가능한 상태 저장 클라이언트

과거에는 브라우저/앱이 상태 비저장(stateless) 클라이언트였다.

이제는 **오프라인에서도 동작 가능한 클라이언트**, 즉 **로컬 저장소와 UI 상태를 유지**하는 방향으로 발전하고 있다.

* 모바일 장치는 때때로 느리거나 인터넷 연결이 불안정하기 때문에. 

그래서 모바일 앱에서 서버와 통신 없이도 대부분의 기능을 수행하고, 나중에 서버와 동기화하도록 한다. 

#### 상태 변경을 클라이언트한테 푸시하기

웹브라우저는 서버의 데이터 변경사항을 알지 못하기 때문에 상대적으로 오래된 데이터라 볼 수 있다.

때문에 많은 최신 프로토콜이 http의 기본 요청/응답 패턴을 벗어나 서버 전송 이벤트나 웹소켓을 이용하고 있다.

이렇게 되면 쓰기 경로가 최종 사용자까지 확장되며, 이후에는 서버가 보내주는 상태 변경 스트림만 따르면 된다.



### 종단간 이벤트 스트림

리액트, flux, redux 같은 상태 저장 클라이언트와 인터페이스 개발 도구는 내부적으로 사용자 입력을 표현하는 이벤트 스트림이나 서버 응답 스트림을 구독하는 방식을 사용해 클라이언트 상태를 관리한다. 

반응성있는 사용자 인터페이스를 지원하기 위해 노력하는것이며, 이런 데이터 시스템을 설계한다면 현재 상태를 단지 질의하는 방식이 아니라 변경 사항을 구독하는 방식을 염두에 둬야한다.



### 읽기도 이벤트다

지금까지는 `쓰기 = 이벤트`, `읽기 = 요청/응답`으로 구분했지만,

**읽기도 이벤트로 취급 가능**:

- 읽기 요청도 스트림으로 보내고
- 응답도 스트림으로 받는 방식

장점:

- 시스템 전반에서 **인과 관계 추적 가능**
- **읽기 요청 시점에 사용자가 어떤 상태를 봤는지**를 복원할 수 있음
- 분석, 디버깅, 감사(audit)에 유용


## 정확성을 목표로

여기서 말하는 정확성이란, 정확성은 시스템의 성질이 아니라 “전체 흐름”의 결과다

단지 상태 저장 시스템(예: 데이터베이스)이 **ACID 트랜잭션**을 지원한다고 해서 **데이터가 정확하게 유지되는 것이 아니다**.

**애플리케이션 레벨의 버그**나 **사용자의 재요청**, **네트워크 오류** 등은 트랜잭션이 커버할 수 없는 부분이다.

진짜 정확성을 위해서는 시스템의 **입력부터 출력까지 전 구간에 대한 고려**, 즉 **종단 간 설계(end-to-end design)**가 필요하다.

* 트랜잭션만으로는 충분하지 않다. 진짜 정확성을 원한다면 종단 간 사고(end-to-end thinking)가 필요하다.



- **무상태 vs. 상태 저장 시스템**
  - 무상태(stateless) 서비스는 장애 발생 시 재시작만으로 복구 가능.
  - 데이터베이스 같은 상태 저장(stateful) 시스템은 “영원히 기억”하도록 설계되어 한 번의 오류가 장기간 영향을 미칠 수 있어 더 신중한 설계·운용 필요.
- **ACID 트랜잭션의 한계**
  - 지난 40년간 원자성(A), 격리성(I), 지속성(D)이 정확성 보증의 핵심으로 여겨져 왔으나, 완화된(isolation) 수준이나 리더 없는 복제 같은 성능·확장성 기술이 시맨틱을 모호하게 만들기도 함.
  - “일관성(consistency)” 개념도 종종 잘못 정의되어 혼란을 초래.
- **현실과의 간극**
  - 특정 격리 수준·복제 설정이 실제 애플리케이션에 안전한지 판단하기 매우 어려움(실험 사례: Jepsen).
  - 단순 환경에서는 은근히 잘 돌아가도, 복잡한 조건 하에서는 미묘한 버그가 잇따라 발생.

### 데이터베이스에 관한 종단 간(end-to-end) 논증

애플리케이션이 직렬성 트랜잭션같은 데이터 시스템을 사용한다고 해서, 데이터 유실과 손상이 없을것이라는 보장은 없다.

* 정확하지 않은 데이터를 기록하거나, 지운다면 이것을 해결해주진 못함

이것은 **직렬성 트랜잭션만으로는 부족**하다. 

- 애플리케이션 버그로 잘못된 데이터를 쓰거나 삭제하면, 아무리 강력한 트랜잭션도 문제 해결 불가.
- 불변성(immutable append-only 로그)을 도입하면 “파괴적 실수”를 되돌리기 쉬워짐.

**정확히 한 번 실행(exactly-once)**을 이용해보자. 

- 메시지 처리시, 메시지 재시도 시 중복 처리(commit twice) 위험 → 과다 청구·통계 발생. 
- 중복처리는 두번 처리되는것이므로 데이터 손상의 한 형태임. 
- **해결책**:
  1. **멱등성(idempotence)**
     - 연산을 여러 번 수행해도 동일 결과.
     - 메타데이터(실행된 연산 ID 목록)·펜싱(fencing) 기법 필요.
  2. **2단계 커밋(2PC)**
     - TCP 연결·트랜잭션의 1:1 대응을 깨고, 장애 복구 시에도 코디네이터가 커밋 여부를 확인.
     - 그러나 여전히 네트워크 전체 구간(클라이언트↔서버)에서 중복 억제가 필요.

#### 중복 억제(deduplication)와 연산 식별자

TCP는 연결 단위에서 중복을 제거하지만, **HTTP POST → DB 트랜잭션**처럼 계층을 넘는 중복은 막지 못함

어떤 기능(예: 중복 억제, 무결성 보장)은 **시스템 내부(TCP, DB, 스트림 프로세서)에서는 완전히 보장할 수 없고**, **최종 애플리케이션이 책임져야 한다**.

* 예: 사용자가 전송했지만 응답을 못 받으면 다시 클릭해서 중복 실행
  * 즉 타임아웃 후 재연결하면 새로운 트랜잭션이므로, 멱등성이 없으면 중복 적용 위험.
* 또다른 예: 클라이언트가 결제 요청을 보냈지만 네트워크 타임아웃이 나서 응답을 못 받은 경우, 사용자가 다시 시도하면 **중복 결제** 발생 가능성.



구체적 해결책은 **구체적 해결책: 연산 ID + 불변성 + 멱등성**

- 연산에 고유 식별자(request_id)를 부여해서 중복 여부를 판단.
- DB 테이블에 `request_id`에 UNIQUE 제약을 걸고, 같은 요청이면 INSERT 실패시 커밋 무효화.
- 멱등한 연산으로 구성하거나, 불변성 기반의 이벤트 로그 설계 사용.

즉 **정확성은 트랜잭션만으로는 부족하다**

- 진정한 정확성은 다음을 모두 포함해야 한다:
  1. **중복 억제를 위한 연산 ID**
  2. **불변성 및 로그 중심 설계**
  3. **전체 요청 흐름의 추적 (클라이언트 → 서버 → DB까지의 종단 간 제어)**
- 종단 간 정확성 보장을 위한 추상화가 필요하지만, **아직 우리가 가진 추상화는 불충분하다.**

## 제약 조건 강제하기

requestId로 요청을 중복 방지하는것처럼, 다른 종류의 제약조건도 강제하여 막을 수 있다.

* 사용자명/이메일 유일성
* 동일 이름의 파일 중복 저장 방지
* 비행기/극장 좌석 중복 예약 방지
* 계좌 잔고 음수 방지
* 창고 재고 초과 판매 방지
* 회의실 중복 예약 방지



그러나 유일 제약 조건은 합의가 필요하다.

**유일성 충돌**은 동시에 들어오는 요청 간의 경쟁이므로 시스템이 어느 하나만 **수락(accept)**하고 나머지를 **거부(reject)**해야 함.

일반적인 해결법은 **단일 리더**에 요청을 모아 해당 리더가 결정하게 하는 것.

- 단점: 지리적으로 먼 리더, 장애 발생 시 대응 필요

리더 장애 → 다시 **합의 프로토콜** 필요

**파티셔닝**을 잘 하면 유일성 보장도 확장 가능:

- ex) 사용자명 → 해시값 기반으로 분할

단, **비동기 다중 마스터 복제**에서는 유일성 보장이 불가능

- 이유: 충돌이 발생해도 감지 불가 (유일하지 않게 됨)



로그 기반 메시징으로도 유일성을 처리할 수 있따.

* **로그 기반 언번들링 시스템**에서는 유일성 제약도 이 순서를 기반으로 보장 가능

처리 방식 (사용자명 예시)

1. 사용자명 요청 → 해시값으로 로그 파티션에 추가
2. 스트림 처리자:
   - 로그 메시지 순차 소비
   - 사용자명이 비어 있으면 → 사용 처리 후 성공 메시지
   - 이미 사용되고 있으면 → 거부 메시지
3. 사용자명을 요청한 클라이언트는 출력 스트림을 보고 결과 수신

> 핵심: **충돌 가능성이 있는 연산은 같은 파티션으로 보내 순차 처리**

- 다양한 제약 조건에 응용 가능 (ex. 중복 방지, 재고 검사 등)
- **확장성** 확보: 파티션 수 증가 가능
- **결정적 처리**: 중복 요청에도 항상 같은 결과 도출

### 다중 파티션 연산에서의 제약 조건 처리

그러면 여러 파티션에 나눠져있다면?

예제 : 요청 id를 포함하는 파티션, 받는사람 계좌를 포함하는 파티션, 보내는 사람 계좌를 포함하는 파티션

원자적 커밋이 없이 파티셔닝된 로그를 사용하면 정확성을 달성할 수 있다.

1. 계좌 A에서 B로 송금하는 요청은 클라에게 고유 id를 받아 요청 id를 기준으로 특정 로그 파티션에 추가
2. 스트림 처리자는 요청 로그를 읽고, 요청 메시지마다 보내는 사람 계좌 A의 출금 지시 메시지와 받는 사람 B의 입금 지시 메시지 두가지를 출력 스트림으로 방출.
3. 후속 처리자는 출금과 입금 지시 스트림을 소비해 요청 ID로 중복 제거 후 변경 내용을 계좌 잔고에 반영

> 핵심: **동시성 보장과 정확성을 위해 로그 기반 요청 순서를 지키고, 요청 ID로 중복 제거**

- **스트림 처리 장애 시**: 재시작해도 결정적 처리 → 중복 생성돼도 ID 기반 제거 가능
- 추가로, **출금 전용 스트림 처리자**를 사용해 잔고 확인 및 유효성 검증도 가능

>각 계좌 파티션 소비자는 메시지에 포함된 **요청 ID**를 보고
>
>- 처음 보는 ID라면 정상 처리
>- 이미 처리된 ID라면 무시(중복 억제)
>
>이 덕분에, 장애로 재실행되거나 네트워크 지연으로 메시지가 중복 도착해도 “한 번만” 실제 반영
>
>
>왜 원자적 커밋 없이 안전한가?
>
>
>출금과 입금 지시가 각각의 파티션에서 순서대로 처리되니, 파티션 간 일관성만 잘 관리하면 글로벌 순서(원자적 커밋) 없이도 “각 계좌에 정확히 한 번씩” 반영 가능.

## 적시성과 무결성

트랜잭션이 편리한 속성은 선형적으로 처리가 가능하다는것임.

트랜잭션이 보장하던것을 분리하여 생각해보자.

1. **선형성과 적시성의 차이**

- **트랜잭션은 선형성(linearizability)** 을 제공: 커밋된 이후의 쓰기는 **모든 독자에게 즉시 보임**.
- **스트림 기반 시스템**은 다름: 비동기적이므로, 메시지를 보냈다고 해서 바로 처리되지 않음.
- 그러나 소비자가 처리한 결과를 기다릴 수 있고, **유일성 검증 등에는 출력 스트림을 기다리는 방식**이 사용됨.
- 이 기다림은 **검사 결과 알림 목적일 뿐, 처리 정확성과 직접 관련은 없음.**

2. **일관성(consistency)은 두 속성의 결합**

> 대부분의 사람들이 "일관성"이라 부르는 개념은 **적시성 + 무결성**의 결합이다.
> 이 둘은 분리해서 생각할 수 있다.

적시성 (Timeliness)

- 시스템이 항상 **최신 상태를 사용자에게 보여주는 속성**
- 복제 지연처럼 일시적인 불일치는 발생 가능은 함. 하지만 (→ 결국 최신 상태 도달)
- **쓰기 후 읽기 일관성**도 적시성의 완화된 형태
- **CAP 정리**에서의 "일관성"은 바로 이 적시성 개념

무결성 (Integrity)

- **데이터에 오류가 없고, 손상되지 않음**을 의미
  - 누락, 모순, 잘못된 데이터 없음
  - 예: 색인(index)은 실제 데이터베이스 내용을 정확히 반영해야 함
- 무결성 위반한다는것은 → **영구적 불일치**, 명시적 수리 없이는 해결 불가
- 트랜잭션의 원자성, 지속성은 무결성 보존의 도구

 슬로건

* 적시성 위반 → "최종적 일관성"(Eventually Consistent)

* 무결성 위반 → "영구적 불일치"(Permanent Inconsistency)

적시성보다는 무결성이 더 중요하다.

- 적시성 부족 → **불편하거나 혼란스럽지만 수용 가능**
- 무결성 부족 → **시스템 실패로 이어짐**
  - 결제 내역 지연은 괜찮지만,
  - **잔고 계산이 틀리거나, 돈이 사라지면 파국**

### 데이터플로 시스템의 무결성 보장

스트림 기반 시스템의 특징

- 적시성을 보장하진 않지만, 무결성을 보장할 수 있음
- 트랜잭션 없이도 **정확히 한 번(or 결과적으로 한 번)** 처리 구현 가능

무결성 보장을 위한 핵심 메커니즘은 무엇이 있을까? 

| 메커니즘                | 설명                                                 |
| ----------------------- | ---------------------------------------------------- |
| 단일 메시지로 연산 표현 | 원자적 쓰기 가능, 이벤트 소싱과 잘 맞음              |
| 결정적 파생 함수        | 상태 업데이트 로직을 명확하게 표현 (ex. 함수형 처리) |
| 요청 ID 전달            | 모든 처리 단계에서 중복 억제 및 멱등성 확보          |
| 불변 메시지 + 재처리    | 오류 회복이 쉬움, 버그 대응력 ↑                      |

###  **느슨한 제약 조건 = 사과 기반 워크플로(Apology Workflow)**

유일성 제약 조건을 강제하려면 합의가 필요하다. 실제로 많은 애플리케이션은 완화된 유일성 개념을 사용한다.

즉 모든 제약조건을 쓰기 전에 검사할 필요는 없다.

예

* 사용자명 중복: 나중에 사과하고 다른 이름 요청

  좌석 중복 예약: 한쪽에 사과하고 다른 좌석 제공

  재고 부족: 일단 수락 → 배송 지연 안내 + 할인 제공

  초과 예약: 항공/호텔에서는 **고의로 초과 예약**하고 사후 보상

  계좌 초과 인출: 초과 수수료 부과 후 나중에 상환 요구

즉 

* 제약 조건 위반 → **사후 보상 가능하다면**, 반드시 적시하게 검사하지 않아도 됨

  사후 복구 비용이 **수용 가능하다면**, 제약 조건 강제는 선택 사항

### 코디네이션 회피 데이터 시스템

데이터플로 시스템은 코디네이션 없이도 무결성을 강력하게 보장할 수 있다.

* **모든 제약 조건이 강한 적시성과 코디네이션을 요구하지 않음**
  - 느슨한 제약 조건 + 사과 워크플로로 충분히 보완 가능



| 속성        | 전통적 트랜잭션 시스템 | 데이터플로 시스템                   |
| ----------- | ---------------------- | ----------------------------------- |
| 무결성      | ✅ 보장                 | ✅ 보장 가능 (중복 억제, ID 추적 등) |
| 적시성      | ✅ 보장                 | ❌ 보장 안됨 (but 수용 가능)         |
| 성능/확장성 | 낮음 (코디네이션 요구) | 높음 (코디네이션 회피)              |
| 가용성      | 노드 장애 시 제한      | 지역 간 장애에도 독립 운영 가능     |



사과 워크플로우와 코디네이션 비용의 트레이드 오프

**코디네이션과 제약 조건**은 '사과해야 할 일'의 수를 줄인다.

그러나 코디네이션 자체가 성능과 가용성을 저해할 수 있음.

**목표: 최소한의 사과와 중단이 있는 최적 지점 찾기**