# 1. 데이터 통합

복잡한 애플리케이션에서는 데이터를 여러 가지 다른 방법으로 사용한다.

데이터를 사용하는 모든 다른 상황에 적합한 소프트웨어가 있을 가능성은 낮다.

## 1) 파생 데이터에 특화된 도구의 결합

데이터를 다른 방식으로 표현하는 수가 늘어날수록 데이터 시스템을 통합하기 어렵다.

- 데이터베이스와 검색 색인, 분석 시스템에 해당 **데이터의 사본을 유지할 필요가 있다.**

데이터를 두르는 범위는 넓기에 조직 전체 데이터플로를 고려할 때 데이터 통합의 필요성이 명확해진다.

### 1-1) 데이터플로에 대한 추론

입력과 출력을 분명히 할 필요가 있다.

- **어디서** 데이터를 처음으로 기록하는지
- **어떤 표현형**이 **어떤 원본**에서 파생되는지
- 데이터를 모두 올바른 장소로 올바른 형식으로 **어떻게 넣는지**

파생 데이터 시스템은 이벤트 로그를 기반으로 갱신하면 결정적이고 멱등성을 지녀 결함에서 복구하기가 상당히 쉬워진다.

### 1-2) 파생 데이터 대 분산 트랜잭션

- 트랜잭션 시스템
    - 상호 배타적인 잠금을 사용해 쓰기 순서를 결정한다.
    - 선형성을 지원한다.
- 파생 데이터 시스템
    - 로그 기반으로 결정한다.
    - 대개 비동기로 갱신되기 때문에 기본적으로 동시간 갱신 보장을 하지 않는다.

**저자: 현재로서는 로그 기반 파생 데이터가 이종 데이터 시스템을 통합하는 가장 장래성 있는 접근법이라 생각한다.**

### 1-3) 전체 순서화의 제약

작은 시스템에서는 이벤트 로그의 순서 전체를 보장하는 것은 가능하다.

하지만 규모가 더 커지고 더 복잡한 작업부하가 발생함에 따라 한계가 드러난다.

- 단일 리더 노드를 통해야한다.
    - 전체 순서가 정해진 로그를 구축할 때 순서를 결정하기 위함
- **마이크로서비스**
    - 두 이벤트가 서로 다른 서비스에서 발생했다면 이들 사이에는 정해진 순서가 없다.

### 1-4) 인과성 획득을 위한 이벤트 순서화

- 이벤트 간 인과성이 없는 경우
    - 전체 순서가 정해지지 않아도 큰 문제가 아니다.
    - **동시에 발생한 이벤트는 임의로 순서를 정할 수 있기 때문이다.**

**인과성이 미묘하게 있는 경우 (해결하기 어렵다.)**

예시) 친구 삭제 후, 친구 전체 메시지 보냈을 때 → 삭제된 친구에게는 메시지 보내기 이벤트가 없어야 함.

## 2) 일괄 처리와 스트림 처리

### 2-1) 파생 상태 유지

- 일괄 처리
    - 함수형 프로그래밍 언어로 코드를 작성하지 않아도 함수형 특징을 가진다.
    - 결정적이고 출력이 입력에만 의존하며 명시적 출력 외에는 다른 부수 효과가 없는 순수 함수를 장려하며 입력을 불변으로 간주하고 출력은 추가 전용으로만 사용한다.

**입력과 출력을 잘 정의한 결정적 함수의 원리는 조직 내의 데이터플로 추론을 단순화한다.** 데이터 파이프라인은 함수형 애플리케이션 코드를 통해 한 시스템의 상태 변화를 밀어 넣고 그 결과를 파생 시스템에 적용한다.

### 2-2) 애플리케이션 발전을 위한 데이터 재처리

- 기존 데이터 재처리
    - 시스템을 유지보수하기 좋은 메커니즘
    - 새로운기능추가와 변경된 요구사항에 대응할 수 있음
- 재처리 없는 변경
    - 예로, 스키마를 재처리 없이 변경하는 경우에는 레코드에 새로운 필드를 추가하거나 새로운 타입의 레코드를 추가하는 등과 같이 간단한 작업으로만 제한된다.
- **재처리 있는 변경**
    - **재처리를 이용하면 새로운 요구사항을 더 잘 만족하기 위해 완전히 다른 모델로 데이터셋을 재구축할 수 있다.**
- 파생 뷰
    - 예로 파생 뷰를 사용하면 점진적 발전이 가능하다.
    - 이전 스키마와 새로운 스키마를 함께 유지해 같은 데이터를 기반으로 두 개의 독립적인 파생 뷰를 만들 수 있다. → 문제가 생겼을 때 쉽게 이전으로 되돌릴 수 있다.

### 2-3) 람다 아키텍처

- 람다 아키텍처
    - 입력 데이터를 불변 이벤트로서 증가, 데이터셋에 추가하는 방식으로 기록
    - 두 개의 다른 시스템을 병행해서 운용하기를 제안
        - **일괄 처리 시스템 + 스트림 처리 시스템**
    - 스트림 처리자
        - 이벤트를 소비해 근사 갱신을 뷰에 빠르게 반영
    - 일괄 처리자
        - 같은 이벤트 집합을 소비해 정확한 버전의 파생 뷰에 반영

람다 아키텍처는 데이터 시스템 설계를 향상시키는데 영향을 준 아이디어이다.

불변 이벤트 스트림에 대한 뷰를 파생하고, 필요할 때 이벤트를 재처리하는 원리를 보급함.

하지만 몇 가지 문제가 있을 수 있다.

- 일괄 처리와 스트림 처리 양쪽 프레임워크에서 같은 로직을 유지해야 하는 데 **상당한 노력**이 필요하다.
- 스트림 파이프라인과 일괄 처리 파이프라인은 분리된 출력을 생산하기 때문에 **사용자 요청에 대응하기 위해 출력을 병합**해야 한다.
- 전체 과거 데이터를 재처리할 수 있지만 대용량 데이터셋에서 자주 수행하면 **비용이 만만치 않다.**

### 2-4) 일괄 처리와 스트림 처리의 통합

최근에는 람다 아키텍처의 장점만 취할 수 있게 작업이 진행되고 있다.

한 시스템에서 일괄 처리 연산과 스트림 연산을 모두 구현하여 통합한다.

- 통합하기 위해 필요한 기능
    - 최근 이벤트 스트림을 다루는 처리 엔진에서 과거 이벤트를 재생하는 능력
    - 스트림 처리자에서 사용되는 정확히 한 번의 시멘틱
    - 처리 시간 기준이 아니라 이벤트 시간 기준으로 윈도우를 처리하는 도구

# 2. 데이터베이스 언번들링

추상화 수준에서 보면 데이터베이스, 하둡, 운영체제는 모두 같은 기능을 수행한다.

**하지만 실제로는 많은 차이가 있다.**

- 유닉스
    - 저수준 하드웨어 추상화를 프로그래머에게 제공하는 것을 목적으로 한다.
- 데이터베이스
    - 디스크 상의 자료 구조, 동시성, 장애 복구 등의 복잡성을 감추는 고수준 추상화를 애플리케이션 프로그래머에게 제공한다.

## 1) 데이터 저장소 기술 구성하기

데이터베이스에 내장된 기능과 일괄 처리와 스트림 처리로 구축하는 파생 데이터 시스템 사이에는 **유사점이 있다.**

### 1-1) 색인 생성하기

- 색인 생성 과정
    - 새 팔로워 복제본을 구축하는 과정과 유사
    - 스트림 시스템에서 변경 데이터 캡처의 예비 과정과 유사

### 1-2) 모든 것의 메타데이터베이스

모든 접근 패턴에 적합한 단일 데이터 모델이나 저장 형식이 없다고 가정하자.

서로 다른 저장소와 처리 도구를 사용하지만 하나의 응집된 시스템으로 구성할 수 있는 두 가지 길이 있을 수 있다.

- 연합 데이터베이스: 읽기를 통합
    - 하단 저장소 엔진과 처리 메서드를 통합해 질의하는 인터페이스를 제공한다.
- 언번들링 데이터베이스: 쓰기를 통합
    - 연합 데이터베이스
        - 다른 여러 시스템을 읽기 전용으로 질의하는 문제를 해결하지만 **쓰기에는 적합하지 않다.**
    - **언번들링 방식**
        - 저장소 시스템들을 신뢰성 있게 결합하기 쉽게 만드는 것(변경 데이터 캡처, 이벤트 로그를 통해)은 데이터베이스의 색인 유지 기능을 다른 기술에 걸친 쓰기를 동기화할 수 있는 방식으로 언번들링하는 방식과 유사하다.

### 1-3) 언번들링이 동작하게 만들기

다양한 구성 요소로부터 신뢰성, 확장성, 유지보수성을 고려한 시스템을 만든다는 측면에서 연합과 언번들링은 동전의 양면과 같다.

- 쓰기 동기화
    - 전통적인 접근법: 이종 저장소 시스템 간 분산 트랜잭션이 필요
    - 비동기 이벤트 로그: 데이터가 다른 기술 사이의 경계를 오간다면 멱등성을 기반으로 쓰기를 수행하는 편이 현실적일 수 있다.

멱등적 소비자가 사용하는 순서가 정해진 이벤트 로그가 표준 트랜잭션보다 더 단순한 추상화로 이종 시스템에 걸쳐 구현하기 쉽다. **로그 기반 통합의 큰 장점은 다양한 구성 요소 간의 느슨한 결합이다.**

- **장점1. 시스템 수준에서 비동기 이벤트 스트림 사용**
    - 전체 시스템이 개별 구성 요소의 장애나 성능 저하가 생겨도 잘 견디게 만들 수 있다.
- **장점2. 인적 수준에서 데이터 시스템 언번들링**
    - 소프트웨어 구성 요소와 서비스를 다른 팀에서 각자 개발하고 개선하고 독립적으로 유지보수 할 수 있다.

### 1-4) 언번들링 대 통합 시스템

언번들링이 미래에 사용될 방법이라고 가정해도 현재 형태의 데이터베이스를 대체하지는 못할 것이다.

- 언번들링의 목표
    - 특정 작업부하에 대한 성능 측면에서 개별 데이터베이스와 경쟁하는 것이 아니다.
    - 몇 개의 다른 데이터베이스를 결합해 단일 소프트웨어로 가능한 것보다 더 넓은 범위의 작업부하에 대해 좋은 성능을 달성하기 위함

### 1-5) 뭐가 빠졌지?

데이터 시스템을 구성하는 도구는 점점 좋아지고 있다.

하지만 유닉스 셸(단순하고 선언적인 방법으로 저장소와 처리 시스템을 구성하는 고수준 언어)과 동일한 언번들링된 데이터베이스가 존재하지 않는다.

## 2) 데이터플로 주변 애플리케이션 설계

- ~~데이터베이스 인사이드 아웃 접근법~~
    - ~~애플리케이션 코드로 특화된 저장소와 처리 시스템을 조립하는 언번들링 데이터베이스 접근법을 의미한다.~~

현대 데이터 시스템은 내결함성, 확장성, 지속성이 있어야 한다. 데이터 시스템은 시간이 흐름에 따라 이종 기술과 통합이 가능해야하고 존재하는 라이브러리와 서비스를 재사용 가능해야 한다.

### 2-1) 파생 함수로서의 애플리케이션 코드

데이터셋이 다른 데이터셋으로부터 파생될 때는 변환 함수 몇 가지를 거친다.

- 보조 색인
    - 단순한 변환 함수를 사용하는 파생 데이터셋의 일종
- 전문 검색 색인
    - 언어 감지, 단어 분리, 어간 추출, 기본형 처리, 철자 교정, 동의어 식별 등의 다양한 자연어 처리 함수를 적용한 다음 효율적인 조회를 위한 자료 구조를 구축
- 머신러닝 - 특징 엔지니어링
    - 다양한 특징 추출, 통계 분석 함수를 사용해 학습 데이터로부터 파새오딘 것으로 간주할 수 있다.
    - 모델에 새 입력 데이터를 적용하면 입력과 기존 모델에서 모델의 출력이 파생된다.
- 캐시
    - 사용자 인터페이스에 보여줄 형태의 데이터 집합을 포함하여 UI가 변한다면 캐시를 채우고 재구축하는 방법의 정의를 갱신해야 함

파생 데이터셋을 생성하는 함수가 보조 색인 생성 함수와 같은 비슷비슷한 표준 함수가 아니라면 사용자 정의 코드를 써서 애플리케이션에 특화된 측면들 다뤄야 한다.

### 2-2) 애플리케이션 코드와 상태의 분리

대부분의 웹 애플리케이션이 상태 비저장 서비스로 배포된다.

그러나 상태는 어디에는 있어야 하고 일반적으로 그곳은 데이터베이스가 된다.

전형적인 웹 애플리케이션 모델에서 데이터베이스는 네트워크를 통해 동기식으로 접근할 수 있는 변경 가능한 공유 변수와 같이 동작한다. 애플리케이션은 이 변수를 읽고 갱신할 수 있다. 데이터베이스는 이 변수를 지속성 있게 만들고 동시성 제어와 내결함성을 지원한다.

하지만 프로그래밍 언어에서 변경 가능한 변수의 변경을 구독할 수 없고 주기적으로 폴링하여 읽어볼 수 밖에 없다. (변경 데이터 구독은 이제 막 등장하기 시작한 기능이다.)

### 2-3) 데이터플로: 상태 변경과 애플리케이션 코드 간 상호작용

- 데이터플로 측면에서 애플리케이션을 생각
    - 애플리케이션 코드와 상태 관리 간의 관계를 재조정한다는 의미다.
- 상태 처리하는 코드 간의 상호작용과 협동
    - **애플리케이션 코드는 어떤 곳에서 상태 변화를 트리거해 다른 곳의 상태 변화에 응답한다.**
    - **비슷하게 데이터베이스에서 데이터 변경으로 트리거 발생, 색인된 테이블에 변경 사항을 반영하기 위해 보조 색인을 갱신할 때 비슷한 일이 발생한다.**

안정적인 메시지 순서화와 내결함성 있는 메시지 처리는 엄격한 요구사항이다.

하지만 분산 트랙잭션보다 훨씬 저렴하면서 탄탄한 운영을 가능하게 한다.

### 2-4) 스트림 처리자와 서비스

스트림 연산자로 데이터플로 시스템을 구성하는 것은 마이크로서비스 접근법과 유사하다.

하지만 마이크로서비스 접근법이 동기식 요청/응답 상호작용을 사용하지만 **스트림 연산자로 구성한 시스템은 단방향 비동기식 메시지 스트림을 사용한다.**

스트림 연산자는 네트워크 요청을 하지 않는 방향으로 다른 서비스 장애에도 잘 버틸 수 있다.

**하지만 시간 의존성이 있을 수 있으므로 이 부분은 잘 다뤄야 한다.**

→ 변경 스트림을 구독하거나 서비스에 질의를 하는 방식으로 처리

## 3) 파생 상태 관찰하기

- 쓰기 경로
    - 데이터플로 시스템에서 검색 색인, 구체화 뷰, 예측 모델과 같은 파생 데이터셋을 생성하고 최신 상태로 유지하는 과정을 의미한다.
- 읽기 경로
    - 파생 데이터를 생성하는 이유는 다시 질의할 가능성이 크기 때문이다. 이를 “읽기 경로”라 한다.

읽기 경로와 쓰기 경로를 종합하면 데이터를 수집하는 지점에서 데이터를 소비하는 지점까지 데이터의 모든 여정을 포함한다.

파생 데이터셋은 쓰기 경로와 읽기 경로가 만나는 장소다. **파생 데이터셋은 쓰기 기간에 필요한 작업의 양과 읽기 시간에 필요한 작업의 양 간에 트레이드 오프를 나타낸다.**

### 3-1) 구체화 뷰와 캐싱

- 전문 검색 색인
    - 색인이 있는 경우 → 쓰기 경로의 작업량은 늘지만 읽기 경로 작업이 준다.
    - 색인이 없는 경우 → 쓰기 경로의 작업량은 줄지만 읽기 경로 작업이 는다.
- 구체화 뷰(공통 질의 캐시)
    - 가장 공통적인 질의 집합의 검색 결과를 미리 계산하여 색인까지 가지 않고 빠르게 처리 가능하게 한다.
    - 일반적이지 않은 질의는 그대로 색인에서 처리한다.

읽기 경로와 쓰기 경로 사이에 가능한 경계에는 색인만 있는게 아니라 캐싱하거나 grep과 같이 스캔하는 것도 가능하다.

### 3-2) 오프라인 대응 가능한 상태 저장 클라이언트

인터넷 연결 요구 없이 같은 장치의 로컬 데이터베이스를 이용한다.

앱이 오프라인으로 작동한다면 사용자에게는 큰 이점이다.

→ 상태 비저장 클라이언트가 항상 중앙 서버와 통신하는게 아니라 최종 사용자 장치에 상태를 유지하는 쪽으로 나아가면 새로운 기회가 생길 수 있다.

### 3-3) 상태 변경을 클라이언트에게 푸시하기

서버 전송 이벤트, 웹소켓 등을 이용해서 서버와 TCP 연결을 유지하면서 서버가 주도적으로 메시지를 브라우저에 보내는 방식의 통신 채널을 제공하면 클라이언트 측 상태의 신선도를 높일 수 있다.

### 3-4) 종단 간 이벤트 스트림

서버가 상태 변경 이벤트를 클라이언트 측 이벤트 파이프라인으로 푸시하게끔 프로그래밍 모델을 확장하는 것은 자연스럽다.

쓰기 경로를 최종 사용자까지 확장하려면 근본적으로 시스템을 구축하는 방식을 재고할 필요가 있다.

요청/응답 상호작용 방식이 아닌 발행/구독 데이터플로 방식으로 변경해야 한다.

### 3-5) 읽기도 이벤트다

읽기 요청을 이벤트 스트림으로 표현하고 읽기 이벤트와 쓰기 이벤트 모두를 스트림 처리자를 통해 보내는 방법도 가능하다. 스트림 처리자는 읽기 결과를 출력 스트림으로 방출해 읽기 이벤트에 응답한다.

읽기 이벤트를 기록하면 잠재적으로 인과적 의존성과 시스템 전체의 데이터 출처를 추적할 수 있다는 이점이 있다. 하지만 추가적인 저장소가 필요하고 I/O 비용이 더 발생하기도 한다.

### 3-6) 다중 파티션 데이터 처리

스트림 처리자가 이미 제공하는 메시지 라우팅, 파티셔닝, 조인용 인프라를 이용하면 여러 파티션의 데이터 통합이 필요한 복잡한 질의를 분산 실행할 수 있는 가능성을 열어준다.

# 3. 정확성을 목표로

## 1) 데이터베이스에 관한 종단 간 논증

애플리케이션이 직렬성 트랜잭션 같은 비교적 강력한 안전성 속성을 지원하는 데이터 시스템을 사용한다고해서 해플리케이션에 데이터 유실과 손상이 없을 것이라는 보장은 없다.

### 1-1) 연산자의 정확히 한 번 실행

메시지 처리 중 뭔가 잘못된다면 포기하거나 재시도할 수 있다.

재시도한다면 첫 번째 시도에 성공했을 위험이 있음에도 실제로 성공했는지 확인할수 없기 떄문에 결국 메시지가 두 번 처리된다. → 두 번 처리되는 것은 데이터 손상의 한 형태다.

최종적으로 동일한 결과를 얻기 위해서는 계산 조정이 필요하다. → 접근법 중 하나로 연산을 “멱등”으로 만드는 것이다.

### 1-2) 중복 억제

스트림 처리 외에도 많은 곳에서 동일한 중복 제거 패턴이 발생한다.

- TCP 패킷
    - 패킷 일련번호를 사용해 수신자에게 올바른 순서로 패킷을 전달하고, 네트워크 상에서 패킷을 잃어버렸는지 중복됐는지 확인한다.

하지만 TCP 패킷 중복 억제는 TCP 연결 문맥 내에서만 동작한다.

클라이언트가 COMMIT을 전송한 후 네트워크가 불안정하여 끊기면 해당 트랜잭션이 커밋됐는지 알 수 없다.

그러므로 일반적인 중복제거 메커니즘은 도움이 되지 않는다.

### 1-3) 연산 식별자

여러 네트워크 통신 홉을 통과하는 연산을 멱등적으로 만들기 위해 데이터베이스가 제공하는 트랜잭션 메커니즘에 의존하는 것은 충분하지 않다. → **해당 요청의 종단 간 흐름을 생각할 필요가 있다.**

클라이언트 측에서 UUID와 같은 값으로 request_id를 보내고 DB에는 유일성 제약 조건을 걸면된다.

### 1-4) 종단 간 논증

- 문제 기능 (ex. 중복 억제 기능)
    - 통신 시스템의 종단점에 위치한 애플리케이션의 지식과 도움이 있어야 완벽하고 정확하게 구현 가능
    - 문제 기능을 통신 시스템 자체 기능으로 제공하는 것은 불가능하다.

### 1-5) 종단 간 사고를 데이터 시스템에 적용하기

애플리케이션 자체가 중복 억제와 같은 종단 간 대책을 갖출 필요가 있다.

- **저자: 아직 올바른 추상화를 발견하지 못한거 같다.**

## 2) 제약 조건 강제하기

유일성 제약 조건 외에도 다른 종류의 제약 조건도 사용 가능하다.

- 계좌 잔고 음수되지 않도록 보장하기
- 창고 재고분보다 더 많은 상품을 팔지 않도록 보장하기
- 회의실 예약이 겹치지 않게 보장하기

### 2-1) 유일성 제약 조건은 합의가 필요하다.

분산 설정으로 유일성 제약 조건을 강제하기 위해서는 합의가 필요하다.

일반적인 방법으로는 단일 노드를 리더로 만들고 해당 노드가 모든 결정을 하게끔 책임을 부여하는 것이다.

유일성 검사는 유일성이 필요한 값을 기준으로 파티셔닝하면 확장 가능하다.

하지만 비동기 다중 마스터 복제는 쓸 수 없다. → 다른 마스터에서 동시에, 충돌되는 쓰기를 받아들여서 값이 더 이상 유일하지 않을 수 있기 때문이다.

### 2-2) 로그 기반 메시지의 유일성

로그는 모든 소비자가 동일한 순서로 메시지를 보도록 보장한다. (전체 순서 브로드캐스트)

스트림 처리자는 단일 스레드 상에서 한 로그 파티션의 모든 메시지를 순차적으로 소비하므로 결정적으로 판결할 수 있다.

이러한 접근법의 근본 원리는 충돌이 발생할 수 있는 쓰기를 모두 같은 파티션으로 라우팅하고 순서대로 처리하는 것이다.

### 2-3) 다중 파티션 요청 처리

원자적으로 연산을 실행하는 것을 보장하는 작업이 여러 파티션일 때, 여러 데이터가 꼭 같은 파티션에 있어야할 이유는 없다. 원자밋 커밋 없이 파티셔닝된 로그를 사용하면 동등한 정확성을 달성할 수 있다.

1. 클라이언트에게 고유 요청 ID를 발급받아 계좌A → 계좌B로 송금하는 요청한다. 요청 ID를 기준으로 특정 로그 파티션에 추가된다.
2. 스트림 처리자는 요청 로그를 읽는다.
    1. 사람 계좌A의 출금 지시 메시지를 출력 스트림으로 방출
    2. 받는 사람 계좌 B의 입금 지시 메시지를 출력 스트림으로 방출
3. 후속 처리자는 출금과 입금 지시 스트림을 소비해 요청 ID로 중복을 제거한 다음 변경 내용을 계좌 잔고에 반영한다.

## 3) 적시성과 무결성

- 적시성 (Timeliness)
    - 사용자가 시스템을 항상 최신 상태로 관측 가능하다는 의미
- 무결성 (Integrity)
    - 손상이 없다는 의미.

적시성이 위반되면 혼란스러울 수는 있지만, 무결성 위반은 파국이다.

### 3-1) 데이터플로 시스템의 정확성

ACID 트랜잭션은 대개 적시성, 무결성 양쪽 모두 보장한다.

이벤트 기반 데이터플로 시스템의 흥미로운 속성은 적시성과 무결성을 분리하는 것이다.

이벤트 스트림을 비동기로 처리할 때 소비자가 반환하기 전에 명시적으로 메시지 도착을 기다리도록 구축하지 않는다면 적시성은 보장되지 않는다. 물론 무결성이 스트림 시스템의 핵심이다.

스트림 처리 시스템은 분산 트랜잭션과 원자적 커밋 프로토콜 없이 아래 메커니즘을 통해 무결성을 보존할 수 있다.

- 쓰기 연산 내용을 단일 메시지로 표현
- 결정적 파생 함수를 사용해 해당 단일 메시지에서 모든 상태 갱신을 파생하기
- 클라이언트가 생성한 요청ID를 모든 처리 단계를 통해 전달하기
- 메시지를 불변으로 만들고 필요 시 파생 데이터 재처리하기

### 3-2) 느슨하게 해석되는 제약 조건

많은 애플리케이션이 완화된 유일성 개념을 사용해 제한을 피할 수 있다.

- 오류를 바로 잡는 보상 트랜잭션
- 호텔 등 초과 예약되도록 하고 대응
- 일일 전체 초과 인출 금액 제한하여 은행이 감수해야할 위험을 제한

많은 비즈니스 맥락에서 제약 조건을 일시적으로 위반하고 나중에 사과해 바로잡는 것은 실제로 수용 가능한 방법이다. 사과 비용을 수용할 만한지 여부는 비즈니스적 결정 사안이다.

**이런 애플리케이션을 무결성을 반드시 요구한다. 하지만 적시성은 아니다.**

### 3-3) 코디네이션 회피 데이터 시스템

**데이터플로 시스템은 코디네이션 없이도 많은 애플리케이션용 데이터 관리 서비스를 제공할 수 있을 뿐 아니라 여전히 무결성을 강력하게 보장한다.** 이런 코디네이션 회피 데이터 시스템에는 장점이 많다.

## 4) 믿어라. 하지만 확인하라.

- 시스템 모델
    - 정확성, 무결성, 내결함성에 대해 설명할 때 어떤 것은 잘못될 테지만 다른 것은 그렇지 않을 것이라는 가정을 의미한다.

### 4-1) 소프트웨어 버그가 발생해도 무결성 유지하기

데이터베이스 소프트웨어도 버그가 있다.

애플리케이션 코드에서는 더 많은 버그를 각오해야 한다. 데이터베이스는 항상 일관성이 있는 상태에 있으리라고 기대하지만 트랜잭션에 버그가 없을 때만 통한다. 애플리케이션이 데이터베이스를 어떤 식으로든 정확하게 사용하지 않으면 무결성은 보장할 수 없다.

### 4-2) 약속을 맹목적으로 믿지 마라

하드웨어와 소프트웨어가 항상 원하는 만큼 이상적으로 동작하지는 않기 떄문에 데이터 손상은 머잖아 반드시 발생한다. 따라서 버그를 고치고 오류의 원인을 추적하기 위해 적어도 데이터가 손상됐는지 찾는 방법을 마련해야 한다. 데이터 무결성을 체크하는 작업을 감사(auditing)라고 한다.

### 4-3) 검증하는 문화

대부분 정확성 보장이 절대적이라고 가정하며 희박한 데이터 손상 가능성은 대비하지 않는다.

(저자는) 무결성 확인을 지속적으로 수행하는 자가 감사 시스템을 보기를 바란다.

### 4-4) 감사 기능 설계

트랜잭션 자체로는 왜 삽입, 갱신, 삭제를 수행했는지 명확하게 알 수 없다.

**이벤트 기반 시스템은 더 나은 감사 기능을 제공한다.**

이벤트 소싱 접근법에서 시스템의 사용자 입력은 단일 불변 이벤트로 표현되고 어떤 상태 갱신 결과도 이벤트에서 파생할 수 있다. 이런 파생 과정은 결정적이고 반복이 가능하다. → **같은 버전의 파생 코드를 통해 같은 이벤트 로그를 실행하면 동일한 상태 갱신 결과를 만들 수 있다.**

### 4-5) 다시 종단 간 논증

시스템의 모든 개별 구성 요소가 절대로 손상되지 않는다고 완전히 믿기 어렵다면 최소한 데이터의 무결성만이라도 주기적으로 확인해야 한다.

데이터 시스템의 무결성을 확인하는 방법은 종단 간 방식이 최선이다.

무결성 확인이 가능한 시스템이 많을수록 처리 과정의 어떤 단계에서 손상이 발견되지 않을 가능성이 낮아진다.

### 4-6) 감사 데이터 시스템용 도구

감사 기능을 최고 수준으로 고려하는 시스템은 많지 않다.

암호화 감사 기능과 무결성 확인은 종종 머클 트리에 의존한다.

머클 트리는 해시 트리로 특정 데이터셋 내에 나타나는 레코드를 효율적으로 증명하는데 사용한다.

# 4. 옳은 일 하기

데이터셋이 행동, 관심사, 정체성과 같이 인간과 관련된 것이다.

이런 데이터는 인간애와 존경심을 갖고 다뤄야한다.

## 1) 예측 분석

“빅데이터” 판촉에 중요한 부분이다.

날씨 예측이나 질병 확산 예측 분석을 하는 데 데이터를 사용하는 것도 그중 하나다.

### 1-1) 편견과 차별

알고리즘이 내린 결정이 사람이 내린 결정보다 반드시 좋거나 나쁜 것은 아니다.

예측 분석 시스템은 오직 과거로부터 추정한다. 과거가 차별적이라면 예측 분석 시스템은 차별을 성문화한다. 과거보다 나은 미래를 원한다면 도덕적 상상력이 필요하다. 도덕적 상상력은 단지 인간만이 제공할 수 있다.

### 1-2) 책임과 의무

알고리즘도 실수를 할 수 있다. 알고리즘이 잘못됐을 때 누가 책임을 져야 할까?

신용 등급 기관은 데이터를 수집해서 사람에 관한 결정을 내리는 오랜 예이다.

적어도 신용 점수는 일반적으로 그 사람의 실제 차용 내역에 관한 사실을 기반으로 하고 레코드의 오류는 수정될 수 있다. 그러나 머신러닝을 기반으로 한 점수 알고리즘은 보통 더 넓은 범위의 입력을 사용하고 과정이 상당히 불투명해서 왜 그런 결정을 내렸는지 이해하기 어렵고 누군가가 불공평하거나 차별적인 대우를 받는지 알기 어렵다.

의사결정에 데이터를 최우선으로 하는 맹목적 믿음은 망상일 뿐 아니라 절대적으로 위험하다.

### 1-3) 피드백 루프

추천 시스템과 같이 사람들에게 즉각적으로 지대한 영향을 미치지 ㅇ낳는 예측 애플리케이션이라도 직면해야 할 어려운 문제가 있다.

피드백 루프가 언제 발생할지 항상 예측 가능한 것은 아니지만 전체 시스템을 생각하면 많은 결과를 예측할 수 있다.

## 2) 사생활과 추적

행동 데이터 추적은 많은 온라인 서비스에서 사용자 대면 기능을 위해 한층 중요해지고 있다.

검색 결과 순위를 개선하거나, A/B 테스트와 사용자 흐름 분석은 사용자 인터페이스가 얼마나 개선됐는지 알려주는데 유익하다.

### 2-1) 감시

여러 보안상 심각한 문제를 일으킬 수 있는 기록을 가지고 있다. 하지만 사람들은 감출게 없다고 느껴서 기업의 감시를 기꺼이 받아들인다.

### 2-2) 동의와 선택의 자유

사용자가 사용자 행동을 추적하는 서비스 사용을 자발적으로 선택하고 동의했다고 주장할 수 있다.

하지만 사용자는 제공하는 데이터가 무엇이고 어떻게 유지하며 처리되는지 지식이 거의 없다.

그래서 사용자의 데이터로 어떤 일을 하는지 알지 못한 채 받은 동의는 의미가 없다.

물론 미동의 시에 서비스를 이용하지 못하게되는 등으로 인해 결과적으로는 감시를 피하긴 어렵다.

### 2-3) 사생활과 데이터 사용

인터넷 서비스는 사용자가 자신의 사생활 데이터에 무슨 일이 생기는지 이해하지도 못한 채로 이런 데이터를 거대한 규모로 사용하기도 쉽게 만들었다.

### 2-4) 자산과 권력으로서의 데이터

경제적 관점으로 볼 때 타케팅 광고가 서비스를 위해 지불하느 ㄴ것이라면 사람들의 행동 데이터는 서비스의 핵심 자산이다.

데이터는 가치 있기 때문에 많은 사람들이 데이터를 원하고 기업도 물론 데이터를 원한다.

### 2-5) 산업 혁명의 기억

데이터는 정보화 시대의 본질적 특징이다. 산업 혁명이 가진 어두운 면을 관리할 필요가 있는 것처럼 정보화 시대로 이전할 때 직면하는 중요한 문제들을 풀어야 한다.

### 2-6) 법률과 자기 규제

데이터 보호법으로 개인의 권리를 보호할 수 있다.

하지만 이 법률이 오늘날 인터넷 맥락에 효과적인지는 의심스럽다.

각 개인은 스스로 자신의 사생활을 보호할 수 있어야 한다.
