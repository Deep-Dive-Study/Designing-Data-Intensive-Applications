데이터셋이 크고 질의 처리량이 높으면 복제만으로는 부족하고 데이터를 파티션으로 쪼갤 필요가 있다. 이를 “샤딩”이라고 한다.

데이터 파티셔닝의 주된 이유는 확장성이다. 질의를 독립적으로 수행할 수 있는 노드를 추가하여 질의 처리량을 늘릴 수 있다. 복잡한 질의의 경우에는 난이도가 높아지지만 여러 노드에서 병렬 실행 처리가 가능하다.

# 1. 파티셔닝과 복제

복제와 파티셔닝을 함께 적용하여 각 파티션의 복사본을 여러 노드에 저장한다.

각 노드는 어떤 파티션에게 리더이고 다른 파티션에서는 팔로워가 될 수 있다.

![image](https://github.com/user-attachments/assets/e90bf0ac-e88a-40da-a8c6-e6ff7a22de53)


# 2. 키-값 데이터 파티셔닝

- 파티셔닝의 목적
    - 데이터와 질의 부하를 노드 사이에 고르게 분산시키는 것이다.

하지만 파티셔닝이 고르게 이뤄지지 않으면 다른 파티션보다 데이터가 많거나 질의를 많이 받는 파티션이 있을 수 있다. **(쏠림 현상, skewed)** 극단적으로 모든 부하가 한 파티션에 몰려 노드 하나가 병목이 될 수 있다. 이렇게 불균형하게 부하가 높은 파티션을 **“핫스팟”**이라고 한다.

핫스팟을 회피하기 위해서는 레코드를 할당할 노드를 무작위로 선택하면 된다. 더 좋은 방법으로는 단순한 키-값 데이터 모델을 사용하면 된다.

## 1) 키 범위 기준 파티셔닝

각 파티션에 연속된 범위의 키를 할당하는 방법이다. 각 범위들 사이의 경계를 알아 어떤 키가 어느 파티션에 있는지 쉽게 찾을 수 있다. 그리고 파티션이 속한 노드도 알면 적절하게 요청을 직접 보낼 수도 있다.

- 키 범위
    - 키 범위 크기는 동일하지 않아도 된다. → 데이터가 고르게 분포하지 않을 수도 있기 때문이다.
- 파티션 경계
    - 데이터를 고르게 분산시키기 위해 파티션 경계를 데이터에 맞춰 조정해야 한다.
    - 관리자가 수동으로 선택하거나 데이터베이스에서 자동으로 선택되게 할 수 있다.
- 파티션 내 키 정렬된 순서 저장
    - timestamp를 키로 사용한다.
        - 장점: 범위 스캔을 써서 특정 월의 모든 데이터를 쉽게 읽을 수 있다.
        - 단점: 특정한 접근 패턴이 핫스팟을 유발할 수 있다.
        - 해결: 키의 첫 번째 요소를 timestamp가 아닌 다른 것을 먼저 사용한 후에 뒤에 timestamp를 붙이는 방식을 사용해도 좋다.

## 2) 키의 해시값 기준 파티셔닝

쏠림, 핫스팟 위험성이 있어 분산 데이터스토어는 키의 파티션을 정할 때 해시 함수를 사용한다.

키에 적합한 해시 함수를 구했다면 각 파티션에 해시값 범위를 할당하고 해시값이 파티션의 범위에 속하는 모든 키를 그 파티션에 할당하면 된다.

![image](https://github.com/user-attachments/assets/a8ae7539-f526-4974-9f2a-97f5a2e7540d)

- 키 해시값 이용시
    - 범위 질의를 효율적으로 실행할 수 없다.
    - ex. mongoDB에서 해시 기반 샤딩 모드를 활성화하면 범위 질의가 모든 파티션에 전송돼야 한다.
- 범위 질의 타협하는 방식
    - 카산드라의 경우
        - 테이블을 선언할 때 여러 컬럼을 포함하는 복합 기본키를 지정한다.
        - 키의 첫 부분에만 해싱을 적용해 파티션 결정에 사용한다.
        - 남은 컬럼은 SS테이블에서 데이터를 정렬하는 연쇄된 색인으로 사용한다. → 첫 번째 칼럼을 제외하고 다른 컬럼에 대해서는 범위 스캔을 효율적으로 실행할 수 있다.

## 3) 쏠린 작업부하와 핫스팟 완화

키를 해싱해서 파티션하면 핫스팟을 줄일 수 있다.

하지만 완벽하게 핫스팟을 제거할 수 없다.

항상 동일한 키를 읽고 쓰는 극단적인 상황에서는 모든 요청이 동일한 파티션으로 쏠리게 된다.

→ ex. 소셜 미디어 사이트에서 수백만 명의 팔로워를 거느린 유명인의 ID

- 쏠린 작업 부하 보정
    - 현대 데이터 시스템은 자동으로 부하를 조정하지 못하므로 애플리케이션에서 쏠림을 완화해야 한다.
    - 요청이 많이 쏠리는 키에 시작이나 끝에 임의의 숫자를 붙인다.
        - → 임의의 10진수 두 개만 붙여도 한 키에대한 쓰기 작업이 100개의 다른 키로 균등하게 분산된다.
        - → 하지만 다른 키를 쪼개서 쓰면 읽기 실행 시 추가적인 작업이 필요하다.
            - 추가적으로 저장해야 할 정보가 있다.
            - 100개의 키에 해당하는 데이터를 읽어서 조합해야 한다.
            - 어떤 키가 쪼개졌는지 추적할 방법도 필요하다.
- → 쓰기 처리량이 낮은 대다수의 키에도 적용하면 불필요한 오버헤드가 생긴다.

따라서 쏠린 작업부하를 자동으로 감지해서 보정할 수는 있지만 아직은 애플리케이션에 대한 트레이드 오프를 꼼꼼히 따져볼 필요가 있다.

# 3. 파티셔닝과 보조 색인

보조 색인이 연관되면 상황은 복잡해진다.

- 보조 색인
    - 관계형 데이터베이스의 핵심 요소이며 문서 데이터베이스에서도 흔하다.
    - 키-값 저장소에서는 구현 복잡도가 추가되는 것을 피하려고 보조 색인을 지원하지 않지만 보조 색인은 데이터 모델링에 매우 유용하므로 일부 저장소에서는 이를 추가한다.
    - 솔라, 엘라스틱서치 같은 검색 서버에게은 존재의 이유다.

하지만 보조 색인이 파티셔닝에 연관되면 상황은 매우 복잡해진다. 보조 색인이 파티션에 깔끔하게 대응되지 않는 문제점이 있다. 그래서 보조 색인이 있는 데이터베이스를 파티셔닝하는 데 널리 쓰이는 두 가지 방법으로 문서 기반 파티셔닝과 용어 기반 파티셔닝이 있다.

## 1) 문서 기준 보조 색인 파티셔닝

![image](https://github.com/user-attachments/assets/bc6b41ea-54ea-48f6-a8a7-b316420598db)

각 항목에는 문서 ID(document ID)가 있고 이를 기준으로 파티셔닝한다.

각 파티션은 자신의 보조 색인을 유지하며 그 파티션에 속하는 문서만 담당한다.

이러한 문서 파티셔닝 색인을 **“지역 색인(local index)”**이라고 한다.

그러나 문서 기준으로 파티셔닝된 색인을 읽을 때는 주의를 기울여야 한다. color가 red인 자동차를 찾기 위해서는 모든 파티션에 질의를 보내서 얻을 결과를 모아야 하기 때문이다. 이러한 파티셔닝된 데이터베이스에 질의를 보내는 방법을 **“스캐터/개더(scatter/gather)”**라고 한다.

대부분 데이터베이스 벤더들은 보조 색인 질의가 단일 파티션에서만 실행되도록 파티셔닝 방식을 설계하기를 권장하지만 항상 가능하지는 않다.

## 2) 용어 기준 보조 색인 파티셔닝

![image](https://github.com/user-attachments/assets/14d96148-502b-4d54-9fef-8dd1a347d3cd)

- 파티션0: a - r 글자
- 파티션1: s - z 글자

찾고자 하는 용어에 따라 색인의 파티션이 결정되는 색인을 “**용어 기준 보조 색인 파티셔닝(term-partitioned)”**이라고 한다. 

- 장점
    - 범위 스캔에 유용하고 파티셔닝하면 부하가 좀 더 고르게 분산된다.
    - 클라이언트가 모든 파티션에 스캐터/개더를 실행할 필요 없이 원하는 용어를 포함하는 파티션으로만 요청 보내면 된다.
- 단점
    - 쓰기가 느리고 복잡하다. → 색인이 여러 파티션에 영향을 줄 수 있다. (현실에서는 대개 비동기로 갱신)

# 4. 파티션 재균형화

아래와 같은 변화가 생기면 데이터와 요청이 한 노드에서 다른 노드로 옮겨져야 한다.

- 질의 처리량 증가로 CPU 추가하고 싶은 경우
- 데이터셋 크기 증가로 디스크와 램 추가하고 싶은 경우
- 장애가 발생한 장비의 역할을 다른 장비가 넘겨받아야하는 경우

클러스터에서 한 노드가 담당하던 부하를 다른 노드로 옮기는 과정을 **“재균형화(rebalancing)”**라고 한다.

아래 재균형화가 실행될 때 기대하는 최소 요구사항이 있다.

- 재균형화 후, 부하가 클러스터 내에 있는 노드들 사이에 균등하게 분배돼야 한다.
- 재균형화 도중에도 데이터베이스는 읽기 쓰기 요청을 받아들여야 한다.
- 재균형화가 빨리 실행되고 네트워크와 디스크 I/O 부하를 최소화할 수 있도록 노드들 사이에 데이터가 필요 이상으로 옮겨져서는 안된다.

## 1) 재균형화 전략

### 1-1) 쓰면 안 되는 방법: 해시값에 모드 N 연산을 실행

노드가 10대 일 경우 → 123456 mod 10 = 6 → 노드 6에 할당

노드가 11대 일 경우 → 123456 mod 11 = 3 → 노드 3에 할당

노드가 12대 일 경우 → 123456 mod 10 = 0 → 노드 0에 할당

이렇게 키가 자주 이동하면 재균형화 비용이 지나치게 커진다.

### 1-2) 파티션 개수 고정

![image](https://github.com/user-attachments/assets/581ef98a-3d89-4797-baa4-f43c30f0b302)

파티션을 노드 대수보다 많이 만들고 각 노드에 여러 파티션을 할당하는 방식이다. 클러스터에 노드가 추가되면 새 노드는 파티션이 다시 균일하게 분배될 때까지 기존 노드에서 파티션 몇 개를 뺏어온다. 파티션 개수는 변하지 않고  파티션에 할당된 키도 변경되지 않는다. 유일한 변화는 노드에 어떤 파티션이 할당되는가 뿐이다.

처음 데이터베이스 구축 시에 파티션 개수가 고정되고 이후에 변하지 않는 경우가 많으므로 적절한 파티션 개수를 선택해야 한다.

### 1-3) 동적 파티셔닝

키 범위 파티셔닝을 사용하는 데이터베이스에서는 파티션 경계와 개수가 고정돼 있는 게 불편하다. 파티션 경계를 잘못 지정하면 한 파티션에 모든 데이터가 저장될 수도 있다.

이런 이유로 HBase, 리싱크DB처럼 키 범위 파티셔닝을 사용하는 데이터베이스에서는 파티션을 동적으로 만든다.

- 파티션 분할
    - 파티션 크기가 설정된 값을 넘어서면 파티션을 두 개로 쪼개 각각에 원래 파티션의 절반 정도의 데이터가 포함되게 한다.
- 파티션 병합
    - 데이터가 많이 삭제되어 파티션 크기가 임곗값 아래로 떨어지면 인접한 파티션과 합쳐진다.
- 다른 노드로 파티션 이동
    - 큰 파티션이 분할된 후 부하의 균형을 맞추기 위해 분할된 파티션 중 하나가 다른 노드로 이동될 수 있다.

### 1-4) 노드 비례 파티셔닝

카산드라, 케타마에서는 파티션 개수가 노드 대수에 비례하게 한다.

노드 대수가 변함 없는 동안 개별 파티션 크기가 데이터셋 크기에 비례해서 증가하지만 노드 대수를 늘리면 파티션 크기는 다시 작아진다.

- 새로운 노드가 추가되는 경우
    - 고정된 개수의 파티션을 무작위로 선택해 분할한다.
    - 분할된 파티션의 절반은 그대로 두고 다른 절반은 새 노드에 할당한다.
    - 파티션을 무작위로 선택해서 균등하지 않은 분할이 생길 수 있지만 여러 파티션에 대해 평균적으로 보면 균등하다.
    - 파티션 경계를 무작위로 선택하려면 해시 기반 파티셔닝을 사용해야 한다.

## 2) 운영: 자동 재균형화와 수동 재균형화

재균형화를 자동화하면 편리하지만 예측하기 어렵다. 재균형화는 요청 경로를 재설정해야 하고 대량의 데이터를 노드 사이에 이동해야 하므로 비용이 큰 연산이다.

예를 들어 노드 한대에 과부하가 걸려 일시적으로 요청에 대한 응답이 느려졌다. 다른 노드들은 과부하 걸린 노드가 죽었다고 판단하고 해당 노드로부터 부하를 다른 곳으로 옮기기 위해 자동으로 클러스터를 재균형화하려고 한다. 그러면 과부하 걸린 노드와 다른 노드들 그리고 네트워크에 부하를 더해서 상황이 악화되며 연쇄 장애가 발생할 가능성도 있다.

# 5. 요청 라우팅

클라이언트에서 요청을 보낼 때 어느 노드로 접속해야하는지 알 수 있을까? 파티션이 재균형화되면서 노드에 할당되는 파티션이 바뀐다. 데이터베이스에 국한되지 않은 문제로 서비스 찾기(service discovery)의 일종이다.

상위 수준에서 보면 몇 가지 다른 접근법이 있다.

- 클라이언트가 아무 노드에나 접속하게 한다.
    - 해당 노드에 마침 요청을 적용할 파티션이 있다면 거기서 직접 처리한다.
    - 그렇지 않으면 요청을 올바른 노드로 전달해서 응답을 받고 클라이언트에게 응답을 전달한다.
- 클라이언트의 모든 요청을 라우팅 계층으로 먼저 보낸다.
    - 각 요청을 처리할 노드를 알아내고 그에 따라 해당 노드로 요청을 전달한다.
- 클라이언트가 파티셔닝 방법과 파티션이 어떤 노드에 할당됐는지를 알고 있게 한다.

![image](https://github.com/user-attachments/assets/45244d99-a9d0-4a4f-8b34-1eeb06508b03)

- Zookeeper 같은 별도의 코디네이션 서비스 사용
    - 각 노드는 주키퍼에 자신을 등록한다.
    - 주키퍼는 파티션과 노드 사이의 신뢰성 있는 할당 정보를 관리한다.
    - 라우팅 계층이나 파티션 인지 클라이언트 같은 다른 구성요소들은 주키퍼에 있는 정보를 구독할 수 있다.
    - 파티션 소유자가 바뀌든지, 노드가 추가되거나 삭제되면 주키퍼는 라우팅 계층에 이를 알려서 라우팅 정보를 최신으로 유지할 수 있게 한다.

- HBase, 솔라클라우드, 카프카
    - ex. 주키퍼
- 몽고DB
    - ex. 몽고스 데몬
- 카산드라, 리악
    - 가십 프로토콜
- 카우치베이스
    - ex. 목시(moxi)

## 1) 병렬 질의 실행

분석용으로 자주 사용되는 대규모 병렬 처리(massively parallel processing, MPP) 관계형 데이터베이스 제품은 더 복잡한 종류의 질의를 지원한다. MPP 질의 최적화기는 복잡한 질의를 여러 실행 단계와 파티션으로 분해하며 이들 중 다수는 데이터베이스 클러스터 내의 서로 다른 노드에서 병렬적으로 실행될 수 있다. 데이터셋의 많은 부분을 스캔하는 연산을 포함하는 질의는 특히 병렬 실행의 혜택을 받는다.
