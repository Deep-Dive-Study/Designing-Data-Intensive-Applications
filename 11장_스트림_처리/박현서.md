- 스트림
    - 시간 흐름에 따라 점진적으로 생성된 데이터를 일컫는다.
    - 스트림은 유닉스 stdin과 stdout, 프러그래밍 언어 (lazy lists), 자바의 FileInputStream 같은 파일 시스템 API, TCP 연결 등 많은 곳에서 등장한다.

# 1. 이벤트 스트림 전송

- 이벤트
    - 스트림 처리 문맥에서 레코드를 보통 이벤트라고 한다.
    - 특정 시점에 일어난 사건에 대한 세부 사항을 포함하는, 작고 독립된 불변 객체이다.
    - 일반적으로 일기준 시계를 따르는 이벤트 발생 타임스탬프를 포함한다.
- 스트리밍
    - 생산자(producer)가 이벤트를 한 번 만들면, 해당 이벤트를 복수의 소비자(consumer)가 처리할 수 있다.
- 폴링 비용은 좋지 않다.
    - 이론상으로 파일이나 데이터베이스가 있으면 생산자와 소비자를 연결하기에 충분하다.
    - 생산자는 이벤트를 데이터스토어에 기록하고, 각 소비자는 주기적으로 폴링하여 마지막으로 처리한 이벤트 이후에 새로 발생한 이벤트가 있는지 확인한다.
    - 폴링 : 하지만 지연 시데이터스토어는 지연 시간이 낮으면서 지속해서 처리하는 방식에 맞게 설계하지 않았다면 폴링 비용이 크다.
    - 트리거 : 트리거 기능으로 변화에 반응할 수 있지만, 트리거는 기능이 제한적이고 데이터베이스를 설계한 이후에 도입한 개념이다.

이벤트 알림 전달 목적으로 개발된 특별한 도구들이 있다.

## 1) 메시징 시스템

- 메시징 시스템
    - 새로운 이벤트에 대해 소비자에게 알려주려고 쓰이는 일반적인 방법
    - 구축 방법 : 생산자와 소비자 사이에 유닉스 파이프나 TCP 연결과 같은 직접 통신 채널을 사용한다.

발행/구독 모델에서는 여러 시스템들이 다양한 접근법을 사용한다.

모든 목적에 부합하는 단 하나의 정답은 없다.

- 생산자가 소비자의 메시지 처리 속도보다 빠르게 메시지를 발행하면 어떻게 할 것인가?
    - 메시지가 큐에 버퍼링될 때 큐 크기가 증가함에 따라 어떤 현상이 생기는가?
    - 큐 크기가 메모리 크기보다 더 커지면 시스템이 중단되는가, 메시지를 디스크에 쓰는가?
    - 디스크에 메시지를 쓴다면 디스크 접근이 메시징 시스템의 성능에 어떤 영향을 주게 되는가?
- 노드가 죽거나 일시적으로 오프라인 된다면 어떻게 할 것인가?
    - 디스크에 기록하거나 복제본 생성을 할 것인가? 비용은 어떻게 되는가?

메시지 유실 허용은 애플리케이션에 따라 상당히 다르다.

주기적으로 전송되는 센서 판독값과 지표는 가끔 데이터가 누락되더라도 문제가 없다.

하지만 메시지가 많이 누락된다면 지표가 정확하지 않아 즉시 인식하기는 어렵다.

### 1-1) 생산자에서 소비자로 메시지를 직접 전달하기

많은 메시지 시스템은 중간 노드를 통하지 않고 생산자와 소비자를 네트워크로 직접 통신한다.

- UDP 멀티캐스트
    - 생산자는 필요할 때 패킷을 재전송할 수 있게 전송한 패킷을 기억해야 한다.
- ZeroMQ
    - TCP 또는 IP 멀티캐스트 상에서 발행/구독 메시징을 구현한다.
- StatsD과 BruBeck
    - StatsD 프로토콜은 모든 메시지를 받아야 카운터 지표가 정확하다.
- 소비자가 네트워크에 서비스를 노출하면 생산자는 직접 HTTP나 RPC 요청을 직접 보낼 수 있다.

### 1-2) 메시지 브로커

- 메시지 브로커(메시지 큐)
    - 직접 메시징 시스템의 대안으로 널리 사용되는 방법
    - 근본적으로 메시지 스트림을 처리하는 데 최적화된 데이터베이스의 일종
    - 메시지 브로커는 서버로 구동되고 생산자와 소비자는 서버의 클라이언트로 접속한다.

브로커에 데이터가 모이기 때문에 클라이언트의 상태 변경(접속, 접속 해제, 장애)에 쉽게 대처할 수 있다.

### 1-3) 메시지 브로커와 데이터베이스 비교

메시지 브로커와 데이터베이스는 실용적 차이가 있지만 특징은 데이터베이스의 속성과 비슷하다.

- 데이터 보관
    - 데이터베이스 : 명시적으로 데이터가 삭제될 때까지 데이터를 보관한다.
    - 메시지 브로커 : 소비자에게 데이터 배달이 성공할 경우 자동으로 메시지를 삭제한다.
- 데이터 검색
    - 데이터베이스 : 보조 색인을 지원하고 데이터 검색을 위한 다양한 방법을 지원한다.
    - 메시지 브로커 : 특정 패턴과 부합하는 토픽의 부분 집합을 구독하는 방식이다.
- 데이터 질의
    - 데이터베이스 : 질의할 떄 그 결과는 일반적으로 질의 시점의 데이터 스냅숏을 기준으로 한다.
    - 메시지 브로커 : 임의 질의를 지원하지 않지만 데이터가 변하면 클라이언트에게 알려준다.

### 1-4) 복수 소비자

복수 소비자 같은 토픽에서 메시지를 읽을 때 사용하는 주요 패턴 두 가지

- 로드 밸런싱
    - 각 메시지는 소비자 중 하나로 전달된다. 소비자들은 해당 토픽의 메시지 처리하는 작업을 공유한다.
    - 브로커는 메시지를 전달할 소비자를 임의로 지정한다.
- 팬 아웃
    - 각 메시지는 모든 소비자에게 전달된다.
    - 여러 독립적인 소비자가 브로드캐스팅된 동일한 메시지를 서로 간섭 없이 “청취”할 수 있다.

### 1-5) 확인 응답과 재전송

부하 균형 분산, 메시지 재전송을 조합하면 메시지 순서에 영향을 미친다.

소비자마다 독립된 큐를 사용하면 문제가되지 않는다, 메시지가 서로 완전히 독립이라면 메시지 순서가 바뀌는 것은 문제가 되지 않는다.

## 2) 파티셔닝된 로그

메시지 브로커는 메시지를 일시적으로 보관하는 개념으로 만들어졌다.

- 로그 기반 메시지 브로커(log-based message broker)
    - 데이터베이스의 지속성 있는 저장 방법과 메시징 시스템의 지연 시간이 짧은 알림 기능 조합

### 2-1) 로그를 사용한 메시지 저장소

- 로그
    - 디스크에 저장된 추가 전용 레코드의 연속
- 브로커 구조
    - 생산자가 보낸 메시지는 로그 끝에 추가하고 소비자는 로그를 순차적으로 읽어 메시지를 받는다.
- 파티셔닝
    - 디스크 하나를 쓸 때보다 처리량을 높이기 위해 확장하는 방법으로 로그를 파티셔닝하는 방법
- 파티션
    - 다른 파티션과 독립적으로 읽고 쓰기가 가능한 분리된 로그
- 토픽
    - 같은 형식의 메시지를 전달하는 파티션들의 그룹
- 오프셋
    - 각 파티션 내에서 브로커는 모든 메시에 단조 증가하는 순번(오프셋)을 부여한다.

로그 기반 메시지 브로는 모든 메시지를 디스크에 저장하지만, 여러 장비에 메시지를 파티셔닝해 초당 수백만 개의 메시지를 처리할 수 있고 메시지를 복제함으로써 장애에 대비할 수 있다.

### 2-2) 로그 방식과 전통적인 메시징 방식의 비교

로그 기반 접근법은 팬 아웃 메시징 방식을 제공한다. 소비자가 서로 영향 없이 독립적으로 로그를 읽을 수 있고, 메시지를 읽어도 로그에서 삭제되지 않기 때문이다. 개별 메시지를 소비자 클라이언트에게 할당하지 않고, 소비자 그룹 간 로드 밸런싱하기 위해 브로커는 소비자 그룹의 노드들에게 전체 파티션을 할당할 수 있다.

- 토픽 하나를 소비하는 작업을 공유하는 노드 수는 많아야 해당 토픽의 로그 파티션 수로 제한된다.
- 특정 메시지 처리가 느리면 파티션 내 후속 메시지 처리가 지연된다.

JMS/AMQP 방식: 메시지를 처리하는 비용이 비싸고 메시지 단위로 병렬화 처리하고 싶지만 메시지 순서는 중요하지 않는 경우

로그 기반 접근 방식: 처리량이 많고 메시지를 처리하는 속도가 빠르지만 메시지 순서가 중요한 경우

### 2-3) 소비자 오프셋

파티션 하나를 순서대로 처리하면 메시지를 어디까지 처리했는지 알기 쉽다.

브로커는 주기적으로 소비자 오프셋을 기록하면 개별 메시지마다 보내는 확인 응답을 추적할 필요가 없다.

소비자 노드에 장애가 발생하면 소비자 그룹 내 다른 노드에 장애가 발생한 소비자의 파티션을 할당하고 마지막 기록된 오프셋부터 메시지를 처리하기 시작한다.

### 2-4) 디스크 공간 사용

로그를 계속 추가하면 디스크 공간을 전부 사용하게 된다.

디스크 공간 재사용을 위해 로그를 여러 조각으로 나누고 가끔 오래된 조각을 삭제하거나 보관 저장소로 이동한다.

소비자가 뒤쳐지는 경우 소비자 오프셋이 이미 삭제한 조각을 가리킬 수도 있다.

즉, 메시지 일부를 잃어버릴 가능성이 있다.

결과적으로 로그는 크기가 제한된 버퍼로 구현하고 버퍼가 가득 차면 오래된 메시지 순서대로 버린다.

이런 버퍼를 원형 버퍼(circular buffer) 또는 링 버퍼(ring buffer)라고 한다.

메시지 보관 기관과 관계없이 모든 메시지를 디스크에 기록하는 경우 로그 처리량은 일정하다.

하지만 기본적으로 메모리에 메시지를 유지하고 큐가 너무 커질 때만 디스크에 기록하는 메시징 시스템과는 반대다. 큐가 작을 때는 빠르지만 디스크에 기록하기 시작하면 매우 느려진다. 이 시스템의 처리량은 보유한 메시지 양에 따라 다르다.

### 2-5) 소비자가 생산자를 따라갈 수 없을 때

- 선택지
    - 메시지 버리기
    - 버퍼링
    - 배압 적용

로그 기반 접근법은 대용량이지만 고정 크기의 버퍼를 사용하는 버퍼링 형태이다.

소비자가 뒤처져 필요한 메시지가 디스크에 보유한 메시지보다 오래되면 필요한 메시지는 읽을 수 없다.

브로커는 버퍼 크기를 넘는 오래된 메시지를 자연스럽게 버린다.

소비자가 로그 헤드로부터 얼마나 떨어졌는지 모니터링하면 눈에 띄게 뒤처지는 경우 경고할 수 있다.

어떤 소비자가 너무 뒤처져서 메시지를 잃기 시작해도 해당 소비자만 영향을 받고 다른 소비자들의 서비르를 망치지는 않는다. 소비자가 종료되거나 죽으면 자원 소비가 중단되고 소비자 오프셋만 남는다.

### 2-6) 오래된 메시지 재생

소비자의 출력을 제외한, 메시지 처리의 유일한 부수 효과는 소비자 오프셋 이동이다.

소비자 오프셋은 소비자 관리 아래에 있어 쉽게 조작할 수 있다.

메시지를 재처리하기 위해 다른 위치에 출력을 기록할 수있고, 몇 번이든지 처리 코드를 변경해 재처리할 수 있다.

로그 기반 메시징과 일괄 처리는 변환 처리를 반복해도 입력 데이터에 영향을 전혀 주지 않고 파생 데이터르 만든다.

# 2. 데이터베이스와 스트림

## 1) 시스템 동기화 유지하기

데이터 저장과 질의, 처리 요구사항을 모두 만족하는 단일 시스템은 없었다.

애플리케이션이 요구사항을 만족하기 위해 몇 가지 다른 기술의 조합이 필요하다.

- 조합 예시
    - OLTP 데이터베이스 : 사용자 요청에 대응하기 위함
    - 캐시 : 공통 요청의 응답 속도를 높이기 위함
    - 전문 색인 : 검색 질의를 다루기 위함
    - 분석용 데이터 웨어하우스

각 시스템은 데이터의 복제본을 가지고 있고, 그 데이터를 목적에 맞게 최적화된 형태로 각각 저장한다.

- 동기화
    - 관련 있거나 동일한 데이터가 여러 다른 장소에서 나타나기 때문에 서로 동기화는 필수다.
- 이중 기록 (dual write)
    - 데이터가 변할 때마다 애플리케이션 코드에서 명시적으로 각 시스템에 기록한다.
    - 문제점
        - 내결함성 문제로 두 시스템 간 불일치
        - 원자적 커밋을 적용해도 비용이 큼

## 2) 변경 데이터 캡처 (Change Data Capture, CDC)

- 변경 데이터 캡처
    - 데이터베이스에 기록하는 모든 데이터의 변화를 관찰해 다른 시스템으로 데이터를 복제할 수 있는 형태로 추출하는 과정
    - CDC는 데이터가 기록되지마자 변경 내용을 스트림으로 제공할 수 있으면 유용함

데이터베이스에 쓰여진 순서대로 데이터를 가져와 다른 시스템에 변경 사항을 같은 순서로 적용한다.

### 2-1) 변경 데이터 캡처의 구현

- 변경 데이터 캡처
    - 파생 데이터 시스템이 레코드 시스템의 정확한 데이터 복제본을 가지게 하기 위해 레코드 시스템에 발생하는 모든 변경 사항을 파생 데이터 시스템에 반영하는 것을 보장하는 메커니즘이다.
- **로그 기반 메시지 브로커**
    - CDC는 변경 사항을 캡처할 데이터베이스 하나를 리더로 하고 나머지를 팔로워로 한다.
    - 로그 기반 메시지 브로커는 원본 데이터베이스에서 변경 이벤트를 전송하기에 적합하다. → 메시지 순서를 유지하기 때문
- 데이터베이스 트리거
    - 데이터 테이블의 모든 변화를 관찰하는 트리거를 등록하고 변경 로그 테이블에 해당 항목을 추가하는 방식
    - 단점 : 고장 나기 쉽고 성능 오버헤드가 상당하다.

### 2-2) 초기 스냅숏

데이터베이스 전체 상태를 재구축할 수 있으나 모든 변경 사항을 영구적으로 보관하는 일은 디스크 공간이 많이 필요하다. → 로그를 적당히 잘라야 한다.

전문 색인을 새로 구축할 때는 전체 데이터베이스 복사본이 필요하다.

전체 로그 히스토리가 없다면 일관성 있는 스냅숏을 사용해야 한다.

데이터베이스 스냅숏은 변경 로그의 위치나 오프셋에 대응돼야 한다. → 스냅숏 이후에 변경 사항을 적용할 시점을 알 수 있다.

### 2-3) 로그 컴팩션

- 로그 컴팩션(log compaction)
    - 로그 히스토리의 양을 제한한다면 새로운 파생 데이터 시스템을 추가할 때마다 스냅숏을 만들어야 한다.
- 로그 구조화 저장 엔진
    - 주기적으로 같은 키의 로그 레코드를 찾아 중복을 제거한다.
    - 각 키에 대해 가장 최긘에 갱신된 내용만 유지한다.
    - 컴팩션과 병합 과정은 백그라운드로 실행된다.

### 2-4) 변경 스트림용 API 지원

최근 데이터베이스들은 기능 개선, 리버스 엔지니어링을 통해 CDC 지원을 하기보다 점진적으로 변경 스트림을 기본 인터페이스로서 지원하기 시작했다.

## 3) 이벤트 소싱

- 이벤트 소싱(event sourcing)
    - CDC와 유사한 점 : 애플리케이션 상태 변화를 모두 변경 이벤트 로그로 저장한다.
    - CDC와 차이점 : 아이디어를 적용하는 추상화 레벨이 다르다.
    - CDC : 데이터베이스에서 저수준으로 추출한다.
    - 이벤트 소싱 : 애플리케이션 수준에서 발생한 일을 반영하게끔 설계됐다.

애플리케이션 관점에서 사용자의 행동을 불변 이벤트로 기록하는 방식은 변경 가능한 데이터베이스 상에서 사용자의 행동에 따른 효과를 기록하는 방식보다 훨씬 유의미하다.

이벤트 소싱을 사용하면 애플리케이션을 지속해서 개선하기가 매우 유리하다.

### 3-1) 이벤트 로그에서 현재 상태 파생하기

이벤트 로그 그자체로는 유용하지 않다.

사용자는 수정 히스토리가 아닌 현재 상태를 보고 싶어하기 때문이다.

따라서 이벤트 소싱을 사용하는 애플리케이션은 시스템에 기록한 데이터를 표현한 이벤트 로그를 사용자에게 보여주기에 적당한 애플리케이션 상태로 변환해야 한다.

- 레코드 갱신용 CDC 이벤트
    - 레코드의 가장 새로운 버전을 보유한다.
    - 기본키의 현재 값은 기본키의 가장 최신 이벤트로 결정되고 같은 키의 이전 이벤트는 로그 컴팩션을 통해 버린다.
- 이벤트 소싱
    - 이벤트를 보다 상위 수준에서 모델링한다.
    - 사용자 행동의 의도를 표현한다.
    - 이벤트가 앞선 이벤트를 덮어쓰지 않는다.
    - 마지막 상태를 재구축하기 위해서는 전체 히스토리가 필요하다.
    - 로그 컴팩션이 불가능하다.

### 3-2) 명령과 이벤트

- 이벤트 소싱 철학
    - 이벤트와 명령(command)을 구분하는데 주의한다.

## 4) 상태와 스트림 그리고 불변성

불변성 원리는 이벤트 소싱과 CDC를 강력하게 만든다.

상태가 변할 때마다 해당 상태는 시간이 흐름에 따라 변한 이벤트의 마지막 결과다.

상태가 어떻게 바뀌었든 항상 이런 변화를 일으킨 일련의 이벤트가 있다.

그래서 변경 로그를 지속성 있게 저장한다면 상태를 간단히 재생성할 수 있는 효과가 있다.

### 4-1) 불변 이벤트의 장점

잘못된 거래 내역을 지우거나 고치지 않고, 실수를 보완하는 거래 내역을 추가한다.

추가만 하는 불변 이벤트 로그를 썼다면 문제 상황의 진단과 복구가 훨씬 쉽다.

### 4-2) 동일한 이벤트 로그로 여러 가지 뷰 만들기

불변 이벤트 로그에서 가변 상태를 분리하면 동일한 이벤트 로그로 다른 여러 읽기 전용 뷰를 만들 수 있다.

이벤트 로그에서 데이터베이스로 변환하는 명시적인 단계가 있으면 시간이 흐름에 따라 애플리케이션을 발전시키기 쉽다. 기존 데이터를 새로운 방식으로 표현하는 새 기능을 추가하려면 이벤트 로그를 사용해 신규 기능용으로 분리한 읽기 최적화된 뷰를 구축할 수 있다.

### 4-3) 동시성 제어

- 이벤트 소싱과 CDC의 가장 큰 단점
    - 이벤트 로그의 소비가 대개 비동기로 이뤄진다.
- 해결책
    1. 읽기 뷰의 갱신과 로그에 이벤트를 추가하는 작업을 동기식으로 수행하는 방법 → 트랜잭션에서 여러 쓰기를 원자적 단위로 결합해야 한다.
    2. 이벤트 로그로 현재 상태를 만드는 방법
        1. 이벤트 소싱을 사용하면 사용자 동작에 대한 설명을 자체적으로 포함하는 이벤트를 설계할 수 있다. → 사용자 동작은 한 장소에서 한 번 쓰기만 필요하다.

### 4-4) 불변성의 한계

이벤트 소스 모델을 사용하지 않는 많은 시스템에서도 불변성에 의존한다.

다양한 데이터베이스는 내부적으로 시점 스냅숏을 지원하기 위해 불변 자료 구조나 다중 버전 데이터를 사용한다.

- 성능 문제
    - 상대적으로 작은 데이터셋에서 매우 빈번히 갱신과 삭제를 하는 작업부하는 불변 히스토리가 감당하기 힘들 정도로 커지거나 파편화 문제가 생길 수 있다.
- 관리상 문제
    - 이전 데이터를 삭제해야 할 때 다른 이벤트를 로그에 추가한다고 해결되지 않는다. → 실제 원하는 바는 히스토리를 새로 쓰고 문제가 되는 데이터를 처음부터 기록하지 않았던것 처럼 하는 것이다.

# 3. 스트림 처리

- 스트림 처리 방법 3가지
    - 이벤트에서 데이터를 꺼내 데이터베이스나 캐시, 검색 색인 또는 유사한 저장소 시스템에 기록하고 다른 클라이언트가 이 시스템에 해당 데이터를 질의한다.
    - 이벤트를 사용자에게 직접 보낸다.
    - 하나 이상의 입력 스트림을 처리해 하나 이상의 출력 스트림을 생산한다.

스트림을 처리해 다른 파생 스트림을 생산하는 부분을 알아보자.

일괄 처리 작업과 큰 다른 점은 스트림은 끝나지 않는다는 것이다.

## 1) 스트림 처리의 사용

스트림 처리는 특정 상황이 발생하면 조직에 경고를 해주는 모니터링 목적으로 오랜 기간 사용돼 왔다.

- 사기 감시 시스템
    - 신용카드의 사용 패턴이 기대치 않게 변경되는지 확인해서 도난된 것으로 의심되면 카드 결제를 막는다.
- 거래 시스템
    - 금융 시장의 가격 변화를 감지해서 특정 규칙에 따라 거래를 싱ㄹ행해야 한다.
- 제조 시스템
    - 공장의 기계 상태를 모니터링하다 오작동을 발견하면 문제를 빨리 규명해야 한다.
- 군사 첩보 시스템
    - 잠재적 침략자의 활동을 추적해 공격 신호가 있으면 경보를 발령해야 한다.

시간이 흘러 다른 용도로 스트림 처리를 사용하는 사용자들이 나타나기 시작했다.

### 1-1) 복잡한 이벤트 처리

- 복잡한 이벤트 처리 (Complex Event Processing, CEP)
    - 특정 이벤트 패턴을 검색해야 하는 애플리케이션에 특히 적합하다.

### 1-2) 스트림 분석

스트림 처리를 사용하는 다른 영역으로 스트림 분석이 있다.

CEP와 스트림 사이의 경계는 불분명하지만 분석은 대량의 이벤트를 집계하고 통계적 지표를 뽑는 것을 우선시한다.

### 1-3) 구체화 뷰 유지하기

데이터베이스 변경에 대한 스트림은 캐시, 검색 색인, 데이터 웨어하우스 같은 파생 데이터 시스템이 원본 데이터베이스의 최신 내용을 따라잡게하는데 쓸 수 있다.

### 1-4) 스트림 상에서 검색하기

복수 이벤트로 구성된 패턴을 찾는 CEP 외에도 전문 검색 질의와 같은 복잡한 기준을 기반으로 개별 이벤트를 검색해야 하는 경우도 있다.

스트림 검색은 질의를 먼저 저장하고 CEP와 같이 문서는 질의를 지나가면서 실행된다.

### 1-5) 메시지 전달과 RPC

유사 RPC 시스템과 스트림 처리 사이에 겹치는 영역이 있다.

예를 들어, 아파치 스톰에 분산 RPC라 부르는 기능이 있다.

이벤트 스트림을 처리하는 노드 집합에 질의를 맡길 수 있고, 이 질의는 입력 스트림 이벤트가 끼워지고 그 결과들을 취합해 사용자에게 돌려준다.

## 2) 시간에 관한 추론

스트림 처리자는 종종 시간을 다뤄야 할 때가 있다.

주로 시간 윈도우를 자주 사용한다.

- 일괄 처리
    - 각 이벤트에 내장된 타임스탬프를 본다.
    - 이벤트 처리를 결정적으로 만들 수 있다.
- 스트림 처리
    - 윈도우 시간을 결정할 때 처리하는 장비의 시스템 시계를 이용한다.
    - 이벤트 생성과 이벤트 처리 사이의 간격이 무시할 정도로 작다면 꽤 합리적이지만, 눈에 띌 정도로 처리가 지연되면 문제가 생긴다.

### 2-1) 이벤트 시간 대 처리 시간

스트림 처리 알고리즘은 타이밍과 순서 문제를 처리하게끔 명확히 작성할 필요가 있다.

### 2-2) 준비 여부 인식

이벤트 시간 기준으로 윈도우를 정의할 때 까다로운 문제가 있다.

특정 윈도우에서 모든 이벤트가 도착했다거나 아직도 이벤트가 계속 들어오고 있는지를 확신할 수 없다는 점이다.

윈도우를 이미 종료한 후에 도착한 **낙오자 이벤트**를 처리할 방법이 필요하다.

- 낙오자 이벤트를 무시한다.
    - 정상적인 환경에서 낙오자 이벤트는 대체로 적은 비율을 차지하기 때문이다.
    - 놓친 이벤트의 수를 지표로 추적해 많은 양의 데이터가 누락되는 경우 경고를 보낼 수 있다.
- 수정 값을 발행하다.
    - 낙오자 이벤트가 포함된 윈도우를 기준으로 갱신된 값이다. → 이전 출력을 취소해야 할 수도 있다.

### 2-3) 어쨌든 어떤 시계를 사용할 것인가?

이벤트의 타임스탬프는 모바일 장치 로컬 시계를 따르는, 실제 사용자와의 상호작용이 발생했던 실제 시각이어야 한다. 그러나 고의로 잘못된 시간이 설정됐을 가능성이 있기 때문에 사용자가 제어하는 장비의 시계를 항상 신뢰하기는 어렵다.

잘못된 장치 시계를 조정하는 한 가지 방법은 세 가지 타임스탬프를 로그로 남기는 것이다.

- 이벤트가 발생한 시간 : 장치 시계를 따른다.
- 이벤트를 서버로 보낸 시간 : 장치 시계를 따른다.
- 서버에서 이벤트를 받은 시간 : 서버 시계를 따른다.

두번 째와 세 번째의 타임스탬프를 차이를 구하면 장치 시계와 서버 시계 간의 오프셋을 추정할 수 있다.

이러한 문제는 스트림 처리에서만 나타나는 것은 아니다. 단지 스트림 처리할 때가 더 시간의 흐름을 잘 알 수 있기 때문에 문제가 두드러질 뿐이다.

### 2-4) 윈도우 유형

이벤트 타임스탬프를 어떻게 결정할지 안다면 다음 단계는 윈도우 기간을 어떻게 정의해야할 지 결정해야 한다.

- 텀블링 윈도우(Tumbling window)
    - 크기는 고정 길이다.
    - 모든 이벤트는 정확히 한 윈도우에 속한다.
- 홉핑 윈도우(Hopping window)
    - 크기는 고정 길이다.
    - 결과를 매끄럽게 만들기 위해 윈도우를 중첩할 수 있다.
- 슬라이딩 윈도우(Sliding window)
    - 각 시간 간격 사이에서 발생한 모든 이벤트를 포함한다.
- 세션 윈도우(Session window)
    - 고정된 기간이 없다.
    - 사용자가 짧은 시간 동안 발생시킨 모든 이벤트를 그룹화해서 세션 윈도우를 정의한다.

## 3) 스트림 조인

스트림 처리는 데이터 파이프라인을 끝이 없는 데이터셋의 증분 처리로 일반화하기 때문에 스트림에서도 조인에 대한 필요성은 정확히 동일하다.

스트림 상에서 조인은 일괄 처리 작업보다 어렵다. → 스트림 상에서 새로운 이벤트가 언제든 나타날 수 있다는 사실이 있기 때문이다.

- 스트림 조인의 유형 3가지
    - 스트림 스트림 조인
    - 스트림 테이블 조인
    - 테이블 테이블 조인

### 3-1) 스트림 스트림 조인(윈도우 조인)

검색 품질 측정을 위해 사용자가 클릭한 검색 결과뿐만아니라 클릭하지 않은 검색 결과를 알 수 있는 방식이 필요하다. 이를 위해서는 스트림 처리자가 상태를 유지해야 한다.

- 지난 시간에 발생한 모든 이벤트를 세션ID로 색인한다.
- 검색 이벤트, 클릭 이벤트가 발생할 때마다 해당 색인에 추가한다.
- 스트림 처리자는 같은 세션ID로 이미 도착한 다른 이벤트가 있는지 다른 색인을 확인 해야한다.
- 이벤트가 매칭되면 검색한 결과를 클릭했다고 말해주는 이벤트를 방출한다.
- 검색 이벤트가 클릭 이벤트 매칭 없이 만료되면 검색 결과가 클릭되지 않았다라고 말해주는 이벤트를 방출한다.

### 3-2) 스트림 테이블 조인(스트림 강화)

사용자 활동 이벤트 집합과 사용자 프로필 데이터베이스를 조인하는 일괄 처리 예제를 기반으로 두고 보자.

- 입력 : 사용자 ID를 포함한 활동 이벤트 스트림
- 출력 : 해당 ID를 가진 사용자 프로필 정보가 추가된 활동 이벤트
- 스트림 처리 방법들
    1. 하나의 활동 이벤트를 대상으로 데이터베이스에서 이벤트의 사용자 ID를 찾아 활동 이벤트에 프로필 정보를 추가
    2. 스트림 처리자 내부에 데이터베이스 사본을 적재
        1. 하지만 스트림 처리는 오랜 기간 수행하기 때문에 시간이 흘러가면서 데이터베이스의 내용이 변할 가능성이 높다. 그래서 스트림 처리자가 사용하는 데이터베이스의 로컬 복사본을 최신 상태로 유지해야 한다. 이는 CDC를 사용하면 해결 가능하다.

### 3-3) 테이블 테이블 조인(구체화 뷰 유지)

- 예제
    - 사용자 u가 새로운 트윗을 보냈을 떄 u를 팔로잉하는 모든 사용자의 타임라인에 트윗 추가
    - 사용자가 트윗을 삭제하면 모든 사용자의 타임라인에서 해당 트윗을 삭제
    - 사용자 u1이 사용자 u2를 팔로우하기 시작하면 u2의 최근 트윗을 u1의 타임라인에 추가
    - 사용자 u1이 사용자 u2 팔로우를 취소했을 때 사용자 u2의 트윗을 사용자 u1의 타임라인에서 제거
- 스트림 처리자에서 캐시 유지를 구현하기 위한 스트림
    - 트윗 이벤트 스트림(전송과 삭제)
    - 팔로우 관계 이벤트 스트림(팔로우와 언팔로우)

스트림 처리는 새로운 트윗이 도착했을 때 어떤 타임 라인을 갱신해야 하는지 알기 위해 각 사용자의 팔로우 집합이 포함된 데이터베이스를 유지해야 한다.

### 3-4) 조인의 시간 의존성

복수 개의 스트림에 걸친 이벤트 순서가 결정되지 않으면 조인도 비결정적이다.

동이 문제를 데이터 웨어 하우스에서는 천천히 변하는 차원(slowly changing dimension, SCD)라고 한다.

## 4) 내결함성

일괄 처리는 결정적으로 처리되어 문제가 발생했을지라도 결과적으로 작업의 결과는 동일하다.

하지만 스트림은 무한하여 처리를 절대 완료할 수 없다.

### 4-1) 마이크로 일괄 처리와 체크 포인트

- 마이크로 일괄 처리(microbatching)
    - 스트림을 작은 블록으로 나누고 각 블록을 소형 일괄 처리와 같이 다루는 방법
    - 마이크로 일괄 처리는 암묵적으로 텀블링 윈도우를 지원한다.
- 아파치 플링크
    - 주기적으로 상태의 롤링 체크포인트를 생성하고 지속성 있는 저장소에 저장한다.
    - 스트림 연산자에 장애가 발생하면 스트림 연산자는 가장 최근 체크포인트에서 재시작하고 해당 체크포인트와 장애 발생 사이의 출력은 버린다.

### 4-2) 원자적 커밋 재검토

정확히 한 번 처리되는 것처럼 보일려면 처리가 성공했을 때만 모든 출력과 이벤트 처리의 부수 효과가 발생해야 한다.

### 4-3) 멱등성

결국 목표는 처리 효과가 두 번 나타나는 일 없이 안전하게 재처리하기 위해 실패한 태스크의 부분 출력을 버리는 것이다. 여러 방법 중 멱등성에 의존하는 방법이 있다.

연산 자체가 멱등적이지 않아도 약간의 여분 메타데이터로 연산을 멱등적으로 만들 수 있다.

예를 들어 카프카로부터 메시지를 소비할 때 모든 메시지에는 영속적이고 단조 증가하는 오프셋이 있다.

### 4-4) 실패 후에 상태 재구축하기

윈도우 집계, 조인용 테이블과 색인처럼 상태가 필요한 스트림 처리는 실패 후에도 해당 상태가 복구됨을 보장해야 한다.

- 원격 데이터 저장소에 상태를 유지하고 복제하는 방법
- 스트림 처리자의 로컬에 상태를 유지하고 주기적으로 복제하는 방법
