11장: 스트림 처리
일괄처리는 입력으로 파일 집합을 읽어 출력으로 새로운 파일 집합을 생성하는 기술이다.

출력은 파생 대이터라서 필요하다면 다시 일괄 처리를 수행해 재 생성 가능하다. 

그러나 데이터는 계속 생산되며 모아서 처리하는 일괄처리 방식은 느리다. 하루를 기다려야 하기 때문

더 자주 처리하거나, 이벤트 발생 시 바로 처리하는 방식으로 스트림 처리를 할 수 있다.

이벤트 스트림 전송

입력이 파일일때는 파일을 분석해 레코드의 연속으로 바꾸지만, 스트림 처리에서는 보통 이벤트라고 하는 작고 독립된 불견 객체를 받아 처리한다. 

이벤트는 일반적으로 이벤트 발생 타임 스탬프를 포함한다.
스트리밍은 생산자가 이벤트를 만들면 복수의 소비자가 토픽이나 스트림으로 이벤트를 묵어 빧아 처맇나다.

데이터스토어를 주기적으로 폴링해 처리할 수 있지만, 폴링이 잦을수록 이벤트 반환율이 떨어지기 떄문에 오버헤드가 더 커지므로, 이벤트가 나타날때마다 소비자에게 알리는 편이 더 낫다.

데이터베이스 말고 이벤트를 알리는 방법이 무엇이 있을까? 

메시징 시스템

이벤트를 소비자에게 전달하려면 보통 메시징 시스템을 사용함.

생산자는 이벤트를 메시지에 담아 보내고, 소비자는 그것을 받아 처리함.

발행/구독 모델을 구현하는 방법은 다양한 방식이 존재하며 정답은 없다. 아래를 고려하자

생산자가 소비자보다 메시지를 빨리 생산한다면?
시스템은 메시지를 버리거나, 큐에 버퍼링하거나, 백프레셔를 적용한다.
큐에 메시지가 쌓일때 메모리보다 커지면 시스템이 중단되는가? 메시지를 디스크에 쓰는가?
노드가 죽거나 일시적으로 오프라인이 된다면 어떨까? 손실되는 메시지가 있어야 하나?
디스크에 기록하거나, 복제본 생성을 하거나 둘 다 해야 한다
때로 메시지를 잃어도 괜찮다면, 처리량은 높이고 지연 시간은 낮출 수 있다. 
생산자에서 소비자로 메시지를 직접 전달하기

많은 메시지 시스템은 중간 노드를 통하지 않고 직접 통신해서 전달한다

UDP 멀티캐스트는 낮은 지연이 필수인 주식과 같은곳에서 많이 사용됌. UDP 자체는 신뢰성이 낮아도 애플리케이션 단 프로토콜은 패킷 복구 가능
직접 메시징 시스템은 잘 동작하지만, 일반적으로 메시지가 유실될 수 있는 가능성을 고려해서 코드를 작성해야 한다. 

또한 소비자가 오프라인이라면 메시지를 전달하지 못하는 상태에 있어 메시지가 유실될 수 있따

메시지 브로커

직접 메시징 시스템 대안으로 메시지 브로커(큐)를 두고 사용한다. 브로커는 메시지를 처리하는 일종의 데이터베이스이다. 브로커에 데이터가 모이기 때문에, 클라이언트의 상태 변경에 쉽게 대처할 수 있다.

메시지 브로커와 데이터베이스의 비교

메시지 브로커와 데이터베이스에는 중요한 실용적 차이가 있지만 이 특징은 데이 터베이스의 속성과 상당히 비슷하다.

데이터베이스는 명시적으로 데이터가 삭제될 때까지 데이터를 보관한다. 반면 메시지 브로커 대부분은 소비자에게 데이 터 배달이 성공할 경우 자동으로 메시지를 삭제한다. 이런 메시지 브로커는 오랜 기간 데이터를 저장하는 용도로 적당하 지 않다.
메시지 브로커는 대부분 메시지를 빨리 지우기 때문에 작업 집합이 상당히 작다고 가정한다. 즉 큐 크기가 작다. 소비자가 느려 메시지 브로커가 많은 메시지를 버퍼링해야 한다면(메시지를 메모리 안에 다 넣을 수 없으면 디스크로 내보낼 수도 있 다) 개별 메시지 처리 시간이 길어지고 전체 처리량이 저하된다[6]
데이터베이스는 보조 색인을 지원하고 데이터 검색을 위한 다양한 방법을 지원하는 반면 메시지 브로커는 특정 패턴과 부합하는 토픽의 부분 집합을 구독하는 방식을 지원한다. 메커니즘은 다르지만 둘 다 본질적으로 클라이언트가 데이터에서 필 요한 부분을 선택하는 방법이다.
데이터베이스에 질의할 때 그 결과는 일반적으로 질의 시점의 데이터 스냅숏을 기준으로 한다. 다른 클라이언트가 이어서 질의 결과를 바꾸는 어떤 데이터를 데이터베이스에 기록한다면 첫 번째 클라이언트는 다시 질의하거나, 데이터 변화를 폴링 하지 않는다면 앞선 결과가 기간이 지나 유효하지 않다는 점을 알 길이 없다. 반대로 메시지 브로커는 임의 질의를 지원하 지 않지만 데이터가 변하면(즉 전달할 새로운 메시지가 생겼을 때) 클라이언트에게 알려준다.
복수 소비자

복수 소부지가 같은 토픽에서 메시지를 읽을때 사용하는 두가지 주요 패턴

image-20250628153505021

로드 밸런싱
각 메시지는 소비자 중 하나로 전달된다. 따라서 소비자들은 해당 토픽의 메시지를 처리하는 작업을 공유한다. 브로커는 메시 지를 전달할 소비자를 임의로 지정한다. 이 패턴은 메시지를 처리하는 비용이 비싸서 처리를 병렬화하기 위해 소비자를 추가 하고 싶을 때 유용하다. (AMQP는 같은 큐를 소비하는 클라이언트를 여러 개 둬서 로드 밸런싱을 구현할 수 있다. JMS에서는 이 방식을 공유 구독(shared subscription)이라 한다.)

팬 아웃
각 메시지는 모든 소비자에게 전달된다. 팬 아웃 방식을 사용하면 여러 독립적인 소비자가 브로드캐스팅된 동일한 메시지를 서로 간섭 없이 청취"할 수 있다. 이것은 같은 입력 파일을 읽어 여러 다른 일괄 처리 작업에서 사용하는 것과 동일하다. (이 기능은 JMS에서는 토픽 구독, AMQP에서는 바인딩 교환으로 제공된다.)

확인 응답과 재전송

소비자는 언제라도 장애가 발생할 수 있어, 메시지 수신 후 장애 발생하여 유실 가능함.

이걸 방지하기 위해 확인 응답을 사용해서, 클라이언트가 메시지 처리가 끝낫을때 브로커에게 명시적으로 응답하여 지울 수 있도록 함. 

브로커가 ack를 받기 전 클라이언트 연결이 닫히거나 타임아웃되면 브로커는 메시지가 처리되지 않았다고 가정하고 다른 소비자에게 다시 전송한다

장애 복구 시 메시지 재전송이 순서를 바꿀 수 있다
생산자가 다음 순서로 소비자에게 메시지를 전송한다 해보자. m1 → m2 → m3 → m4 → m5

이제 다음 상황을 상상해보자

m3은 소비자 2가 받았지만, 처리 도중 장애 발생.
m3은 확인 응답(ACK) 이 브로커에 도달하지 못함.
브로커는 "m3이 처리 안 됐구나!"라고 판단하고 → 다른 소비자(소비자 1) 에게 재전송함.
그런데 이미 소비자 1은 m4를 처리 중이이였음. 

결국 소비자 1의 처리 순서는 다음과 같이 됨 

m4 → m3 → m5
따라서 메시지 순서 보장이 필요한 시스템이라면:
하나의 소비자만 사용하거나 (소비자마다 독립된 큐 )
파티션/키 기반으로 같은 메시지 그룹은 같은 소비자가 처리하도록 강제해야 함.
파티셔닝된 로그

메시지 브로커가 메시지를 디스크에 지속성 있께 보관하더라도, 소비자에게 전달된 후 즉시 삭제한다. 브로커는 일시적으로 보관하는 개념으로 만들어졌기 때문.

메시징 시스템에 새로운 소비자를 추가하면 일반적으로 소비자를 등록한 시점 이후에 전송된 메시지부터 받기 시작한다. 이전 메시지는 한번 지나가면 다시 복구할 수 없다.

신규 구독자는 “등록 시점 이후”에 온 메시지만 수신
이전에 삭제된 메시지는 받을 수 없음
 파일 시스템, 데이터베이스는 이와 반대다. 클라이언트를 새로 추가하더라도 과거에 기록했던 데이터도 애플리케이션이 명 시적으로 덮어쓰거나 지우지 않으면 얼마든지 읽을 수 있다.

데이터베이스의 지속성 있는 저장 방법과 메시징 시스템의 지연 시간이 짧은 알림 기능을 조합할 수 는 없을까? 이것이 로그 기반 메시지 브로커(log-based message broker)의 기본 아이디어다.

로그를 사용한 메시지 저장소

로그는 디스크에 저장된 추가 전용 레코드의 연속이다.

생산자가 보낸 메시지는 로그 끝에 추가하고, 소비자는 로그를 읽어 순차적으로 메시지를 받는다.

디스크 하나를 쓸때보다 처리량을 높이기 위해 확장하는 방법으로 로그를 파티셔닝하는 방법이 있다.

image-20250628161153006

각 파티션 내에서 브로커는 모든 메시지에 오프셋이라고 부르는 단조 증가 순번을 부여한다.

단 다른 파티션간 메시지 순서는 보장하지 않는다. 
카프카, 키네시스 등이 이런 방식으로 동작한다. 

이런 브로커는 모든 메시지를 디스크에 저장하지만, 여러 장비에 파티셔닝하여 초당 수백만개의 메시지를 처리할 수 있고 복제함으로써 장애에 대비할 수 있다. 

로그 방식과 전통적 메시징 방식의 비교

로그 기반 접근법은, 팬 아웃 방식을 제공할 수 있다.

각 클라이언트는 할당된 파티션의 메시지를 모두 소비한다. 일반적으로 소비자에 로그 파티션이 할 당되면 소비자는 단일 스레드로 파티션에서 순차적으로 메시지를 읽는다. 이런 거친 방식의 로드 밸 런싱 방법은 몇 가지 불리한 면이 있다.

토픽 하나를 소비하는 작업을 공유하는 노드 수는 많아야 해당 토픽의 로그 파티션 수 제한된다. 같은 파티션 내 메시지 는 같은 노드로 전달되기 때문이다.
특정 메시지 처리가 느리면 파티션 내 후속 메시지 처리가 지연된다(선두 차단(head-of-ine blocking) 형태.
즉 메시지를 처리하는 비용이 비싸고 메시지 단위로 병렬화 처리하고 싶지만 메시지 순서는 그렇게 중요하지 않다면 JMS/AMOP 방식의 메시지 브로커가 적합하다. 반면 처리량이 많고 메시지를 처 리하는 속도가 빠르지만 메시지 순서가 중요하다면 로그 기반 접근법이 효과적이다.

소비자 오프셋

오프셋: 파티션 내 각 메시지에 부여된 순차 번호
소비자 오프셋: 소비자가 “처리 완료” 상태로 표시한 마지막 메시지의 번호
오프셋을 사용한 메시지 처리 방법

소비자는 메시지를 읽으면서 처리 완료 시점의 오프셋을 주기적으로 브로커에 기록
브로커는 개별 메시지 ACK 대신 소비자 오프셋만 저장
기록된 오프셋 이하의 메시지는 “이미 처리됨”, 그보다 높은 오프셋은 “미처리”로 간주
장점

추적 오버헤드 감소
매 메시지마다 ACK를 관리할 필요 없이 오프셋만 주기 기록
배치·파이프라이닝
오프셋 기록 작업을 일괄로 묶어 처리 가능
처리량(throughput) 향상
장애 복구 과정

소비자 노드 장애 발생
같은 소비자 그룹의 다른 노드가 해당 파티션과 마지막 기록된 오프셋 인계받음
인계받은 노드는 그 오프셋부터 메시지 처리 재개
그러나 중복처리 가능성이 있다.

장애 시점에 이미 처리했으나 아직 오프셋을 기록하지 못한 메시지는 재시작 후 다시 읽혀, 소비자에게 중복 전달될 수 있음
디스크 공간 사용

로그를 계속 추가한다면, 결국 디스크 공간을 전부 사용하게 되어서, 이문제를 해결하기 위해 실제로는 로그를 여러 조각으로 나누고 오래된 조각을 삭제하거나 보관 저장소로 이동함.

또한 소비자 처리 속도가 느려 메시지가 생산되는 속도를 따라잡지 못하면 소비자가 너무 뒤처질 수 있음.

소비자 오프셋이 삭제된 세그먼트를 가리킬 때
소비자 처리 속도가 너무 느려서,
브로커가 해당 세그먼트를 이미 삭제했다면
→ 그 오프셋 이전 메시지는 복구 불가 → 메시지 일부 유실 발생 가능
유실 방지를 위한 버퍼링 한계
“디스크 링 버퍼(circular buffer)” 구조 사용
새 로그 기록 시,
버퍼가 가득 차면 가장 오래된 세그먼트부터 순차적으로 덮어쓰기
간단하게 계산해보자

하드디스크 용량이 6TB 순차 처리량 150MB/s 일때, 11시간이면 메시지가 가득 차서 지워야함. 
실제 운영 환경에서는 
최대 대역폭으로 연속 기록하는 경우는 거의 없음
따라서 수 일~수 주치 메시지를 보관 가능
그리고, 처리량의 특성을 따져보면 

로그 기반 브로커
모든 메시지를 무조건 디스크에 기록
보관량(로그 크기)에 상관없이 쓰기 처리량은 일정
메모리 우선 큐 방식 대비
메모리 큐가 작을 땐 빠르지만,
큐가 일정 크기 이상으로 커지면 디스크 기록 발생 → 처리량 급감
반대로 로그 기반 브로커는 처음부터 끝까지 디스크 기록만 하므로,
메시지 양이 많아져도 처리량 변화 없음
데이터베이스와 스트림

이종 데이터 시스템에서 발생하는 문제 한 가지를 먼저 살펴본 다음 이벤트 스트림의 아이디어를 데이터베이스에 적용해 이 문제를 해결하는 방법을 찾는다.

시스템 동기화 유지하기

변경 데이터 캡처

변경 데이터 캡처는 DB에 기록되는 모든 변화를 관찰해 다른 시스템으로 데이터를 복제할 수 있는 형태로 추출하는 과정이다.

image-20250628164546084

예를 들면 데이터베이스의 변경 사항을 캡처해 같은 변경 사항을 검색 색인에 꾸준히 반영할 수 있 다. 같은 순서로 로그 변경이 반영된다면 데이터베이스의 데이터와 색인이 일치할 것이다. 

변경 데이터 캡쳐의 구현

CDC는 본질적으로 변경 사항을 캡처할 DB 하나를 리더로 하고 나머지를 팔로워로 한다.

DB 트리거를 이용하기도 하는데, 고장나기 쉽고 성능 오버헤드가 상당하다. 

때문에 복제 로그를 파싱해서 사용하는데, 스키마 변경 등 해결해야 할 여러 문제가 있지만 트리거 방식보다 견고한 방법이다.

변경 데이터 캡처는 메시지 브로커와 동일하게 비동기 방식으로 동작한다. 레코드 데이터베이스 시 스템은 변경 사항을 커밋하기 전에 변경 사항이 소비자에게 적용될 때까지 기다리지 않는다. 운영상 이점이 있는 설계로 느린 소비자가 추가되더라도 레코드 시스템에 미치는 영향이 적다. 하지만 복제 지연의 모든 문제가 발생하는 단점이 있다

초기 스냅숏

데이터베이스의 모든 변경 내역(체인지 로그)만으로는 최신 상태를 복구할 수 있지만,

로그가 너무 방대해 디스크를 금방 소모
전체 로그 재생 시간이 지나치게 오래 걸림
전체 상태 복제 시점에, 아직 로그에 남아 있지 않은 “오랫동안 변경되지 않은 레코드”까지 포함해야 함

예시: 인덱스를 새로 만들거나, 신규 팔로워 노드를 완전 복제할 때
로그만으로는 “과거 어느 시점의 전체 데이터”를 보장할 수 없어 일관성 있는 스냅숏(snapshot) 필요

때문에 스냅숏과 로그 오프셋을 연계해서

스냅숏 생성 시점에 데이터베이스 전체 덤프(복사본)를 뜸
그 덤프가 적용된 마지막 로그 위치(또는 오프셋 번호)를 함께 기록
스냅숏 이후의 변경 로그는 이 오프셋부터 순차적으로 재생(apply)
덤프 데이터 + 그 이후 로그 재생 = 완전한 최신 상태 확보
이벤트 소싱

이벤트 소싱은 ddd에서 개발한 기법으로, 애플리 케이션 상태 변화를 모두 변경 이벤트 로그로 둔다.

변경 데이터 캡처(CDC)와의 차이

구분	변경 데이터 캡처 (CDC)	이벤트 소싱
추출 레벨	데이터베이스 변경 로그(저수준)	애플리케이션 로직 수준 이벤트(고수준)
저장 방식	기존 테이블에 읽기 전용으로 전체 레코드 갱신·삭제 수행	이벤트 로그에 추가 전용(append-only)
애플리케이션 의존성	CDC 실행 여부를 애플리케이션이 몰라도 됨	애플리케이션 코드가 “이벤트 로그”에서 상태를 직접 재구성해야 함
경쟁 조건 보장	DB 복제 로그 사용 시 기록 순서 보장 (경쟁 조건 없음)	애플리케이션 차원에서 이벤트 순서를 보장하고, 상태 계산 로직 구현 필요
주요 장점

불변 기록
모든 상태 변화가 이벤트 단위로 남아 있어, 과거 이력을 항상 완전하게 조회 가능
애플리케이션 수준 의미 보존
“학생이 강의 신청을 취소했다” 같은 비즈니스 의미의 단위 이벤트를 저장
내부 테이블 조작(삭제·업데이트) 세부 사항에 대한 가정 불필요
유연한 기능 확장
새로운 기능(예: 대기자 명단 처리) 추가 시
기존 이벤트를 그대로 두고,
부수 효과(예: 대기자 승인)를 별도 코드로 처리 가능
디버깅 및 감사(audit) 용이
사건(event) 단위로 로그가 남으므로, 문제 발생 시점과 원인을 정확히 추적
애플리케이션 버그로 인한 잘못된 상태 변경 방지
전통 방식과 이벤트 소싱 방식 비교

이벤트 소싱 방식
"StudentCancelledLecture(studentId, lectureId, timestamp, reason)" 이벤트 추가
이후 상태 재구성 시 이 이벤트만 읽어 “수강 취소”로 반영
비교: 전통적 방식
수강 테이블에서 해당 레코드 삭제
피드백 테이블에 취소 사유 INSERT
신규 기능 추가 시(대기자 승인)
삭제된 레코드를 어떻게 복원할지, 피드백 테이블 연관 방식 등 복잡한 가정 필요
명령과 이벤트

이벤트 소싱은 명령과 이벤트를 구분하는데 주의한다.

명령(Command)과 이벤트(Event)의 구분
명령: 사용자가 시스템에 요청을 처음 보낼 때의 행위.
아직 처리되지 않은 의도(intention)이며, 실행 실패 가능성이 있다.
예: “아이디 등록을 해줘”, “좌석을 예매해줘”
이벤트: 명령이 유효성 검사를 통과하고 확정된 결과.
시스템의 불변(immutable) 기록으로 간주되며, 언제든 “사실(fact)”로 받아들여진다.
이벤트 발생 이후에는 취소나 변경 요청도 별도의 새로운 이벤트로 기록된다.
명령 접수

사용자의 요청을 명령으로 받아들인다.
동기식 검증

데이터 무결성(중복 사용자명, 이미 예약된 좌석 등)을 즉시 검사
트랜잭션 직렬성을 활용해 “검증 ➔ 이벤트 발행”을 원자적으로 처리
이벤트 발행

검증에 성공하면 “사용자명 등록됨”, “좌석 예약됨” 같은 불변 이벤트 생성
이 시점부터 해당 사실은 시스템의 변경 불가능한 로그로 기록
이벤트의 특성

불변성: 한 번 기록된 이벤트는 되돌릴 수 없고, 모든 소비자가 동일한 순서로 보게 된다.

사실(fact): 나중에 취소나 변경을 요청하더라도 “이전에 예약했다”는 사실은 그대로 남음.

거절 불가: 이벤트 스트림을 구독하는 소비자는 이미 기록된 이벤트를 거부하거나 삭제할 수 없음.

성능 문제가 생기면 비동기 처리와 이벤트 분할 전략을 사용함

문제: 동기 검증이 복잡하거나 외부 시스템 의존도가 높을 때, 처리 지연이 발생
해결책: 두 단계 이벤트
가예약 이벤트 (SeatPreReserved)
즉시 발행하여 요청을 받아들였음을 기록
확정 이벤트 (SeatReservationConfirmed)
비동기 유효성 검사(예: 결제 완료, 외부 좌석 시스템 확인) 후 발행
이 방식으로, 1단계에서는 빠르게 이벤트를 기록하고, 2단계에서 최종 상태를 확정할 수 있다.
상태와 스트림, 그리고 불변성 

입력 파일의 불변성
10장에서 다룬 것처럼, 일괄 처리(batch job)에서는 원본 입력 파일을 건드리지 않고도 언제든지 다양한 실험적(what-if) 처리를 시도할 수 있다.
오류가 발생해도 원본은 그대로이므로 “되돌리기”나 “다른 파라미터로 재실행”이 매우 쉬움.
불변성이 주는 장점
재현성: 동일한 코드를 여러 번 돌려도 같은 결과 보장
오류 격리: 잘못된 처리가 원본에 영향을 주지 않음
기록 보존: 모든 버전의 입력 데이터를 보존해 변경 이력 추적 가능
이런 불변성 원리가 이벤트 소싱(event sourcing)과 변경 데이터 캡처(CDC) 패턴에서도 핵심 역할을 한다.

상태(State) vs. 이벤트 로그(Event Log)

전통적 관점: 데이터베이스는 ‘현재 상태’ 저장소
사용자가 조회 쿼리를 날릴 때 가장 빠르게 읽을 수 있도록 설계
삽입·갱신·삭제가 모두 가능해 “상태(state)”가 시시각각 바뀜
불변적 로그 관점: 모든 변경을 ‘사건(event)’으로 기록
예:
좌석 예약 → SeatReserved(showId, seatNo, userId)
입금 처리 → MoneyDeposited(accountId, amount)
HTTP 요청 처리 → RequestHandled(requestId, latency)
한 번 기록된 이벤트는 그 자체로 사실(fact)이 되며 절대 수정·삭제되지 않음
두 관점은 모순처럼 보이지만, 사실은 “변경 가능한 상태”가 “불변 이벤트 로그”의 누적 결과” 이다.

수학적으로 말하자면

상태 ← 적분(integration)

“지금의 상태”는 과거에 발생한 모든 이벤트(stream)를 합산한 결과라는 의미
이벤트 스트림 ← 미분(differentiation)

“이 시점에 어떤 변화가 일어났는가”를 상태 변화의 순간 순간으로 나눠 본다는 의미
주의: 엄밀한 수학 모델은 아니지만, “모든 상태 변화는 이벤트의 누적이다”라는 직관을 얻는 데 유용하다.
로그 컴팩션(Log Compaction)이 있어야 로그와 DB 상태 차이를 메울 수 있다. 

로그마다 최신 버전만을 보유하는 것. 
무차별 기록의 단점
키 하나가 여러 번 갱신되면, 로그에 같은 키의 이벤트가 수없이 쌓여 저장 공간과 재생 속도에 부담
컴팩션의 원리
각 키(key)별로 “최신 이벤트 하나”만 남기고, 이전에 덧붙인 오래된 이벤트를 삭제
예:
AccountBalanceChanged(a, +100) → AccountBalanceChanged(a, -30) → AccountBalanceChanged(a, +50)
컴팩션 후엔 “현재 잔고 변화 합: +120” 상태만 남도록 요약
컴팩션 후에도
로그의 “append-only 불변성”은 유지되며, 단지 오래된 중간 버전을 휴지 통으로 치운 것뿐
불변 이벤트의 장점

회계사는 금융 거래시 불변성을 이용해왔다. 거래가 발생하면 거래 정보를 원장에 추가만 하는 방식으로.

이것은 원장 자체가 “돈·상품·서비스 교환”에 대한 이벤트 로그 역할
손익계산서·대차대조표 등은 이 원장의 거래 내역을 합산해 만든 결과물
불변하게 추가가 되면 복구에 용이하다.

전통적 RDBMS에서 잘못된 업데이트가 덮어쓰기 되면 복구 어려움

불변 이벤트 로그는 추가만 가능하므로

잘못된 이벤트 이후에 보정 이벤트를 덧붙여 시스템 상태를 원상 복구
문제 발생 시 “어떤 이벤트가 잘못됐고, 어떻게 보정됐는지” 이력을 명확히 추적
결국 불변 로그는 적용 범위가  금융 시스템처럼 엄격한 감사가 필요한 곳은 물론

일괄 처리(batch job)·이벤트 기반 시스템·분석 파이프라인 등에도 유용

코드 버그로 잘못된 데이터가 들어와도 원본이 손상되지 않으므로 문제 진단·복구가 수월
분석가와 마케터는 고객 행동 이력을 다양한 관점에서 재구성 가능
동일한 이벤트 로그로 여러가지 뷰 만들기

불변 이벤트 로그에서 가변 상태를 분리하면 동일한 이벤트 로그로 다른 여러 읽기 전용 뷰를 만들 수 있다.

불변 이벤트 로그만을 덧붙이기(append-only) 방식으로 유지
가변 상태(읽기용 뷰)는 이 로그를 기반으로 다양하게 재구성
단일 이벤트 스트림을 여러 소비자(뷰)가 병렬로 구독해 각기 다른 형태의 상태를 만든다
실제 적용 사례로

Druid: 카프카 토픽을 직접 읽어 OLAP 분석용 데이터베이스 뷰 구축
Pistachio: 카프카를 커밋 로그(commit log)처럼 사용해 분산 키-값 저장소에 동기화
Kafka Connect Sink: 카프카에서 관계형·NoSQL 데이터베이스 및 검색 인덱스로 이벤트 전송
이처럼 “분산 로그 → 다양한 저장소/색인” 흐름은 대량 데이터 동기화에 적합

이렇게 쓰기 전용으로 한곳에 쌓아두고, 그 쓴 데이터 바탕으로 읽기 데이터를 만드는 것을 아래 CQRS라고 할 수 있다. 

Command Query Responsibility Segregation
쓰기(명령)는 이벤트 로그에만 기록
읽기(질의)는 뷰에서만 수행
효과
읽기 최적화된 스키마(비정규화 포함)를 자유롭게 설계 가능
쓰기 최적화와 읽기 최적화를 완전히 분리해 성능·유연성 확보
동시성 제어

이벤트 소싱과 CDC의 가장 큰 단점은 비동기 소비와 “자기 쓰기 읽기” 문제가 있다. 

문제: 이벤트를 로그에 기록한 직후에, 그 이벤트를 기반으로 한 읽기 뷰(view)에 반영되지 않았을 수 있음
영향: 사용자는 “방금 쓴 글이 보이지 않는다” 같은 일관성 문제를 경험
해결책 1 동기식 처리

방법:

이벤트 로그에 Append
읽기 뷰에 Update 를 하나의 트랜잭션으로 묶어 원자적으로 수행
제약:

로그와 뷰가 같은 저장소에 있어야, 분산 트랜잭션 없이 처리 가능
다른 시스템에 분리돼 있으면 분산 트랜잭션 또는 복잡한 브로드캐스트(전체 순서 보장) 필요
이벤트 로그로 현재 상태를 만들어 한장소에서 한번만 쓰게 만드는 방법도 있다.

단일 쓰기 포인트
사용자 동작을 “하나의 이벤트”로 설계 → 단일 로그 Append만으로 모든 변경 기록
다중 객체 트랜잭션 대신, “사용자 행위(event)” 자체가 여러 상태 변경을 설명
파티셔닝 전략
로그 파티션 번호 = 상태 파티션 번호로 매핑
예: 사용자 ID % N → 파티션 3
파티션3 로그 소비자는 오직 파티션3 상태만 갱신
단일 스레드로 “한 번에 하나씩” 처리 → 동시성 제어 불필요
파티션 내에서는 순서가 보장되므로 동시성 비결정성이 제거됨
스트림 처리

스트림으로 할 수 있는 일은 크게 세가지

이벤트에서 데이터를 꺼내 디비나 캐시, 색인 같은 시스템에 기록해서 질의하게 만든다
이벤트를 사용자에게 직접보낸다. 알림 이메일 등
입력 스트림을 처리해 출력 스트림을 생산하여 파이프라인을 구성함
일괄 처리 작업과 가장 크게 다른점은 스트림은 끝나지 않는다. 

스트림 분석

분석은 연속한 특정 이벤트 패턴보다 대량의 이벤트를 집계하고 통계적 지표를 뽑는것을 우선한다

특정 유형 이벤트 빈도가 얼마나 자주 발생하는지
특정 기간에 걸친 값의 이동 평균 계산
이전 시간 간격과 현재 통계값을 비교
보통 이런것은 윈도우로 구간을 나누어 처리한다

스트림 시스템은 블룸 필터같은 확률적 알고리즘을 사용하기도 한다. 

이벤트 시간 대 처리 시간

메시지가 지연되면 순서를 예측하기도 어렵고, 이벤트 순서가 꼬일수도 있다

분당 요청 수를 세기 위해 1분 윈도우에 그룹화 했을떄, 37분에 들어온 이벤트를 카운트한 다음

38분과 39분에 속한다면? 

이경우 낙오된 이벤트를 처리할 두가지 방법이 있따

낙오자 이벤트 무시
수정 값을 발행해서 기존 값을 갱신
어떤 시계를 사용해야 할까?

가능하다면, 클라이언트의 시계를 봐야지 정확하다. 그래야 지연된지 알 수 있다. 

잘못된 장치 시계를 조정하는 한 가지 방법은 세 가지 타임스탬프를 로그로 남기는 것이다[82].

이벤트가 발생한 시간. 장치 시계를 따른다.
이벤트를 서버로 보낸 시간. 장치 시계를 따른다.
서버에서 이벤트를 받은 시간. 서버 시계를 따른다.
2번째와 3번째 타임스탬프 차이를 구하면 클라 시계와 서버 시계간의 차이를 추정할 수 있게 된다.

윈도우 유형

이벤트 타임스탬프를 어떻게 결정할지 안다면 다음 단계는 윈도우 기간을 어떻게 정의해야 하는지 결정하는 일이다. 윈도우는 이벤트 수를 세거나 윈도우 내 평균값을 구하는 등 집계를 할 때 사용한다.

텀블링 윈도우 (Tumbling Window)
고정된 크기, 겹치지 않음
각 이벤트는 정확히 하나의 윈도우에 속함
예: 1분 텀블링 윈도우 → 10:03:00 ~ 10:03:59
구현: 타임스탬프에서 초 단위를 버려 정해진 간격으로 분할
홉핑 윈도우 (Hopping Window)
고정된 크기, 겹칠 수 있음
윈도우가 일정한 간격(hop)으로 이동하며 중복 포함 가능
예: 5분 홉핑 윈도우, hop 1분 → 10:0310:07, 10:0410:08, ...
구현: 텀블링 윈도우를 여러 개 중첩하여 구성
슬라이딩 윈도우 (Sliding Window)
지속적으로 움직이는 시간 창
윈도우는 지속적으로 갱신되며, 기준 시간 간격 내의 모든 이벤트 포함
예: 5분 슬라이딩 윈도우 → 10:08:12 이벤트는 10:03:13 이후 이벤트와 함께 포함될 수 있음
구현: 시간순 버퍼 유지, 오래된 이벤트 제거
세션 윈도우 (Session Window)
고정된 길이 없음, 이벤트 활동 기반으로 윈도우 결정
비활성 시간이 일정 시간(예: 30분) 이상 지속되면 윈도우 종료
같은 사용자의 연속된 활동을 하나의 세션으로 묶음
예: 웹사이트 접속 기록, 로그인 후 활동 추적 등에 사용
스트림 조인

스트림 조인이란, 시간에 따라 연속적으로 들어오는 데이터(스트림)들 사이에서 특정 조건(주로 키)을 기준으로 관련된 레코드들을 결합(join) 하는 것

스트림 조인이 어려운 이유

이벤트가 언제 도착할지 예측 불가 (지연, 순서 뒤바뀜 등)
데이터가 무한히 계속 들어옴
상태(state)를 오래 유지하거나 타임아웃 조건을 설정해야 
스트림 조인의 유형 3가지

스트림-스트림 조인 (Stream-Stream Join)
두 개의 스트림 간의 조인
시간 윈도우가 필요 (예: 최근 1시간 안의 검색과 클릭 조합)
예:
검색 스트림: 사용자가 검색한 키워드
클릭 스트림: 검색 결과 중 어떤 URL을 클릭했는지
두 이벤트 모두 필요하므로 양쪽 모두 상태 유지 필요
스트림-테이블 조인 (Stream-Table Join)
실시간 이벤트 스트림과 기준 테이블(상태 정보)을 조인
예:
스트림: 사용자 활동 이벤트
테이블: 사용자 프로필 정보
프로필 정보를 이벤트에 붙여 enrich(강화)
보통 테이블은 로컬에 캐시하거나 CDC 방식으로 실시간 갱신
테이블-테이블 조인 (Table-Table Join)
두 테이블(스트림에서 만들어진 상태/뷰)의 조인
목적: 구체화된 뷰(materialized view) 유지
예:
테이블1: 사용자 팔로우 관계
테이블2: 트윗 정보
조인 결과: 트위터 타임라인
트윗, 삭제, 팔로우/언팔로우 등의 이벤트로 상태 변화 시 즉시 반영
내결함성 

일괄 처리와 비교되는 스트림 처리의 도전 과제는 다음이 있다.

일괄 처리: 입력이 불변이고 태스크 재시작이 쉬움 → effectively-once 보장
스트림 처리: 입력이 무한, 종료 시점 없음 → 일괄 처리와 같은 단순 재처리 불가능
1. 마이크로 일괄 처리와 체크포인트

마이크로 일괄 처리 (Microbatching)
스트림을 짧은 블록으로 잘라 일괄 처리처럼 처리 (ex: Spark Streaming)
일반적으로 1초 단위
장점: 일괄 처리의 내결함성 방식 유지
단점: 지연(latency)과 스케줄링 비용 간 트레이드오프 존재
체크포인트 기반 처리 (Checkpointing)
ex: Flink
연산자 상태를 주기적으로 스냅샷 후 저장소(HDFS 등)에 저장
장애 시 최근 체크포인트부터 재시작, 해당 사이 출력은 폐기
체크포인트는 barrier라는 신호로 트리거됨
2. 외부 시스템과 부수 효과

출력이 외부로 나간 뒤에는 재처리로 인해 부수 효과가 중복될 수 있음
예: 이메일 발송, 외부 DB에 쓰기, Kafka 등 메시지 브로커에 기록 등
이를 방지하기 위해 원자적 커밋(atomic commit) 필요
3. 원자적 커밋 (Atomic Commit)

처리 성공 시에만 모든 부수 효과(commit)를 수행해야 함
일괄 처리에서의 2단계 커밋과 유사
Google Cloud Dataflow, VoltDB, Kafka 등은 제한된 환경에서 이를 구현
4. 멱등성 (Idempotence)

같은 작업을 여러 번 해도 결과가 같음
예: set("key", "value")는 멱등 / increment("key")는 비멱등
연산 자체가 멱등이 아니어도 메타데이터(ex: Kafka offset)로 멱등화 가능
Storm의 Trident, Kafka Streams 등도 이 방식 채택
단, 멱등성을 전제로 하기 위해 필요한 조건:
메시지 재생 순서 보장
처리 결정적(deterministic)이어야 함
상태 충돌 방지 위한 펜싱(Fencing) 필요
5. 상태 복구 전략

상태가 필요한 경우(예: 윈도우 집계, 조인 등), 장애 후에도 정확한 상태 복원 필요
복구 방식:

원격 저장소에 상태 저장 및 복제
느릴 수 있음 (네트워크 왕복)
로컬 상태 + 주기적 복제
Flink: 상태 스냅샷 → HDFS
Kafka Streams: 상태 변화 → 로그 컴팩션된 Kafka 토픽
상태 재생성
예: 작은 윈도우 상태는 재생 가능
로컬 DB 캐시나 CDC 기반 DB도 재구축 가능
6. 트레이드오프

로컬 상태 vs 원격 상태 선택은 디스크/네트워크 특성, 처리량/지연/복원성에 따라 달라짐
상황에 따라 최적의 선택은 달라지며, 모든 조건을 만족하는 절대 해법은 없음
